# Preface {-}

```{r align='center', out.width='390px', out.height='550px', echo=FALSE, include = knitr::is_html_output()}
knitr::include_graphics(file.path('cover', 'thesis_cover.jpg')) # show thesis cover
```

In this thesis, I explore a different, complementary approach to the traditional methodology of hypothesis testing used in psychology and cognitive neuroscience research. Although this alternative approach has deep roots in psychology and is thus by no means new, the version I advocate and have used in this thesis extends it with ideas and techniques from the rapidly growing field of artificial intelligence and specifically machine learning.

In **chapter \@ref(shared-states)**, I describe a study in which we used predictive models applied to functional MRI data, known as “decoding models” in the neuroimaging literature, to test a hypothesis about the shared neural basis of emotion experience and emotion understanding. To remedy the interpretational difficulties inherent to decoding analyses (and predictive models in general), **chapter \@ref(confounds-decoding)** outlines a method we developed to adjust for confounds in decoding analyses which helps to rule out alternative explanations of the results. Moving away from the focus on predictive models, **chapter \@ref(aomic)** is the result from our effort to publish the “Amsterdam Open MRI Collection” (AOMIC), a set of three large, multimodal, MRI datasets, and **chapter \@ref(morbid-curiosity)** describes a confirmatory, fully pre-registered neuroimaging study on a psychological phenomenon called “morbid curiosity”. Finally, the last two chapters return to the use of predictive models, this time in the context of facial expression perception. **Chapter \@ref(hypothesis-kernel-analysis)** outlines a method we developed (“hypothesis kernel analysis”) to formalize verbal hypotheses as quantitative predictive models, which we apply to a specific set of hypotheses about how facial movements relate to categorical emotions. At last, **chapter \@ref(static-vs-dynamic)** concludes this thesis with a study that compares predictive models of affective face perception based on static features (i.e., facial morphology) and dynamic features (i.e., facial movements), which shows that people integrate both sources of information in their affective inferences and experiences.

---

This PhD project was conducted under the supervision of Dr. [H. Steven Scholte](https://scholtelab.io/steven-scholte/) and Dr. [Suzanne Oosterwijk](https://sites.google.com/site/suzanneoosterwijk/) at the [Department of Psychology](https://psyres.uva.nl/), Faculty of Behavioral and Social Sciences, University of Amsterdam.

```{=html}
<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />The online version of this thesis is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>. The <i class="fa fa-file-pdf-o"></i> pdf version of the thesis is available for download on the toolbar above.</p>
```