% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Jack2017-qp,
  title    = "{Data-Driven} Methods to Diversify Knowledge of Human Psychology",
  author   = "Jack, Rachael and Crivelli, Carlos and Wheatley, Thalia",
  abstract = "Psychology aims to understand real human behavior. However,
              cultural biases in the scientific process can constrain
              knowledge. We describe here how data-driven methods can relax
              these constraints to reveal new insights that theories can
              overlook. To advance knowledge we advocate a symbiotic approach
              that better combines data-driven methods with theory.",
  journal  = "Trends Cogn. Sci.",
  month    =  nov,
  year     =  2017,
  keywords = "cultural psychology; data-driven methods; diversity;
              generalizability; human universals",
  language = "en"
}

@ARTICLE{Naselaris2021-ba,
  title     = "Extensive sampling for complete models of individual brains",
  author    = "Naselaris, Thomas and Allen, Emily and Kay, Kendrick",
  abstract  = "In designing cognitive neuroscience experiments, resource
               limitations induce a fundamental trade-off between sampling
               variation across individual brains and sampling variation across
               experimental conditions. Here, we argue that extensive sampling
               of experimental conditions is essential for understanding how
               human brains process complex stimuli, that a model of how any
               one brain does this is likely to generalize to most other
               brains, and that introducing large numbers of subjects into an
               analysis pool is likely to introduce unnecessary and undesirable
               variance. Thus, contrary to conventional wisdom, we believe that
               sampling many individuals provides relatively few benefits and
               that extensive sampling of a limited number of subjects is more
               productive for revealing general principles. Furthermore, an
               emphasis on depth in individual brains is well-suited for
               capitalizing on the improvements in resolution and
               signal-to-noise ratio that are being achieved in modern
               neuroscientific measurement techniques.",
  journal   = "Current Opinion in Behavioral Sciences",
  publisher = "Elsevier",
  volume    =  40,
  pages     = "45--51",
  month     =  aug,
  year      =  2021
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jolly2019-lx,
  title     = "The flatland fallacy: Moving beyond low--dimensional thinking",
  author    = "Jolly, E and Chang, L J",
  abstract  = "Psychology is a complicated science. It has no general axioms or
               mathematical proofs, is rarely directly observable, and is the
               only discipline in which the subject matter (ie, human
               psychological phenomena) is also the tool of investigation. Like
               the Flatlanders in Edwin …",
  journal   = "Top. Cogn. Sci.",
  publisher = "Wiley Online Library",
  year      =  2019
}

@ARTICLE{Bzdok2017-li,
  title     = "Classical Statistics and Statistical Learning in Imaging
               Neuroscience",
  author    = "Bzdok, Danilo",
  abstract  = "Brain-imaging research has predominantly generated insight by
               means of classical statistics, including regression-type
               analyses and null-hypothesis testing using t-test and ANOVA.
               Throughout recent years, statistical learning methods enjoy
               increasing popularity especially for applications in rich and
               complex data, including cross-validated out-of-sample prediction
               using pattern classification and sparsity-inducing regression.
               This concept paper discusses the implications of inferential
               justifications and algorithmic methodologies in common data
               analysis scenarios in neuroimaging. It is retraced how classical
               statistics and statistical learning originated from different
               historical contexts, build on different theoretical foundations,
               make different assumptions, and evaluate different outcome
               metrics to permit differently nuanced conclusions. The present
               considerations should help reduce current confusion between
               model-driven classical hypothesis testing and data-driven
               learning algorithms for investigating the brain with imaging
               techniques.",
  journal   = "Front. Neurosci.",
  publisher = "frontiersin.org",
  volume    =  11,
  pages     = "543",
  month     =  oct,
  year      =  2017,
  keywords  = "Rosetta Stone; data science; epistemology; machine learning;
               neuroimaging; p-value; statistical inference",
  language  = "en"
}

@UNPUBLISHED{Borsboom2020-xg,
  title    = "Theory Construction Methodology: A practical framework for theory
              formation in psychology",
  author   = "Borsboom, Denny and van der Maas, Han and Dalege, Jonas and
              Kievit, Rogier and Haig, Brian",
  abstract = "This paper aims to improve theory formation in psychology by
              developing a practical methodology for constructing explanatory
              theories: Theory Construction Methodology (TCM). TCM is a
              sequence of five steps. First, the theorist identifies empirical
              phenomena to become the target of explanation. Second, the
              theorist constructs a proto-theory: a set of theoretical
              principles that potentially explain these phenomena. Third, the
              proto-theory is used to construct a formal model: a set of model
              equations or simulation models that encode the explanatory
              principles. Fourth, the theorist investigates this model's
              explanatory adequacy. This is done by formalizing the empirical
              phenomena in terms of the model, and assessing whether the model
              indeed reproduces them. Fifth, the theorist studies the overall
              adequacy of the theory by evaluating whether phenomena are indeed
              reproduced faithfully, whether explanatory principles are
              parsimonious and substantively plausible, and whether the theory
              implies new predictions to promote further research. We
              illustrate TCM with an example taken from the intelligence
              literature (the mutualism model of intelligence), discuss the
              place of TCM in the larger scheme of scientific research, and
              propose an outline for a university curriculum that can
              systematically educate psychologists in the process of theory
              formation.",
  month    =  feb,
  year     =  2020
}

@ARTICLE{Haufe2014-el,
  title    = "On the interpretation of weight vectors of linear models in
              multivariate neuroimaging",
  author   = "Haufe, Stefan and Meinecke, Frank and G{\"o}rgen, Kai and
              D{\"a}hne, Sven and Haynes, John-Dylan and Blankertz, Benjamin
              and Bie{\ss}mann, Felix",
  abstract = "The increase in spatiotemporal resolution of neuroimaging devices
              is accompanied by a trend towards more powerful multivariate
              analysis methods. Often it is desired to interpret the outcome of
              these methods with respect to the cognitive processes under
              study. Here we discuss which methods allow for such
              interpretations, and provide guidelines for choosing an
              appropriate analysis for a given experimental goal: For a surgeon
              who needs to decide where to remove brain tissue it is most
              important to determine the origin of cognitive functions and
              associated neural processes. In contrast, when communicating with
              paralyzed or comatose patients via brain-computer interfaces, it
              is most important to accurately extract the neural processes
              specific to a certain mental state. These equally important but
              complementary objectives require different analysis methods.
              Determining the origin of neural processes in time or space from
              the parameters of a data-driven model requires what we call a
              forward model of the data; such a model explains how the measured
              data was generated from the neural sources. Examples are general
              linear models (GLMs). Methods for the extraction of neural
              information from data can be considered as backward models, as
              they attempt to reverse the data generating process. Examples are
              multivariate classifiers. Here we demonstrate that the parameters
              of forward models are neurophysiologically interpretable in the
              sense that significant nonzero weights are only observed at
              channels the activity of which is related to the brain process
              under study. In contrast, the interpretation of backward model
              parameters can lead to wrong conclusions regarding the spatial or
              temporal origin of the neural signals of interest, since
              significant nonzero weights may also be observed at channels the
              activity of which is statistically independent of the brain
              process under study. As a remedy for the linear case, we propose
              a procedure for transforming backward models into forward models.
              This procedure enables the neurophysiological interpretation of
              the parameters of linear backward models. We hope that this work
              raises awareness for an often encountered problem and provides a
              theoretical basis for conducting better interpretable
              multivariate neuroimaging analyses.",
  journal  = "Neuroimage",
  volume   =  87,
  pages    = "96--110",
  month    =  feb,
  year     =  2014,
  keywords = "Activation patterns; Decoding; EEG; Encoding; Extraction filters;
              Forward/backward models; Generative/discriminative models;
              Interpretability; Multivariate; Neuroimaging; Regularization;
              Sparsity; Univariate; fMRI",
  language = "en"
}

@article{baker2018deep,
  title={Deep convolutional networks do not classify based on global object shape},
  author={Baker, Nicholas and Lu, Hongjing and Erlikhman, Gennady and Kellman, Philip J},
  journal={PLoS computational biology},
  volume={14},
  number={12},
  pages={e1006613},
  year={2018},
  publisher={Public Library of Science}
}

@ARTICLE{Jack2017-gt,
  title     = "Toward a Social Psychophysics of Face Communication",
  author    = "Jack, Rachael and Schyns, Philippe G",
  abstract  = "As a highly social species, humans are equipped with a powerful
               tool for social communication-the face. Although seemingly
               simple, the human face can elicit multiple social perceptions
               due to the rich variations of its movements, morphology, and
               complexion. Consequently, identifying precisely what face
               information elicits different social perceptions is a complex
               empirical challenge that has largely remained beyond the reach
               of traditional methods. In the past decade, the emerging field
               of social psychophysics has developed new methods to address
               this challenge, with the potential to transfer psychophysical
               laws of social perception to the digital economy via avatars and
               social robots. At this exciting juncture, it is timely to review
               these new methodological developments. In this article, we
               introduce and review the foundational methodological
               developments of social psychophysics, present work done in the
               past decade that has advanced understanding of the face as a
               tool for social communication, and discuss the major challenges
               that lie ahead.",
  journal   = "Annu. Rev. Psychol.",
  publisher = "annualreviews.org",
  volume    =  68,
  pages     = "269--297",
  month     =  jan,
  year      =  2017,
  keywords  = "culture; facial expressions; reverse correlation; social
               communication; social psychophysics",
  language  = "en"
}

@ARTICLE{LeCun2015-xa,
  title     = "Deep learning",
  author    = "LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey",
  abstract  = "Deep learning allows computational models that are composed of
               multiple processing layers to learn representations of data with
               multiple levels of abstraction. These methods have dramatically
               improved the state-of-the-art in speech recognition, visual
               object recognition, object detection and many other domains such
               as drug discovery and genomics. Deep learning discovers
               intricate structure in large data sets by using the
               backpropagation algorithm to indicate how a machine should
               change its internal parameters that are used to compute the
               representation in each layer from the representation in the
               previous layer. Deep convolutional nets have brought about
               breakthroughs in processing images, video, speech and audio,
               whereas recurrent nets have shone light on sequential data such
               as text and speech.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  521,
  number    =  7553,
  pages     = "436--444",
  month     =  may,
  year      =  2015,
  language  = "en"
}

@INPROCEEDINGS{Deng2009-bp,
  title     = "{ImageNet}: A large-scale hierarchical image database",
  booktitle = "2009 {IEEE} Conference on Computer Vision and Pattern
               Recognition",
  author    = "Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and
               Li, Kai and Fei-Fei, Li",
  abstract  = "The explosion of image data on the Internet has the potential to
               foster more sophisticated and robust models and algorithms to
               index, retrieve, organize and interact with images and
               multimedia data. But exactly how such data can be harnessed and
               organized remains a critical problem. We introduce here a new
               database called ``ImageNet'', a large-scale ontology of images
               built upon the backbone of the WordNet structure. ImageNet aims
               to populate the majority of the 80,000 synsets of WordNet with
               an average of 500-1000 clean and full resolution images. This
               will result in tens of millions of annotated images organized by
               the semantic hierarchy of WordNet. This paper offers a detailed
               analysis of ImageNet in its current state: 12 subtrees with 5247
               synsets and 3.2 million images in total. We show that ImageNet
               is much larger in scale and diversity and much more accurate
               than the current image datasets. Constructing such a large-scale
               database is a challenging task. We describe the data collection
               scheme with Amazon Mechanical Turk. Lastly, we illustrate the
               usefulness of ImageNet through three simple applications in
               object recognition, image classification and automatic object
               clustering. We hope that the scale, accuracy, diversity and
               hierarchical structure of ImageNet can offer unparalleled
               opportunities to researchers in the computer vision community
               and beyond.",
  publisher = "ieeexplore.ieee.org",
  pages     = "248--255",
  month     =  jun,
  year      =  2009,
  keywords  = "Large-scale systems;Image
               databases;Explosions;Internet;Robustness;Information
               retrieval;Image retrieval;Multimedia databases;Ontologies;Spine"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cummins2000-pk,
  title     = "How does it work?`` versus'' what are the laws?``: Two
               conceptions of psychological explanation",
  author    = "Cummins, Robert",
  journal   = "Explanation and cognition",
  publisher = "books.google.com",
  pages     = "117--144",
  year      =  2000,
  keywords  = "TFBC"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Tosh2020-sf,
  title        = "The piranha problem: Large effects swimming in a small pond",
  author       = "Tosh, Christopher and Greengard, Philip and Goodrich, Ben and
                  Gelman, Andrew and Vehtari, Aki and Hsu, Daniel",
  abstract     = "In some scientific fields, it is common to have certain
                  variables of interest that are of particular importance and
                  for which there are many studies indicating a relationship
                  with a different explanatory variable. In such cases,
                  particularly those where no relationships are …",
  publisher    = "stat.columbia.edu",
  year         =  2020,
  howpublished = "\url{http://www.stat.columbia.edu/~gelman/research/unpublished/piranhas.pdf}",
  note         = "Accessed: 2021-5-6"
}

@ARTICLE{Kellen2019-af,
  title     = "A Model Hierarchy for Psychological Science",
  author    = "Kellen, David",
  abstract  = "Lee et al. (2019) provided a comprehensive list of
               recommendations for modelers that aims at improving the
               robustness of their results. Drawing from the literature on
               philosophy of science, the present commentary argues for a
               broader view of modeling that considers the different roles that
               they play in our scientific practices. Following Suppes (1966),
               I propose a model hierarchy and discuss the distinct issues that
               arise at each of its levels. The benefit of a hierarchy of this
               kind is that it can aid researchers in better understanding the
               different challenges that they face.",
  journal   = "Computational Brain \& Behavior",
  publisher = "Springer",
  volume    =  2,
  number    =  3,
  pages     = "160--165",
  month     =  dec,
  year      =  2019
}

@ARTICLE{Halevy2009-cv,
  title     = "The Unreasonable Effectiveness of Data",
  author    = "Halevy, Alon and Norvig, Peter and Pereira, Fernando",
  abstract  = "At Brown University, there is excitement of having access to the
               Brown Corpus, containing one million English words. Since then,
               we have seen several notable corpora that are about 100 times
               larger, and in 2006, Google released a trillion-word corpus with
               frequency counts for all sequences up to five words long. In
               some ways this corpus is a step backwards from the Brown Corpus:
               it's taken from unfiltered Web pages and thus contains
               incomplete sentences, spelling errors, grammatical errors, and
               all sorts of other errors. It's not annotated with carefully
               hand-corrected part-of-speech tags. But the fact that it's a
               million times larger than the Brown Corpus outweighs these
               drawbacks. A trillion-word corpus - along with other Web-derived
               corpora of millions, billions, or trillions of links, videos,
               images, tables, and user interactions - captures even very rare
               aspects of human behavior. So, this corpus could serve as the
               basis of a complete model for certain tasks - if only we knew
               how to extract the model from the data.",
  journal   = "IEEE Intell. Syst.",
  publisher = "ieeexplore.ieee.org",
  volume    =  24,
  number    =  2,
  pages     = "8--12",
  month     =  mar,
  year      =  2009,
  keywords  = "Humans;Data mining;Machine learning;Speech recognition;Frequency
               estimation;Web pages;Videos;Broadcasting;Natural language
               processing;Tagging;machine learning;very large data
               bases;Semantic Web"
}

@ARTICLE{Kriegeskorte2008-kv,
  title     = "Representational similarity analysis - connecting the branches
               of systems neuroscience",
  author    = "Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter",
  abstract  = "A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO
               QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH:
               brain-activity measurement, behavioral measurement, and
               computational modeling. Using measured brain-activity patterns
               to evaluate computational network models is complicated by the
               need to define the correspondency between the units of the model
               and the channels of the brain-activity data, e.g., single-cell
               recordings or voxels from functional magnetic resonance imaging
               (fMRI). Similar correspondency problems complicate relating
               activity patterns between different modalities of brain-activity
               measurement (e.g., fMRI and invasive or scalp
               electrophysiology), and between subjects and species. In order
               to bridge these divides, we suggest abstracting from the
               activity patterns themselves and computing representational
               dissimilarity matrices (RDMs), which characterize the
               information carried by a given representation in a brain or
               model. Building on a rich psychological and mathematical
               literature on similarity analysis, we propose a new experimental
               and data-analytical framework called representational similarity
               analysis (RSA), in which multi-channel measures of neural
               activity are quantitatively related to each other and to
               computational theory and behavior by comparing RDMs. We
               demonstrate RSA by relating representations of visual objects as
               measured with fMRI in early visual cortex and the fusiform face
               area to computational models spanning a wide range of
               complexities. The RDMs are simultaneously related via
               second-level application of multidimensional scaling and tested
               using randomization and bootstrap techniques. We discuss the
               broad potential of RSA, including novel approaches to
               experimental design, and argue that these ideas, which have deep
               roots in psychology and neuroscience, will allow the integrated
               quantitative analysis of data from all three branches, thus
               contributing to a more unified systems neuroscience.",
  journal   = "Front. Syst. Neurosci.",
  publisher = "frontiersin.org",
  volume    =  2,
  pages     = "4",
  month     =  nov,
  year      =  2008,
  keywords  = "computational modeling; electrophysiology; fMRI; population
               code; representation; similarity",
  language  = "en"
}

@UNPUBLISHED{Daube2020-ps,
  title    = "Deep neural network explains human visual categorisation using
              similar functional features",
  author   = "Daube, Christoph and Xu, Tian and Zhan, Jiayu and Webb, Andrew
              and Ince, Robin A A and Garrod, Oliver G B and Schyns, Philippe",
  abstract = "Deep neural networks (DNNs) can resolve real-world tasks with
              apparent human-like performance and could therefore offer
              accessible information-processing models of the brain. However,
              interpreting these models remains a challenge. Here, we address
              this challenge by leveraging the experimental control of a
              generative model of the stimuli, in the form of faces that vary
              in 3D shape and texture. We asked human participants to rate how
              similar randomly generated faces were to four familiar
              colleagues. We then predicted these human responses from the
              shape and texture parameters of the generative model and from the
              activations of four DNNs trained on different optimisation
              objectives. With information- theoretic redundancy and reverse
              correlation, we then grounded behavioural prediction performance
              into interpretable functional shape and texture features. Our
              study addresses a critical prerequisite to evaluating the
              similarity between the brain and its DNN models: both must
              process the same functional features in the task.",
  month    =  sep,
  year     =  2020,
  keywords = "behaviour; DNN; face; information theory; PID; VAE; visual"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ngo2021-kf,
  title     = "Predicting Individual Task Contrasts From Resting-state
               Functional Connectivity using a Surface-based Convolutional
               Network",
  author    = "Ngo, G and Khosla, M and Jamison, K and Kuceyeski, A and
               {others}",
  abstract  = "Task-based and resting-state represent the two most common
               experimental paradigms of functional neuroimaging. While
               resting-state offers a flexible and scalable approach for
               characterizing brain function, task-based techniques provide
               superior localization. In this …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ivanova2021-wk,
  title     = "Is it that simple? Linear mapping models in cognitive
               neuroscience",
  author    = "Ivanova, A A and Schrimpf, M and Anzellotti, S and Zaslavsky, N
               and {others}",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021
}

@ARTICLE{Aviezer2017-wa,
  title     = "The inherently contextualized nature of facial emotion
               perception",
  author    = "Aviezer, Hillel and Ensenberg, Noga and Hassin, Ran R",
  abstract  = "According to mainstream views of emotion perception, facial
               expressions are powerful signals conveying specific emotional
               states. This approach, which endorsed the use of
               stereotypical-posed faces as stimuli, has typically ignored the
               role of context in emotion perception. We argue that this
               methodological tradition is flawed. Real-life facial expressions
               are often highly ambiguous, heavily relying on contextual
               information. We review recent work suggesting that context is an
               inherent part of real-life emotion perception, often leading to
               radical categorical changes. Contextual effects are not an
               obscurity at the fringe of facial emotion perception, rather,
               they are part of emotion perception itself.",
  journal   = "Curr Opin Psychol",
  publisher = "Elsevier",
  volume    =  17,
  pages     = "47--54",
  month     =  oct,
  year      =  2017,
  language  = "en"
}

@ARTICLE{Aliko2020-ry,
  title     = "A naturalistic neuroimaging database for understanding the brain
               using ecological stimuli",
  author    = "Aliko, Sarah and Huang, Jiawen and Gheorghiu, Florin and Meliss,
               Stefanie and Skipper, Jeremy I",
  abstract  = "Neuroimaging has advanced our understanding of human psychology
               using reductionist stimuli that often do not resemble
               information the brain naturally encounters. It has improved our
               understanding of the network organization of the brain mostly
               through analyses of 'resting-state' data for which the functions
               of networks cannot be verifiably labelled. We make a
               'Naturalistic Neuroimaging Database' (NNDb v1.0) publically
               available to allow for a more complete understanding of the
               brain under more ecological conditions during which networks can
               be labelled. Eighty-six participants underwent behavioural
               testing and watched one of 10 full-length movies while
               functional magnetic resonance imaging was acquired. Resulting
               timeseries data are shown to be of high quality, with good
               signal-to-noise ratio, few outliers and low movement.
               Data-driven functional analyses provide further evidence of data
               quality. They also demonstrate accurate timeseries/movie
               alignment and how movie annotations might be used to label
               networks. The NNDb can be used to answer questions previously
               unaddressed with standard neuroimaging approaches, progressing
               our knowledge of how the brain works in the real world.",
  journal   = "Sci Data",
  publisher = "nature.com",
  volume    =  7,
  number    =  1,
  pages     = "347",
  month     =  oct,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Adjerid2018-vs,
  title     = "Big data in psychology: A framework for research advancement",
  author    = "Adjerid, Idris and Kelley, Ken",
  abstract  = "The potential for big data to provide value for psychology is
               significant. However, the pursuit of big data remains an
               uncertain and risky undertaking for the average psychological
               researcher. In this article, we address some of this uncertainty
               by discussing the potential impact of big data on the type of
               data available for psychological research, addressing the
               benefits and most significant challenges that emerge from these
               data, and organizing a variety of research opportunities for
               psychology. Our article yields two central insights. First, we
               highlight that big data research efforts are more readily
               accessible than many researchers realize, particularly with the
               emergence of open-source research tools, digital platforms, and
               instrumentation. Second, we argue that opportunities for big
               data research are diverse and differ both in their fit for
               varying research goals, as well as in the challenges they bring
               about. Ultimately, our outlook for researchers in psychology
               using and benefiting from big data is cautiously optimistic.
               Although not all big data efforts are suited for all researchers
               or all areas within psychology, big data research prospects are
               diverse, expanding, and promising for psychology and related
               disciplines. (PsycINFO Database Record (c) 2018 APA, all rights
               reserved).",
  journal   = "Am. Psychol.",
  publisher = "psycnet.apa.org",
  volume    =  73,
  number    =  7,
  pages     = "899--917",
  month     =  oct,
  year      =  2018,
  language  = "en"
}

@UNPUBLISHED{Haslbeck2019-ic,
  title    = "Modeling Psychopathology: From Data Models to Formal Theories",
  author   = "Haslbeck, Jonas M B and Ryan, Ois{\'\i}n and Robinaugh, Donald
              and Waldorp, Lourens and Borsboom, Denny",
  abstract = "Over the past decade there has been a surge of empirical research
              investigating mental disorders as complex systems. In this paper,
              we investigate how to best make use of this growing body of
              empirical research and move the field toward its fundamental aims
              of explaining, predicting, and controlling psychopathology. We
              first review the contemporary philosophy of science literature on
              scientific theories and argue that fully achieving the aims of
              explanation, prediction, and control requires that we construct
              formal theories of mental disorders: theories expressed in the
              language of mathematics or a computational programming language.
              We then investigate three routes by which one can use empirical
              findings (i.e., data models) to construct formal theories: (a)
              using data models themselves as formal theories, (b) using data
              models to infer formal theories, and (c) comparing empirical data
              models to theory-implied data models in order to evaluate and
              refine an existing formal theory. We argue that the third
              approach is the most promising path forward. We conclude by
              introducing the Abductive Formal Theory Construction (AFTC)
              framework, informed by both our review of philosophy of science
              and our methodological investigation. We argue that this approach
              provides a clear and promising way forward for using empirical
              research to inform the generation, development, and testing of
              formal theories both in the domain of psychopathology and in the
              broader field of psychological science.",
  month    =  dec,
  year     =  2019,
  keywords = "Clinical Psychology; Complex Dynamical Systems; Computational
              Modeling; Formal Theory; Network Approach; Theory development"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ekman1997-bk,
  title     = "Universal facial expressions of emotion",
  author    = "Ekman, Paul and Keltner, Dacher",
  abstract  = "The culture speciﬁc view, that facial behaviors are associated
               with emotion through culturally variable learning, received
               support from Klineberg's (1938) descriptions of how the facial
               behaviors described in Chinese literature diﬁered from the
               facial behaviors associated with …",
  journal   = "Segerstrale U, P. Molnar P, eds. Nonverbal communication: Where
               nature meets culture",
  publisher = "paulekman.com",
  pages     = "27--46",
  year      =  1997
}

@ARTICLE{Naselaris2021-ba,
  title     = "Extensive sampling for complete models of individual brains",
  author    = "Naselaris, Thomas and Allen, Emily and Kay, Kendrick",
  abstract  = "In designing cognitive neuroscience experiments, resource
               limitations induce a fundamental trade-off between sampling
               variation across individual brains and sampling variation across
               experimental conditions. Here, we argue that extensive sampling
               of experimental conditions is essential for understanding how
               human brains process complex stimuli, that a model of how any
               one brain does this is likely to generalize to most other
               brains, and that introducing large numbers of subjects into an
               analysis pool is likely to introduce unnecessary and undesirable
               variance. Thus, contrary to conventional wisdom, we believe that
               sampling many individuals provides relatively few benefits and
               that extensive sampling of a limited number of subjects is more
               productive for revealing general principles. Furthermore, an
               emphasis on depth in individual brains is well-suited for
               capitalizing on the improvements in resolution and
               signal-to-noise ratio that are being achieved in modern
               neuroscientific measurement techniques.",
  journal   = "Current Opinion in Behavioral Sciences",
  publisher = "Elsevier",
  volume    =  40,
  pages     = "45--51",
  month     =  aug,
  year      =  2021
}

@ARTICLE{Zech2018-bq,
  title     = "Variable generalization performance of a deep learning model to
               detect pneumonia in chest radiographs: A cross-sectional study",
  author    = "Zech, John R and Badgeley, Marcus A and Liu, Manway and Costa,
               Anthony B and Titano, Joseph J and Oermann, Eric Karl",
  abstract  = "BACKGROUND: There is interest in using convolutional neural
               networks (CNNs) to analyze medical imaging to provide
               computer-aided diagnosis (CAD). Recent work has suggested that
               image classification CNNs may not generalize to new data as well
               as previously believed. We assessed how well CNNs generalized
               across three hospital systems for a simulated pneumonia
               screening task. METHODS AND FINDINGS: A cross-sectional design
               with multiple model training cohorts was used to evaluate model
               generalizability to external sites using split-sample
               validation. A total of 158,323 chest radiographs were drawn from
               three institutions: National Institutes of Health Clinical
               Center (NIH; 112,120 from 30,805 patients), Mount Sinai Hospital
               (MSH; 42,396 from 12,904 patients), and Indiana University
               Network for Patient Care (IU; 3,807 from 3,683 patients). These
               patient populations had an age mean (SD) of 46.9 years (16.6),
               63.2 years (16.5), and 49.6 years (17) with a female percentage
               of 43.5\%, 44.8\%, and 57.3\%, respectively. We assessed
               individual models using the area under the receiver operating
               characteristic curve (AUC) for radiographic findings consistent
               with pneumonia and compared performance on different test sets
               with DeLong's test. The prevalence of pneumonia was high enough
               at MSH (34.2\%) relative to NIH and IU (1.2\% and 1.0\%) that
               merely sorting by hospital system achieved an AUC of 0.861 (95\%
               CI 0.855-0.866) on the joint MSH-NIH dataset. Models trained on
               data from either NIH or MSH had equivalent performance on IU (P
               values 0.580 and 0.273, respectively) and inferior performance
               on data from each other relative to an internal test set (i.e.,
               new data from within the hospital system used for training data;
               P values both <0.001). The highest internal performance was
               achieved by combining training and test data from MSH and NIH
               (AUC 0.931, 95\% CI 0.927-0.936), but this model demonstrated
               significantly lower external performance at IU (AUC 0.815, 95\%
               CI 0.745-0.885, P = 0.001). To test the effect of pooling data
               from sites with disparate pneumonia prevalence, we used
               stratified subsampling to generate MSH-NIH cohorts that only
               differed in disease prevalence between training data sites. When
               both training data sites had the same pneumonia prevalence, the
               model performed consistently on external IU data (P = 0.88).
               When a 10-fold difference in pneumonia rate was introduced
               between sites, internal test performance improved compared to
               the balanced model (10$\times$ MSH risk P < 0.001; 10$\times$
               NIH P = 0.002), but this outperformance failed to generalize to
               IU (MSH 10$\times$ P < 0.001; NIH 10$\times$ P = 0.027). CNNs
               were able to directly detect hospital system of a radiograph for
               99.95\% NIH (22,050/22,062) and 99.98\% MSH (8,386/8,388)
               radiographs. The primary limitation of our approach and the
               available public data is that we cannot fully assess what other
               factors might be contributing to hospital system-specific
               biases. CONCLUSION: Pneumonia-screening CNNs achieved better
               internal than external performance in 3 out of 5 natural
               comparisons. When models were trained on pooled data from sites
               with different pneumonia prevalence, they performed better on
               new pooled data from these sites but not on external data. CNNs
               robustly identified hospital system and department within a
               hospital, which can have large differences in disease burden and
               may confound predictions.",
  journal   = "PLoS Med.",
  publisher = "journals.plos.org",
  volume    =  15,
  number    =  11,
  pages     = "e1002683",
  month     =  nov,
  year      =  2018,
  language  = "en"
}

@ARTICLE{Jack2014-ku,
  title     = "Dynamic facial expressions of emotion transmit an evolving
               hierarchy of signals over time",
  author    = "Jack, Rachael E and Garrod, Oliver G B and Schyns, Philippe G",
  abstract  = "Designed by biological and social evolutionary pressures, facial
               expressions of emotion comprise specific facial movements to
               support a near-optimal system of signaling and decoding.
               Although highly dynamical, little is known about the form and
               function of facial expression temporal dynamics. Do facial
               expressions transmit diagnostic signals simultaneously to
               optimize categorization of the six classic emotions, or
               sequentially to support a more complex communication system of
               successive categorizations over time? Our data support the
               latter. Using a combination of perceptual expectation modeling,
               information theory, and Bayesian classifiers, we show that
               dynamic facial expressions of emotion transmit an evolving
               hierarchy of ``biologically basic to socially specific''
               information over time. Early in the signaling dynamics, facial
               expressions systematically transmit few, biologically rooted
               face signals supporting the categorization of fewer elementary
               categories (e.g., approach/avoidance). Later transmissions
               comprise more complex signals that support categorization of a
               larger number of socially specific categories (i.e., the six
               classic emotions). Here, we show that dynamic facial expressions
               of emotion provide a sophisticated signaling system, questioning
               the widely accepted notion that emotion communication is
               comprised of six basic (i.e., psychologically irreducible)
               categories, and instead suggesting four.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  24,
  number    =  2,
  pages     = "187--192",
  month     =  jan,
  year      =  2014,
  language  = "en"
}

@ARTICLE{Holdgraf2017-eu,
  title     = "Encoding and Decoding Models in Cognitive Electrophysiology",
  author    = "Holdgraf, Christopher R and Rieger, Jochem W and Micheli,
               Cristiano and Martin, Stephanie and Knight, Robert T and
               Theunissen, Frederic E",
  abstract  = "Cognitive neuroscience has seen rapid growth in the size and
               complexity of data recorded from the human brain as well as in
               the computational tools available to analyze this data. This
               data explosion has resulted in an increased use of multivariate,
               model-based methods for asking neuroscience questions, allowing
               scientists to investigate multiple hypotheses with a single
               dataset, to use complex, time-varying stimuli, and to study the
               human brain under more naturalistic conditions. These tools come
               in the form of ``Encoding'' models, in which stimulus features
               are used to model brain activity, and ``Decoding'' models, in
               which neural features are used to generated a stimulus output.
               Here we review the current state of encoding and decoding models
               in cognitive electrophysiology and provide a practical guide
               towards conducting experiments and analyses in this emerging
               field. Our examples focus on using linear models in the study of
               human language and audition. We show how to calculate auditory
               receptive fields from natural sounds as well as how to decode
               neural recordings to predict speech. The paper aims to be a
               useful tutorial to these approaches, and a practical
               introduction to using machine learning and applied statistics to
               build models of neural activity. The data analytic approaches we
               discuss may also be applied to other sensory modalities, motor
               systems, and cognitive systems, and we cover some examples in
               these areas. In addition, a collection of Jupyter notebooks is
               publicly available as a complement to the material covered in
               this paper, providing code examples and tutorials for predictive
               modeling in python. The aim is to provide a practical
               understanding of predictive modeling of human brain data and to
               propose best-practices in conducting these analyses.",
  journal   = "Front. Syst. Neurosci.",
  publisher = "journal.frontiersin.org",
  volume    =  11,
  pages     = "61",
  year      =  2017,
  keywords  = "NeuroimagingMethods"
}

@UNPUBLISHED{Schrimpf2018-pz,
  title    = "{Brain-Score}: Which Artificial Neural Network for Object
              Recognition is most {Brain-Like}?",
  author   = "Schrimpf, Martin and Kubilius, Jonas and Hong, Ha and Majaj,
              Najib J and Rajalingham, Rishi and Issa, Elias B and Kar, Kohitij
              and Bashivan, Pouya and Prescott-Roy, Jonathan and Schmidt,
              Kailyn and Yamins, Daniel L K and DiCarlo, James J",
  abstract = "The internal representations of early deep artificial neural
              networks (ANNs) were found to be remarkably similar to the
              internal neural representations measured experimentally in the
              primate brain. Here we ask, as deep ANNs have continued to
              evolve, are they becoming more or less brain-like? ANNs that are
              most functionally similar to the brain will contain mechanisms
              that are most like those used by the brain. We therefore
              developed Brain-Score -- a composite of multiple neural and
              behavioral benchmarks that score any ANN on how similar it is to
              the brain's mechanisms for core object recognition -- and we
              deployed it to evaluate a wide range of state-of-the-art deep
              ANNs. Using this scoring system, we here report that: (1)
              DenseNet-169, CORnet-S and ResNet-101 are the most brain-like
              ANNs. There remains considerable variability in neural and
              behavioral responses that is not predicted by any ANN, suggesting
              that no ANN model has yet captured all the relevant mechanisms.
              (3) Extending prior work, we found that gains in ANN ImageNet
              performance led to gains on Brain-Score. However, correlation
              weakened at $\geq$ 70\% top-1 ImageNet performance, suggesting
              that additional guidance from neuroscience is needed to make
              further advances in capturing brain mechanisms. (4) We uncovered
              smaller (i.e. less complex) ANNs that are more brain-like than
              many of the best-performing ImageNet models, which suggests the
              opportunity to simplify ANNs to better understand the ventral
              stream. The scoring system used here is far from complete.
              However, we propose that evaluating and tracking model-benchmark
              correspondences through a Brain-Score that is regularly updated
              with new brain data is an exciting opportunity: experimental
              benchmarks can be used to guide machine network evolution, and
              machine networks are mechanistic hypotheses of the brain's
              network and thus drive next experiments. To facilitate both of
              these, we release Brain-Score.org: a platform that hosts the
              neural and behavioral benchmarks, where ANNs for visual
              processing can be submitted to receive a Brain-Score and their
              rank relative to other models, and where new experimental data
              can be naturally incorporated.",
  journal  = "bioRxiv",
  pages    = "407007",
  month    =  sep,
  year     =  2018,
  language = "en"
}

@ARTICLE{Keltner2019-tm,
  title     = "Emotional Expression: Advances in Basic Emotion Theory",
  author    = "Keltner, Dacher and Sauter, Disa and Tracy, Jessica and Cowen,
               Alan",
  abstract  = "In this article, we review recent developments in the study of
               emotional expression within a basic emotion framework. Dozens of
               new studies find that upwards of 20 emotions are signaled in
               multimodal and dynamic patterns of expressive behavior. Moving
               beyond word to stimulus matching paradigms, new studies are
               detailing the more nuanced and complex processes involved in
               emotion recognition and the structure of how people perceive
               emotional expression. Finally, we consider new studies
               documenting contextual influences upon emotion recognition. We
               conclude by extending these recent findings to questions about
               emotion-related physiology and the mammalian precursors of human
               emotion.",
  journal   = "J. Nonverbal Behav.",
  publisher = "Springer",
  volume    =  43,
  number    =  2,
  pages     = "133--160",
  month     =  jun,
  year      =  2019,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Scholte2018-he,
  title     = "Fantastic {DNimals} and where to find them",
  author    = "Scholte, H Steven",
  abstract  = "The introduction of deep neural networks (DNNs, Krizhevsky et
               al., 2012; Lecun et al., 1998) has altered the fields of
               computer vision and machine learning and these networks are
               starting to have an impact on the field of biological vision.
               Kendrick Kay's paper in this issue is therefore timely in
               addressing two important questions in this area, namely: i) how
               DNNs can be used to study vision, ii) how they relate to other
               modeling approaches. A central question Kay (2017) asks is how
               DNNs relate to the tri-level framework of Marr (1982) …",
  journal   = "Neuroimage",
  publisher = "pure.uva.nl",
  volume    =  180,
  number    = "Pt A",
  pages     = "112--113",
  month     =  oct,
  year      =  2018,
  language  = "en"
}

@ARTICLE{Kriegeskorte2015-qi,
  title     = "Deep Neural Networks: A New Framework for Modeling Biological
               Vision and Brain Information Processing",
  author    = "Kriegeskorte, Nikolaus",
  abstract  = "Recent advances in neural network modeling have enabled major
               strides in computer vision and other artificial intelligence
               applications. Human-level visual recognition abilities are
               coming within reach of artificial systems. Artificial neural
               networks are inspired by the brain, and their computations could
               be implemented in biological neurons. Convolutional feedforward
               networks, which now dominate computer vision, take further
               inspiration from the architecture of the primate visual
               hierarchy. However, the current models are designed with
               engineering goals, not to model brain computations.
               Nevertheless, initial studies comparing internal representations
               between these models and primate brains find surprisingly
               similar representational spaces. With human-level performance no
               longer out of reach, we are entering an exciting new era, in
               which we will be able to build biologically faithful feedforward
               and recurrent computational models of how biological brains
               perform high-level feats of intelligence, including vision.",
  journal   = "Annu Rev Vis Sci",
  publisher = "annualreviews.org",
  volume    =  1,
  pages     = "417--446",
  month     =  nov,
  year      =  2015,
  keywords  = "artificial intelligence; biological vision; computational
               neuroscience; computer vision; deep learning; neural network;
               object recognition",
  language  = "en"
}

@ARTICLE{Ekman1990-mg,
  title     = "The Duchenne smile: emotional expression and brain physiology.
               {II}",
  author    = "Ekman, P and Davidson, R J and Friesen, W V",
  abstract  = "Facial expression, EEG, and self-report of subjective emotional
               experience were recorded while subjects individually watched
               both pleasant and unpleasant films. Smiling in which the muscle
               that orbits the eye is active in addition to the muscle that
               pulls the lip corners up (the Duchenne smile) was compared with
               other smiling in which the muscle orbiting the eye was not
               active. As predicted, the Duchenne smile was related to
               enjoyment in terms of occurring more often during the pleasant
               than the unpleasant films, in measures of cerebral asymmetry,
               and in relation to subjective reports of positive emotions, and
               other smiling was not.",
  journal   = "J. Pers. Soc. Psychol.",
  publisher = "psycnet.apa.org",
  volume    =  58,
  number    =  2,
  pages     = "342--353",
  month     =  feb,
  year      =  1990,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Allen2021-zd,
  title     = "A massive {7T} {fMRI} dataset to bridge cognitive and
               computational neuroscience",
  author    = "Allen, E J and St-Yves, G and Wu, Y and Breedlove, J L and
               Dowdle, L T and {others}",
  abstract  = "Extensive sampling of neural activity during rich cognitive
               phenomena is critical for robust understanding of brain
               function. We present the Natural Scenes Dataset (NSD), in which
               high-resolution fMRI responses to tens of thousands of richly
               annotated natural scenes are measured while participants perform
               a continuous recognition task. To optimize data quality, we
               develop and apply novel estimation and denoising techniques.
               Simple visual inspections of the NSD data reveal clear
               representational transformations along the ventral visual …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021
}

@ARTICLE{Oosterwijk2017-dw,
  title     = "Choosing the negative: A behavioral demonstration of morbid
               curiosity",
  author    = "Oosterwijk, Suzanne",
  abstract  = "This paper examined, with a behavioral paradigm, to what extent
               people choose to view stimuli that portray death, violence or
               harm. Based on briefly presented visual cues, participants made
               choices between highly arousing, negative images and positive or
               negative alternatives. The negative images displayed social
               scenes that involved death, violence or harm (e.g., war scene),
               or decontextualized, close-ups of physical harm (e.g., mutilated
               face) or natural threat (e.g., attacking shark). The results
               demonstrated that social negative images were chosen
               significantly more often than other negative categories.
               Furthermore, participants preferred social negative images over
               neutral images. Physical harm images and natural threat images
               were not preferred over neutral images, but were chosen in about
               thirty-five percent of the trials. These results were replicated
               across three different studies, including a study that presented
               verbal descriptions of images as pre-choice cues. Together,
               these results show that people deliberately subject themselves
               to negative images. With this, the present paper demonstrates a
               dynamic relationship between negative information and behavior
               and advances new insights into the phenomenon of morbid
               curiosity.",
  journal   = "PLoS One",
  publisher = "journals.plos.org",
  volume    =  12,
  number    =  7,
  pages     = "e0178399",
  month     =  jul,
  year      =  2017,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Forstmann2015-rz,
  title     = "An Introduction to {Model-Based} Cognitive Neuroscience",
  author    = "Forstmann, Birte U and Wagenmakers, Eric-Jan",
  editor    = "Forstmann, Birte U and Wagenmakers, Eric-Jan",
  abstract  = "This is the first book on model-based cognitive neuroscience, a
               nascent field that is defined by a reciprocal relationship
               between cognitive neuroscience and behavioral mathematical
               modeling. Traditionally, cognitive neuroscience and behavioral
               modeling are separate …",
  publisher = "Springer, New York, NY",
  year      =  2015
}

@ARTICLE{Meehl1967-af,
  title     = "{Theory-Testing} in Psychology and Physics: A Methodological
               Paradox",
  author    = "Meehl, Paul E",
  abstract  = "Because physical theories typically predict numerical values, an
               improvement in experimental precision reduces the tolerance
               range and hence increases corroborability. In most psychological
               research, improved power of a statistical design leads to a
               prior probability approaching 1/2 of finding a significant
               difference in the theoretically predicted direction. Hence the
               corroboration yielded by ``success'' is very weak, and becomes
               weaker with increased precision. ``Statistical significance''
               plays a logical role in psychology precisely the reverse of its
               role in physics. This problem is worsened by certain unhealthy
               tendencies prevalent among psychologists, such as a premium
               placed on experimental ``cuteness'' and a free reliance upon ad
               hoc explanations to avoid refutation.",
  journal   = "Philos. Sci.",
  publisher = "journals.uchicago.edu",
  volume    =  34,
  number    =  2,
  pages     = "103--115",
  year      =  1967,
  keywords  = "TFBC"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Guest2020-ef,
  title     = "How computational modeling can force theory building in
               psychological science",
  author    = "Guest, Olivia and Martin, Andrea E",
  abstract  = "Psychology is a broad field that endeavors to develop
               explanatory theories of human capacities and behaviors based on
               a wide variety of methodologies and dependent measures. Here we
               argue that whether or not researchers choose to employ modeling
               (viz …",
  publisher = "PsyArXiv",
  year      =  2020
}

@ARTICLE{Nunez2019-lh,
  title     = "What happened to cognitive science?",
  author    = "N{\'u}{\~n}ez, Rafael and Allen, Michael and Gao, Richard and
               Miller Rigoli, Carson and Relaford-Doyle, Josephine and
               Semenuks, Arturs",
  abstract  = "More than a half-century ago, the 'cognitive revolution', with
               the influential tenet 'cognition is computation', launched the
               investigation of the mind through a multidisciplinary endeavour
               called cognitive science. Despite significant diversity of views
               regarding its definition and intended scope, this new science,
               explicitly named in the singular, was meant to have a cohesive
               subject matter, complementary methods and integrated theories.
               Multiple signs, however, suggest that over time the prospect of
               an integrated cohesive science has not materialized. Here we
               investigate the status of the field in a data-informed manner,
               focusing on four indicators, two bibliometric and two
               socio-institutional. These indicators consistently show that the
               devised multi-disciplinary program failed to transition to a
               mature inter-disciplinary coherent field. Bibliometrically, the
               field has been largely subsumed by (cognitive) psychology, and
               educationally, it exhibits a striking lack of curricular
               consensus, raising questions about the future of the cognitive
               science enterprise.",
  journal   = "Nat Hum Behav",
  publisher = "nature.com",
  volume    =  3,
  number    =  8,
  pages     = "782--791",
  month     =  aug,
  year      =  2019,
  language  = "en"
}

@ARTICLE{Poldrack2014-ov,
  title     = "Making big data open: data sharing in neuroimaging",
  author    = "Poldrack, Russell A and Gorgolewski, Krzysztof J",
  abstract  = "In the last decade, major advances have been made in the
               availability of shared neuroimaging data, such that there are
               more than 8,000 shared MRI (magnetic resonance imaging) data
               sets available online. Here we outline the state of data sharing
               for task-based functional MRI (fMRI) data, with a focus on
               various forms of data and their relative utility for subsequent
               analyses. We also discuss challenges to the future success of
               data sharing and highlight the ethical argument that data
               sharing may be necessary to maximize the contribution of human
               subjects.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  17,
  number    =  11,
  pages     = "1510--1517",
  month     =  nov,
  year      =  2014,
  language  = "en"
}

@ARTICLE{Cichy2019-zf,
  title     = "Deep Neural Networks as Scientific Models",
  author    = "Cichy, Radoslaw M and Kaiser, Daniel",
  abstract  = "Artificial deep neural networks (DNNs) initially inspired by the
               brain enable computers to solve cognitive tasks at which humans
               excel. In the absence of explanations for such cognitive
               phenomena, in turn cognitive scientists have started using DNNs
               as models to investigate biological cognition and its neural
               basis, creating heated debate. Here, we reflect on the case from
               the perspective of philosophy of science. After putting DNNs as
               scientific models into context, we discuss how DNNs can
               fruitfully contribute to cognitive science. We claim that beyond
               their power to provide predictions and explanations of cognitive
               phenomena, DNNs have the potential to contribute to an often
               overlooked but ubiquitous and fundamental use of scientific
               models: exploration.",
  journal   = "Trends Cogn. Sci.",
  publisher = "Elsevier",
  volume    =  23,
  number    =  4,
  pages     = "305--317",
  month     =  apr,
  year      =  2019,
  keywords  = "deep learning; explanation; exploration; neural network;
               prediction; scientific model",
  language  = "en"
}

@INCOLLECTION{Newell1973-no,
  title     = "You can't play 20 questions with nature and win: Projective
               comments on the papers of this symposium",
  booktitle = "Visual Information Processing",
  author    = "Newell, Allen",
  editor    = "Chase, W G",
  publisher = "New York: Academic Press",
  year      =  1973,
  address   = "New York"
}

@ARTICLE{Hirschberg2015-fr,
  title     = "Advances in natural language processing",
  author    = "Hirschberg, Julia and Manning, Christopher D",
  abstract  = "Natural language processing employs computational techniques for
               the purpose of learning, understanding, and producing human
               language content. Early computational approaches to language
               research focused on automating the analysis of the linguistic
               structure of language and developing basic technologies such as
               machine translation, speech recognition, and speech synthesis.
               Today's researchers refine and make use of such tools in
               real-world applications, creating spoken dialogue systems and
               speech-to-speech translation engines, mining social media for
               information about health or finance, and identifying sentiment
               and emotion toward products and services. We describe successes
               and challenges in this rapidly advancing area.",
  journal   = "Science",
  publisher = "science.sciencemag.org",
  volume    =  349,
  number    =  6245,
  pages     = "261--266",
  month     =  jul,
  year      =  2015,
  language  = "en"
}

@BOOK{Gescheider2013-zm,
  title     = "Psychophysics: The Fundamentals",
  author    = "Gescheider, George A",
  abstract  = "This third edition of a classic text which was first published
               in 1976 is the only comprehensive, up-to-date presentation of
               psychophysics currently available. It has been used by
               undergraduate and graduate students, and scholars throughout the
               world and is consistently thought of as the best single source
               for learning the basic principles of psychophysics. The coverage
               of the field is comprehensive, including topics ranging from the
               classical methods of threshold measurement, to the modern
               methods of detection theory, to psychophysical scaling of
               sensation magnitude. The approach is one in which methods,
               theories, and applications are described for each experimental
               procedure. New features found in this third edition include: *
               methodological and theoretical contributions made in the field
               during this time period, * descriptions of adaptive procedures
               for measuring thresholds, context effects in scaling, theory of
               quantal fluctuations, multidimensional scaling, nonmetric
               scaling of sensory differences, and the relationship between the
               size of the DL and the slope of the sensation magnitude
               function, * new methods for measuring the observer's sensitivity
               of criterion and an expanded discussion of category scaling
               including the range frequency model and verbally labeled
               categories, and * methods used to control the observer's
               nonlinear use of numbers in magnitude estimation such as
               line-length scaling, magnitude matching, master scaling, and
               category-ratio scaling.",
  publisher = "Psychology Press",
  month     =  jun,
  year      =  2013,
  language  = "en"
}

@ARTICLE{Klein2018-un,
  title     = "Many Labs 2: Investigating Variation in Replicability Across
               Samples and Settings",
  author    = "Klein, Richard A and Vianello, Michelangelo and Hasselman, Fred
               and Adams, Byron G and Adams, Reginald B and Alper, Sinan and
               Aveyard, Mark and Axt, Jordan R and Babalola, Mayowa T and
               Bahn{\'\i}k, {\v S}t{\v e}p{\'a}n and Batra, Rishtee and
               Berkics, Mih{\'a}ly and Bernstein, Michael J and Berry, Daniel R
               and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad
               and Brandt, Mark J and Busching, Robert and R{\'e}dei, Anna
               Cabak and Cai, Huajian and Cambier, Fanny and Cantarero,
               Katarzyna and Carmichael, Cheryl L and Ceric, Francisco and
               Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen,
               Eva E and Cheong, Winnee and Cicero, David C and Coen, Sharon
               and Coleman, Jennifer A and Collisson, Brian and Conway, Morgan
               A and Corker, Katherine S and Curran, Paul G and Cushman, Fiery
               and Dagona, Zubairu K and Dalgar, Ilker and Dalla Rosa, Anna and
               Davis, William E and de Bruijn, Maaike and De Schutter, Leander
               and Devos, Thierry and de Vries, Marieke and Do{\u g}ulu, Canay
               and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow
               and Durrheim, Kevin and Ebersole, Charles R and Edlund, John E
               and Eller, Anja and English, Alexander Scott and Finck, Carolyn
               and Frankowska, Natalia and Freyre, Miguel-{\'A}ngel and
               Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C and
               Ghoshal, Tanuka and Giessner, Steffen R and Gill, Tripat and
               Gnambs, Timo and G{\'o}mez, {\'A}ngel and Gonz{\'a}lez, Roberto
               and Graham, Jesse and Grahe, Jon E and Grahek, Ivan and Green,
               Eva G T and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth
               L and Hall, Michael P and Heffernan, Marie E and Hicks, Joshua A
               and Houdek, Petr and Huntsinger, Jeffrey R and Huynh, Ho Phi and
               IJzerman, Hans and Inbar, Yoel and Innes-Ker, {\AA}se H and
               Jim{\'e}nez-Leal, William and John, Melissa-Sue and Joy-Gaba,
               Jennifer A and Kamilo{\u g}lu, Roza G and Kappes, Heather Barry
               and Karabati, Serdar and Karick, Haruna and Keller, Victor N and
               Kende, Anna and Kervyn, Nicolas and Kne{\v z}evi{\'c}, Goran and
               Kovacs, Carrie and Krueger, Lacy E and Kurapov, German and
               Kurtz, Jamie and Lakens, Dani{\"e}l and Lazarevi{\'c}, Ljiljana
               B and Levitan, Carmel A and Lewis, Neil A and Lins, Samuel and
               Lipsey, Nikolette P and Losee, Joy E and Maassen, Esther and
               Maitner, Angela T and Malingumu, Winfrida and Mallett, Robyn K
               and Marotta, Satia A and Me{\dj}edovi{\'c}, Janko and
               Mena-Pacheco, Fernando and Milfont, Taciano L and Morris, Wendy
               L and Murphy, Sean C and Myachykov, Andriy and Neave, Nick and
               Neijenhuijs, Koen and Nelson, Anthony J and Neto, F{\'e}lix and
               Lee Nichols, Austin and Ocampo, Aaron and O'Donnell, Susan L and
               Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz,
               G{\'a}bor and Osowiecka, Malgorzata and Packard, Grant and
               P{\'e}rez-S{\'a}nchez, Rolando and Petrovi{\'c}, Boban and
               Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and
               Pogge, Gabrielle and Pollmann, Monique M H and Rutchick, Abraham
               M and Saavedra, Patricio and Saeri, Alexander K and Salomon,
               Erika and Schmidt, Kathleen and Sch{\"o}nbrodt, Felix D and
               Sekerdej, Maciej B and Sirlop{\'u}, David and Skorinko, Jeanine
               L M and Smith, Michael A and Smith-Castro, Vanessa and Smolders,
               Karin C H J and Sobkow, Agata and Sowden, Walter and Spachtholz,
               Philipp and Srivastava, Manini and Steiner, Troy G and Stouten,
               Jeroen and Street, Chris N H and Sundfelt, Oskar K and Szeto,
               Stephanie and Szumowska, Ewa and Tang, Andrew C W and Tanzer,
               Norbert and Tear, Morgan J and Theriault, Jordan and Thomae,
               Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M
               and Ujhelyi, Adrienn and van Aert, Robbie C M and van Assen,
               Marcel A L M and van der Hulst, Marije and van Lange, Paul A M
               and van 't Veer, Anna Elisabeth and V{\'a}squez-
               Echeverr{\'\i}a, Alejandro and Ann Vaughn, Leigh and
               V{\'a}zquez, Alexandra and Vega, Luis Diego and Verniers,
               Catherine and Verschoor, Mark and Voermans, Ingrid P J and
               Vranka, Marek A and Welch, Cheryl and Wichman, Aaron L and
               Williams, Lisa A and Wood, Michael and Woodzicka, Julie A and
               Wronska, Marta K and Young, Liane and Zelenski, John M and
               Zhijia, Zeng and Nosek, Brian A",
  abstract  = "We conducted preregistered replications of 28 classic and
               contemporary published findings, with protocols that were peer
               reviewed in advance, to examine variation in effect magnitudes
               across samples and settings. Each protocol was administered to
               approximately half of 125 samples that comprised 15,305
               participants from 36 countries and territories. Using the
               conventional criterion of statistical significance (p < .05), we
               found that 15 (54\%) of the replications provided evidence of a
               statistically significant effect in the same direction as the
               original finding. With a strict significance criterion (p <
               .0001), 14 (50\%) of the replications still provided such
               evidence, a reflection of the extremely high-powered design.
               Seven (25\%) of the replications yielded effect sizes larger
               than the original ones, and 21 (75\%) yielded effect sizes
               smaller than the original ones. The median comparable Cohen?s ds
               were 0.60 for the original findings and 0.15 for the
               replications. The effect sizes were small (< 0.20) in 16 of the
               replications (57\%), and 9 effects (32\%) were in the direction
               opposite the direction of the original effect. Across settings,
               the Q statistic indicated significant heterogeneity in 11 (39\%)
               of the replication effects, and most of those were among the
               findings with the largest overall effect sizes; only 1 effect
               that was near zero in the aggregate showed significant
               heterogeneity according to this measure. Only 1 effect had a tau
               value greater than .20, an indication of moderate heterogeneity.
               Eight others had tau values near or slightly above .10, an
               indication of slight heterogeneity. Moderation tests indicated
               that very little heterogeneity was attributable to the order in
               which the tasks were performed or whether the tasks were
               administered in lab versus online. Exploratory comparisons
               revealed little heterogeneity between Western, educated,
               industrialized, rich, and democratic (WEIRD) cultures and less
               WEIRD cultures (i.e., cultures with relatively high and low
               WEIRDness scores, respectively). Cumulatively, variability in
               the observed effect sizes was attributable more to the effect
               being studied than to the sample or setting in which it was
               studied.",
  journal   = "Advances in Methods and Practices in Psychological Science",
  publisher = "SAGE Publications Inc",
  volume    =  1,
  number    =  4,
  pages     = "443--490",
  month     =  dec,
  year      =  2018
}

@ARTICLE{Guclu2015-qj,
  title     = "Deep Neural Networks Reveal a Gradient in the Complexity of
               Neural Representations across the Ventral Stream",
  author    = "G{\"u}{\c c}l{\"u}, Umut and van Gerven, Marcel A J",
  abstract  = "Converging evidence suggests that the primate ventral visual
               pathway encodes increasingly complex stimulus features in
               downstream areas. We quantitatively show that there indeed
               exists an explicit gradient for feature complexity in the
               ventral pathway of the human brain. This was achieved by mapping
               thousands of stimulus features of increasing complexity across
               the cortical sheet using a deep neural network. Our approach
               also revealed a fine-grained functional specialization of
               downstream areas of the ventral stream. Furthermore, it allowed
               decoding of representations from human brain activity at an
               unsurpassed degree of accuracy, confirming the quality of the
               developed approach. Stimulus features that successfully
               explained neural responses indicate that population receptive
               fields were explicitly tuned for object categorization. This
               provides strong support for the hypothesis that object
               categorization is a guiding principle in the functional
               organization of the primate ventral stream.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  35,
  number    =  27,
  pages     = "10005--10014",
  month     =  jul,
  year      =  2015,
  keywords  = "deep learning; functional magnetic resonance imaging; neural
               coding",
  language  = "en"
}

@ARTICLE{Turner2017-fi,
  title     = "Approaches to Analysis in Model-based Cognitive Neuroscience",
  author    = "Turner, Brandon M and Forstmann, Birte U and Love, Bradley C and
               Palmeri, Thomas J and Van Maanen, Leendert",
  abstract  = "Our understanding of cognition has been advanced by two
               traditionally nonoverlapping and non-interacting groups.
               Mathematical psychologists rely on behavioral data to evaluate
               formal models of cognition, whereas cognitive neuroscientists
               rely on statistical models to understand patterns of neural
               activity, often without any attempt to make a connection to the
               mechanism supporting the computation. Both approaches suffer
               from critical limitations as a direct result of their focus on
               data at one level of analysis (cf. Marr, 1982), and these
               limitations have inspired researchers to attempt to combine both
               neural and behavioral measures in a cross-level integrative
               fashion. The importance of solving this problem has spawned
               several entirely new theoretical and statistical frameworks
               developed by both mathematical psychologists and cognitive
               neuroscientists. However, with each new approach comes a
               particular set of limitations and benefits. In this article, we
               survey and characterize several approaches for linking brain and
               behavioral data. We organize these approaches on the basis of
               particular cognitive modeling goals: (1) using the neural data
               to constrain a behavioral model, (2) using the behavioral model
               to predict neural data, and (3) fitting both neural and
               behavioral data simultaneously. Within each goal, we highlight a
               few particularly successful approaches for accomplishing that
               goal, and discuss some applications. Finally, we provide a
               conceptual guide to choosing among various analytic approaches
               in performing model-based cognitive neuroscience.",
  journal   = "J. Math. Psychol.",
  publisher = "Elsevier",
  volume    =  76,
  number    = "B",
  pages     = "65--79",
  month     =  feb,
  year      =  2017,
  keywords  = "analysis methods; linking; model-based cognitive neuroscience",
  language  = "en"
}

@UNPUBLISHED{Dinga2020-si,
  title    = "Controlling for effects of confounding variables on machine
              learning predictions",
  author   = "Dinga, Richard and Schmaal, Lianne and Penninx, Brenda W J and
              Veltman, Dick J and Marquand, Andre F",
  abstract = "Machine learning predictive models are being used in neuroimaging
              to predict information about the task or stimuli or to identify
              potentially clinically useful biomarkers. However, the
              predictions can be driven by confounding variables unrelated to
              the signal of interest, such as scanner effect or head motion,
              limiting the clinical usefulness and interpretation of machine
              learning models. The most common method to control for
              confounding effects is regressing out the confounding variables
              separately from each input variable before machine learning
              modeling. However, we show that this method is insufficient
              because machine learning models can learn information from the
              data that cannot be regressed out. Instead of regressing out
              confounding effects from each input variable, we propose
              controlling for confounds post-hoc on the level of machine
              learning predictions. This allows partitioning of the predictive
              performance into the performance that can be explained by
              confounds and performance independent of confounds. This approach
              is flexible and allows for parametric and non-parametric confound
              adjustment. We show in real and simulated data that this method
              correctly controls for confounding effects even when traditional
              input variable adjustment produces false-positive findings.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.08.17.255034",
  month    =  aug,
  year     =  2020,
  language = "en"
}

@ARTICLE{Norman2006-bt,
  title    = "Beyond mind-reading: multi-voxel pattern analysis of {fMRI} data",
  author   = "Norman, Kenneth A and Polyn, Sean M and Detre, Greg J and Haxby,
              James V",
  abstract = "A key challenge for cognitive neuroscience is determining how
              mental representations map onto patterns of neural activity.
              Recently, researchers have started to address this question by
              applying sophisticated pattern-classification algorithms to
              distributed (multi-voxel) patterns of functional MRI data, with
              the goal of decoding the information that is represented in the
              subject's brain at a particular point in time. This multi-voxel
              pattern analysis (MVPA) approach has led to several impressive
              feats of mind reading. More importantly, MVPA methods constitute
              a useful new tool for advancing our understanding of neural
              information processing. We review how researchers are using MVPA
              methods to characterize neural coding and information processing
              in domains ranging from visual perception to memory search.",
  journal  = "Trends Cogn. Sci.",
  volume   =  10,
  number   =  9,
  pages    = "424--430",
  month    =  sep,
  year     =  2006,
  language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pearl2019-mm,
  title     = "The limitations of opaque learning machines",
  author    = "Pearl, Judea",
  abstract  = "As a former physicist, I was extremely interested in
               cybernetics. Though it did not utilize the full power of Turing
               Machines, it was highly transparent, perhaps because it was
               founded on classical control theory and information theory. We
               are losing this transparency now, with the …",
  journal   = "Possible minds: twenty-five ways of looking at AI",
  publisher = "cs.ucla.edu",
  pages     = "13--19",
  year      =  2019
}

@ARTICLE{Ekman1969-pu,
  title     = "Pan-cultural elements in facial displays of emotion",
  author    = "Ekman, P and Sorenson, E R and Friesen, W V",
  abstract  = "Observers in both literate and preliterate cultures chose the
               predicted emotion for photographs of the face, although
               agreement was higher in the literate samples. These findings
               suggest that the pan-cultural element in facial displays of
               emotion is the association between facial muscular movements and
               discrete primary emotions, although cultures may still differ in
               what evokes an emotion, in rules for controlling the display of
               emotion, and in behavioral consequences.",
  journal   = "Science",
  publisher = "science.sciencemag.org",
  volume    =  164,
  number    =  3875,
  pages     = "86--88",
  month     =  apr,
  year      =  1969,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gewin2016-ff,
  title     = "Data sharing: An open mind on open data",
  author    = "Gewin, Virginia",
  abstract  = "… According to social psychologist Brian Nosek , executive
               director of the Center for Open Science, the average data
               -sharing rate for the journal Psychological Science, which uses
               the badges, increased tenfold to 38\% from 2013 to 2015 …",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  529,
  number    =  7584,
  pages     = "117--119",
  month     =  jan,
  year      =  2016,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Peelen2007-ew,
  title     = "Using multi-voxel pattern analysis of {fMRI} data to interpret
               overlapping functional activations",
  author    = "Peelen, Marius V and Downing, Paul E",
  abstract  = "… Patterns of fMRI activation can be used to discriminate
               cognitive states (sometimes called 'mind reading … Here, we
               point out an additional use of MVPA : its ability to interpret
               over- lapping … In a common-coding interpre- tation, the shared
               region is thought to contain neurons that are …",
  journal   = "Trends Cogn. Sci.",
  publisher = "academia.edu",
  volume    =  11,
  number    =  1,
  pages     = "4--5",
  month     =  jan,
  year      =  2007,
  language  = "en"
}

@ARTICLE{Moshontz2018-rc,
  title     = "The Psychological Science Accelerator: Advancing Psychology
               through a Distributed Collaborative Network",
  author    = "Moshontz, Hannah and Campbell, Lorne and Ebersole, Charles R and
               IJzerman, Hans and Urry, Heather L and Forscher, Patrick S and
               Grahe, Jon E and McCarthy, Randy J and Musser, Erica D and
               Antfolk, Jan and Castille, Christopher M and Evans, Thomas Rhys
               and Fiedler, Susann and Flake, Jessica Kay and Forero, Diego A
               and Janssen, Steve M J and Keene, Justin Robert and Protzko,
               John and Aczel, Balazs and Solas, Sara {\'A}lvarez and Ansari,
               Daniel and Awlia, Dana and Baskin, Ernest and Batres, Carlota
               and Borras-Guevara, Martha Lucia and Brick, Cameron and Chandel,
               Priyanka and Chatard, Armand and Chopik, William J and Clarance,
               David and Coles, Nicholas A and Corker, Katherine S and Dixson,
               Barnaby James Wyld and Dranseika, Vilius and Dunham, Yarrow and
               Fox, Nicholas W and Gardiner, Gwendolyn and Garrison, S Mason
               and Gill, Tripat and Hahn, Amanda C and Jaeger, Bastian and
               Ka{\v c}m{\'a}r, Pavol and Kaminski, Gwena{\"e}l and Kanske,
               Philipp and Kekecs, Zoltan and Kline, Melissa and Koehn, Monica
               A and Kujur, Pratibha and Levitan, Carmel A and Miller, Jeremy K
               and Okan, Ceylan and Olsen, Jerome and Oviedo-Trespalacios,
               Oscar and {\"O}zdo{\u g}ru, Asil Ali and Pande, Babita and
               Parganiha, Arti and Parveen, Noorshama and Pfuhl, Gerit and
               Pradhan, Sraddha and Ropovik, Ivan and Rule, Nicholas O and
               Saunders, Blair and Schei, Vidar and Schmidt, Kathleen and
               Singh, Margaret Messiah and Sirota, Miroslav and Steltenpohl,
               Crystal N and Stieger, Stefan and Storage, Daniel and Sullivan,
               Gavin Brent and Szabelska, Anna and Tamnes, Christian K and
               Vadillo, Miguel A and Valentova, Jaroslava V and Vanpaemel, Wolf
               and Varella, Marco A C and Vergauwe, Evie and Verschoor, Mark
               and Vianello, Michelangelo and Voracek, Martin and Williams,
               Glenn P and Wilson, John Paul and Zickfeld, Janis H and Arnal,
               Jack D and Aydin, Burak and Chen, Sau-Chin and DeBruine, Lisa M
               and Fernandez, Ana Maria and Horstmann, Kai T and Isager, Peder
               M and Jones, Benedict and Kapucu, Aycan and Lin, Hause and
               Mensink, Michael C and Navarrete, Gorka and Silan, Miguel A and
               Chartier, Christopher R",
  abstract  = "Concerns have been growing about the veracity of psychological
               research. Many findings in psychological science are based on
               studies with insufficient statistical power and
               nonrepresentative samples, or may otherwise be limited to
               specific, ungeneralizable settings or populations. Crowdsourced
               research, a type of large-scale collaboration in which one or
               more research projects are conducted across multiple lab sites,
               offers a pragmatic solution to these and other current
               methodological challenges. The Psychological Science Accelerator
               (PSA) is a distributed network of laboratories designed to
               enable and support crowdsourced research projects. These
               projects can focus on novel research questions, or attempt to
               replicate prior research, in large, diverse samples. The PSA's
               mission is to accelerate the accumulation of reliable and
               generalizable evidence in psychological science. Here, we
               describe the background, structure, principles, procedures,
               benefits, and challenges of the PSA. In contrast to other
               crowdsourced research networks, the PSA is ongoing (as opposed
               to time-limited), efficient (in terms of re-using structures and
               principles for different projects), decentralized, diverse (in
               terms of participants and researchers), and inclusive (of
               proposals, contributions, and other relevant input from anyone
               inside or outside of the network). The PSA and other approaches
               to crowdsourced psychological science will advance our
               understanding of mental processes and behaviors by enabling
               rigorous research and systematically examining its
               generalizability.",
  journal   = "Adv Methods Pract Psychol Sci",
  publisher = "journals.sagepub.com",
  volume    =  1,
  number    =  4,
  pages     = "501--515",
  month     =  dec,
  year      =  2018,
  keywords  = "Psychological Science Accelerator; crowdsourcing;
               generalizability; large-scale collaboration; theory development",
  language  = "en"
}

@ARTICLE{Ebersole2016-cr,
  title     = "Many Labs 3: Evaluating participant pool quality across the
               academic semester via replication",
  author    = "Ebersole, Charles R and Atherton, Olivia E and Belanger, Aimee L
               and Skulborstad, Hayley M and Allen, Jill M and Banks, Jonathan
               B and Baranski, Erica and Bernstein, Michael J and Bonfiglio,
               Diane B V and Boucher, Leanne and Brown, Elizabeth R and
               Budiman, Nancy I and Cairo, Athena H and Capaldi, Colin A and
               Chartier, Christopher R and Chung, Joanne M and Cicero, David C
               and Coleman, Jennifer A and Conway, John G and Davis, William E
               and Devos, Thierry and Fletcher, Melody M and German, Komi and
               Grahe, Jon E and Hermann, Anthony D and Hicks, Joshua A and
               Honeycutt, Nathan and Humphrey, Brandon and Janus, Matthew and
               Johnson, David J and Joy-Gaba, Jennifer A and Juzeler, Hannah
               and Keres, Ashley and Kinney, Diana and Kirshenbaum, Jacqeline
               and Klein, Richard A and Lucas, Richard E and Lustgraaf,
               Christopher J N and Martin, Daniel and Menon, Madhavi and
               Metzger, Mitchell and Moloney, Jaclyn M and Morse, Patrick J and
               Prislin, Radmila and Razza, Timothy and Re, Daniel E and Rule,
               Nicholas O and Sacco, Donald F and Sauerberger, Kyle and
               Shrider, Emily and Shultz, Megan and Siemsen, Courtney and
               Sobocko, Karin and Weylin Sternglanz, R and Summerville, Amy and
               Tskhay, Konstantin O and van Allen, Zack and Vaughn, Leigh Ann
               and Walker, Ryan J and Weinberg, Ashley and Wilson, John Paul
               and Wirth, James H and Wortman, Jessica and Nosek, Brian A",
  abstract  = "The university participant pool is a key resource for behavioral
               research, and data quality is believed to vary over the course
               of the academic semester. This crowdsourced project examined
               time of semester variation in 10 known effects, 10 individual
               differences, and 3 data quality indicators over the course of
               the academic semester in 20 participant pools (N=2696) and with
               an online sample (N=737). Weak time of semester effects were
               observed on data quality indicators, participant sex, and a few
               individual differences---conscientiousness, mood, and stress.
               However, there was little evidence for time of semester
               qualifying experimental or correlational effects. The generality
               of this evidence is unknown because only a subset of the tested
               effects demonstrated evidence for the original result in the
               whole sample. Mean characteristics of pool samples change
               slightly during the semester, but these data suggest that those
               changes are mostly irrelevant for detecting effects.",
  journal   = "J. Exp. Soc. Psychol.",
  publisher = "Elsevier",
  volume    =  67,
  pages     = "68--82",
  month     =  nov,
  year      =  2016,
  keywords  = "Social psychology; Cognitive psychology; Replication;
               Participant pool; Individual differences; Sampling effects;
               Situational effects"
}

@ARTICLE{Russakovsky2015-oo,
  title     = "{ImageNet} Large Scale Visual Recognition Challenge",
  author    = "Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan
               and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and
               Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and
               Berg, Alexander C and Fei-Fei, Li",
  abstract  = "The ImageNet Large Scale Visual Recognition Challenge is a
               benchmark in object category classification and detection on
               hundreds of object categories and millions of images. The
               challenge has been run annually from 2010 to present, attracting
               participation from more than fifty institutions. This paper
               describes the creation of this benchmark dataset and the
               advances in object recognition that have been possible as a
               result. We discuss the challenges of collecting large-scale
               ground truth annotation, highlight key breakthroughs in
               categorical object recognition, provide a detailed analysis of
               the current state of the field of large-scale image
               classification and object detection, and compare the
               state-of-the-art computer vision accuracy with human accuracy.
               We conclude with lessons learned in the 5 years of the
               challenge, and propose future directions and improvements.",
  journal   = "Int. J. Comput. Vis.",
  publisher = "Springer",
  volume    =  115,
  number    =  3,
  pages     = "211--252",
  month     =  dec,
  year      =  2015
}

@ARTICLE{Varoquaux2014-su,
  title     = "How machine learning is shaping cognitive neuroimaging",
  author    = "Varoquaux, Gael and Thirion, Bertrand",
  abstract  = "Functional brain images are rich and noisy data that can capture
               indirect signatures of neural activity underlying cognition in a
               given experimental setting. Can data mining leverage them to
               build models of cognition? Only if it is applied to well-posed
               questions, crafted to reveal cognitive mechanisms. Here we
               review how predictive models have been used on neuroimaging data
               to ask new questions, i.e., to uncover new aspects of cognitive
               organization. We also give a statistical learning perspective on
               these progresses and on the remaining gaping holes.",
  journal   = "Gigascience",
  publisher = "academic.oup.com",
  volume    =  3,
  pages     = "28",
  month     =  nov,
  year      =  2014,
  keywords  = "Cognition; Decoding; Encoding; Machine learning; Neuroimaging;
               fMRI",
  language  = "en"
}

@ARTICLE{Oosterwijk2020-uf,
  title     = "Choosing to view morbid information involves reward circuitry",
  author    = "Oosterwijk, Suzanne and Snoek, Lukas and Tekoppele, Jurriaan and
               Engelbert, Lara H and Scholte, H Steven",
  abstract  = "People often seek out stories, videos or images that detail
               death, violence or harm. Considering the ubiquity of this
               behavior, it is surprising that we know very little about the
               neural circuits involved in choosing negative information. Using
               fMRI, the present study shows that choosing intensely negative
               stimuli engages similar brain regions as those that support
               extrinsic incentives and ``regular'' curiosity. Participants
               made choices to view negative and positive images, based on
               negative (e.g., a soldier kicks a civilian against his head) and
               positive (e.g., children throw flower petals at a wedding)
               verbal cues. We hypothesized that the conflicting, but
               relatively informative act of choosing to view a negative image,
               resulted in stronger activation of reward circuitry as opposed
               to the relatively uncomplicated act of choosing to view a
               positive stimulus. Indeed, as preregistered, we found that
               choosing negative cues was associated with activation of the
               striatum, inferior frontal gyrus, anterior insula, and anterior
               cingulate cortex, both when contrasting against a passive
               viewing condition, and when contrasting against positive cues.
               These findings nuance models of decision-making, valuation and
               curiosity, and are an important starting point when considering
               the value of seeking out negative content.",
  journal   = "Sci. Rep.",
  publisher = "nature.com",
  volume    =  10,
  number    =  1,
  pages     = "15291",
  month     =  sep,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Geirhos2020-af,
  title     = "Shortcut learning in deep neural networks",
  author    = "Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis,
               Claudio and Zemel, Richard and Brendel, Wieland and Bethge,
               Matthias and Wichmann, Felix A",
  abstract  = "Deep learning has triggered the current rise of artificial
               intelligence and is the workhorse of today's machine
               intelligence. Numerous success stories have rapidly spread all
               over science, industry and society, but its limitations have
               only recently come into focus. In this Perspective we seek to
               distil how many of deep learning's failures can be seen as
               different symptoms of the same underlying problem: shortcut
               learning. Shortcuts are decision rules that perform well on
               standard benchmarks but fail to transfer to more challenging
               testing conditions, such as real-world scenarios. Related issues
               are known in comparative psychology, education and linguistics,
               suggesting that shortcut learning may be a common characteristic
               of learning systems, biological and artificial alike. Based on
               these observations, we develop a set of recommendations for
               model interpretation and benchmarking, highlighting recent
               advances in machine learning to improve robustness and
               transferability from the lab to real-world applications. Deep
               learning has resulted in impressive achievements, but under what
               circumstances does it fail, and why? The authors propose that
               its failures are a consequence of shortcut learning, a common
               characteristic across biological and artificial systems in which
               strategies that appear to have solved a problem fail
               unexpectedly under different circumstances.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  2,
  number    =  11,
  pages     = "665--673",
  month     =  nov,
  year      =  2020,
  language  = "en"
}

@UNPUBLISHED{Yarkoni2019-fe,
  title    = "The Generalizability Crisis",
  author   = "Yarkoni, Tal",
  abstract = "Most theories and hypotheses in psychology are verbal in nature,
              yet their evaluation overwhelmingly relies on inferential
              statistical procedures. The validity of the move from qualitative
              to quantitative analysis depends on the verbal and statistical
              expressions of a hypothesis being closely aligned---that is, that
              the two must refer to roughly the same set of hypothetical
              observations. Here I argue that most inferential statistical
              tests in psychology fail to meet this basic condition. I
              demonstrate how foundational assumptions of the ``random
              effects'' model used pervasively in psychology impose far
              stronger constraints on the generalizability of results than most
              researchers appreciate. Ignoring these constraints dramatically
              inflates false positive rates and routinely leads researchers to
              draw sweeping verbal generalizations that lack any meaningful
              connection to the statistical quantities they are putatively
              based on. I argue that the routine failure to consider the
              generalizability of one's conclusions from a statistical
              perspective lies at the root of many of psychology's ongoing
              problems (e.g., the replication crisis), and conclude with a
              discussion of several potential avenues for improvement.",
  month    =  nov,
  year     =  2019,
  keywords = "generalization; inference; philosophy of science; prediction;
              psychology; random effects; statistics"
}

@ARTICLE{Barrett2019-bc,
  title     = "Emotional Expressions Reconsidered: Challenges to Inferring
               Emotion From Human Facial Movements",
  author    = "Barrett, Lisa Feldman and Adolphs, Ralph and Marsella, Stacy and
               Martinez, Aleix M and Pollak, Seth D",
  abstract  = "It is commonly assumed that a person's emotional state can be
               readily inferred from his or her facial movements, typically
               called emotional expressions or facial expressions. This
               assumption influences legal judgments, policy decisions,
               national security protocols, and educational practices; guides
               the diagnosis and treatment of psychiatric illness, as well as
               the development of commercial applications; and pervades
               everyday social interactions as well as research in other
               scientific fields such as artificial intelligence, neuroscience,
               and computer vision. In this article, we survey examples of this
               widespread assumption, which we refer to as the common view, and
               we then examine the scientific evidence that tests this view,
               focusing on the six most popular emotion categories used by
               consumers of emotion research: anger, disgust, fear, happiness,
               sadness, and surprise. The available scientific evidence
               suggests that people do sometimes smile when happy, frown when
               sad, scowl when angry, and so on, as proposed by the common
               view, more than what would be expected by chance. Yet how people
               communicate anger, disgust, fear, happiness, sadness, and
               surprise varies substantially across cultures, situations, and
               even across people within a single situation. Furthermore,
               similar configurations of facial movements variably express
               instances of more than one emotion category. In fact, a given
               configuration of facial movements, such as a scowl, often
               communicates something other than an emotional state. Scientists
               agree that facial movements convey a range of information and
               are important for social communication, emotional or otherwise.
               But our review suggests an urgent need for research that
               examines how people actually move their faces to express
               emotions and other social information in the variety of contexts
               that make up everyday life, as well as careful study of the
               mechanisms by which people perceive instances of emotion in one
               another. We make specific research recommendations that will
               yield a more valid picture of how people move their faces to
               express emotions and how they infer emotional meaning from
               facial movements in situations of everyday life. This research
               is crucial to provide consumers of emotion research with the
               translational information they require.",
  journal   = "Psychol. Sci. Public Interest",
  publisher = "journals.sagepub.com",
  volume    =  20,
  number    =  1,
  pages     = "1--68",
  month     =  jul,
  year      =  2019,
  keywords  = "emotion perception; emotion recognition; emotional expression",
  language  = "en"
}

@ARTICLE{Fritz2012-uw,
  title     = "Effect size estimates: current use, calculations, and
               interpretation",
  author    = "Fritz, Catherine O and Morris, Peter E and Richler, Jennifer J",
  abstract  = "The Publication Manual of the American Psychological Association
               (American Psychological Association, 2001, American
               Psychological Association, 2010) calls for the reporting of
               effect sizes and their confidence intervals. Estimates of effect
               size are useful for determining the practical or theoretical
               importance of an effect, the relative contributions of factors,
               and the power of an analysis. We surveyed articles published in
               2009 and 2010 in the Journal of Experimental Psychology:
               General, noting the statistical analyses reported and the
               associated reporting of effect size estimates. Effect sizes were
               reported for fewer than half of the analyses; no article
               reported a confidence interval for an effect size. The most
               often reported analysis was analysis of variance, and almost
               half of these reports were not accompanied by effect sizes.
               Partial $\eta$2 was the most commonly reported effect size
               estimate for analysis of variance. For t tests, 2/3 of the
               articles did not report an associated effect size estimate;
               Cohen's d was the most often reported. We provide a
               straightforward guide to understanding, selecting, calculating,
               and interpreting effect sizes for many types of data and to
               methods for calculating effect size confidence intervals and
               power analysis.",
  journal   = "J. Exp. Psychol. Gen.",
  publisher = "psycnet.apa.org",
  volume    =  141,
  number    =  1,
  pages     = "2--18",
  month     =  feb,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Buchanan2005-zt,
  title     = "A (Very) Brief History of Artificial Intelligence",
  author    = "Buchanan, Bruce G",
  abstract  = "In this brief history, the beginnings of artificial intelligence
               are traced to philosophy, fiction, and imagination. Early
               inventions in electronics, engineering, and many other
               disciplines have influenced AI. Some early milestones include
               work in problems solving which included basic work in learning,
               knowledge representation, and inference as well as demonstration
               programs in language understanding, translation, theorem
               proving, associative memory, and knowledge-based systems. The
               article ends with a brief examination of influential
               organizations and current issues facing the field.",
  journal   = "AIMag",
  publisher = "ojs.aaai.org",
  volume    =  26,
  number    =  4,
  pages     = "53--53",
  month     =  dec,
  year      =  2005,
  language  = "en"
}

@ARTICLE{Oosterwijk2017-sc,
  title     = "Shared states: using {MVPA} to test neural overlap between
               self-focused emotion imagery and other-focused emotion
               understanding",
  author    = "Oosterwijk, Suzanne and Snoek, Lukas and Rotteveel, Mark and
               Barrett, Lisa Feldman and Scholte, H Steven",
  abstract  = "The present study tested whether the neural patterns that
               support imagining 'performing an action', 'feeling a bodily
               sensation' or 'being in a situation' are directly involved in
               understanding other people's actions, bodily sensations and
               situations. Subjects imagined the content of short sentences
               describing emotional actions, interoceptive sensations and
               situations (self-focused task), and processed scenes and focused
               on how the target person was expressing an emotion, what this
               person was feeling, and why this person was feeling an emotion
               (other-focused task). Using a linear support vector machine
               classifier on brain-wide multi-voxel patterns, we accurately
               decoded each individual class in the self-focused task. When
               generalizing the classifier from the self-focused task to the
               other-focused task, we also accurately decoded whether subjects
               focused on the emotional actions, interoceptive sensations and
               situations of others. These results show that the neural
               patterns that underlie self-imagined experience are involved in
               understanding the experience of other people. This supports the
               theoretical assumption that the basic components of emotion
               experience and understanding share resources in the brain.",
  journal   = "Soc. Cogn. Affect. Neurosci.",
  publisher = "academic.oup.com",
  volume    =  12,
  number    =  7,
  pages     = "1025--1035",
  month     =  jul,
  year      =  2017,
  keywords  = "emotion; mentalizing; multi-voxel pattern analysis; simulation",
  language  = "en"
}

@ARTICLE{Van_Rooij2021-bk,
  title     = "Theory Before the Test: How to Build {High-Verisimilitude}
               Explanatory Theories in Psychological Science",
  author    = "van Rooij, Iris and Baggio, Giosu{\`e}",
  abstract  = "Drawing on the philosophy of psychological explanation, we
               suggest that psychological science, by focusing on effects, may
               lose sight of its primary explananda: psychological capacities.
               We revisit Marr's levels-of-analysis framework, which has been
               remarkably productive and useful for cognitive psychological
               explanation. We discuss ways in which Marr's framework may be
               extended to other areas of psychology, such as social,
               developmental, and evolutionary psychology, bringing new
               benefits to these fields. We then show how theoretical analyses
               can endow a theory with minimal plausibility even before contact
               with empirical data: We call this the theoretical cycle.
               Finally, we explain how our proposal may contribute to
               addressing critical issues in psychological science, including
               how to leverage effects to understand capacities better.",
  journal   = "Perspect. Psychol. Sci.",
  publisher = "journals.sagepub.com",
  pages     = "1745691620970604",
  month     =  jan,
  year      =  2021,
  keywords  = "computational analysis; computational-level theory; formal
               modeling; levels of explanation; psychological explanation;
               theoretical cycle; theory development",
  language  = "en"
}

@INBOOK{Frigg2020-hp,
  title     = "{Models in Science}",
  booktitle = "The {Stanford} Encyclopedia of Philosophy",
  author    = "Frigg, Roman and Hartmann, Stephan",
  editor    = "Zalta, Edward N",
  publisher = "Metaphysics Research Lab, Stanford University",
  edition   = "Spring 2020",
  year      =  2020
}

@ARTICLE{Wagenmakers2012-vd,
  title     = "An Agenda for Purely Confirmatory Research",
  author    = "Wagenmakers, Eric-Jan and Wetzels, Ruud and Borsboom, Denny and
               van der Maas, Han L J and Kievit, Rogier A",
  abstract  = "The veracity of substantive research claims hinges on the way
               experimental data are collected and analyzed. In this article,
               we discuss an uncomfortable fact that threatens the core of
               psychology's academic enterprise: almost without exception,
               psychologists do not commit themselves to a method of data
               analysis before they see the actual data. It then becomes
               tempting to fine tune the analysis to the data in order to
               obtain a desired result-a procedure that invalidates the
               interpretation of the common statistical tests. The extent of
               the fine tuning varies widely across experiments and
               experimenters but is almost impossible for reviewers and readers
               to gauge. To remedy the situation, we propose that researchers
               preregister their studies and indicate in advance the analyses
               they intend to conduct. Only these analyses deserve the label
               ``confirmatory,'' and only for these analyses are the common
               statistical tests valid. Other analyses can be carried out but
               these should be labeled ``exploratory.'' We illustrate our
               proposal with a confirmatory replication attempt of a study on
               extrasensory perception.",
  journal   = "Perspect. Psychol. Sci.",
  publisher = "journals.sagepub.com",
  volume    =  7,
  number    =  6,
  pages     = "632--638",
  month     =  nov,
  year      =  2012,
  keywords  = "Bayesian hypothesis test; ESP; confirmatory experiments; wonky
               statistics",
  language  = "en"
}

@ARTICLE{Borsboom2013-wb,
  title     = "Network analysis: an integrative approach to the structure of
               psychopathology",
  author    = "Borsboom, Denny and Cramer, Ang{\'e}lique O J",
  abstract  = "In network approaches to psychopathology, disorders result from
               the causal interplay between symptoms (e.g., worry $\rightarrow$
               insomnia $\rightarrow$ fatigue), possibly involving feedback
               loops (e.g., a person may engage in substance abuse to forget
               the problems that arose due to substance abuse). The present
               review examines methodologies suited to identify such symptom
               networks and discusses network analysis techniques that may be
               used to extract clinically and scientifically useful information
               from such networks (e.g., which symptom is most central in a
               person's network). The authors also show how network analysis
               techniques may be used to construct simulation models that mimic
               symptom dynamics. Network approaches naturally explain the
               limited success of traditional research strategies, which are
               typically based on the idea that symptoms are manifestations of
               some common underlying factor, while offering promising
               methodological alternatives. In addition, these techniques may
               offer possibilities to guide and evaluate therapeutic
               interventions.",
  journal   = "Annu. Rev. Clin. Psychol.",
  publisher = "annualreviews.org",
  volume    =  9,
  pages     = "91--121",
  year      =  2013,
  language  = "en"
}

@ARTICLE{Breiman2001-lf,
  title     = "Statistical Modeling: The Two Cultures (with comments and a
               rejoinder by the author)",
  author    = "Breiman, Leo",
  abstract  = "There are two cultures in the use of statistical modeling to
               reach conclusions from data. One assumes that the data are
               generated by a given stochastic data model. The other uses
               algorithmic models and treats the data mechanism as unknown. The
               statistical community has been committed to the almost exclusive
               use of data models. This commitment has led to irrelevant
               theory, questionable conclusions, and has kept statisticians
               from working on a large range of interesting current problems.
               Algorithmic modeling, both in theory and practice, has developed
               rapidly in fields outside statistics. It can be used both on
               large complex data sets and as a more accurate and informative
               alternative to data modeling on smaller data sets. If our goal
               as a field is to use data to solve problems, then we need to
               move away from exclusive dependence on data models and adopt a
               more diverse set of tools.",
  journal   = "SSO Schweiz. Monatsschr. Zahnheilkd.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  16,
  number    =  3,
  pages     = "199--231",
  month     =  aug,
  year      =  2001,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dennett2006-el,
  title     = "The frame problem of {AI}",
  author    = "Dennett, D C",
  abstract  = "Page 446. 20 DC Dennett,`` Cognitive Wheels : The Frame Problem
               of AI '' Once upon a time there was a robot, named R1 by its
               creators. Its only task was to fend for itself. One day its
               designers arranged for it to learn that its spare …",
  journal   = "Philosophy of psychology: Contemporary readings",
  publisher = "Routledge",
  volume    =  433,
  pages     = "67--83",
  year      =  2006
}

@ARTICLE{Nastase2020-he,
  title     = "Keep it real: rethinking the primacy of experimental control in
               cognitive neuroscience",
  author    = "Nastase, Samuel A and Goldstein, Ariel and Hasson, Uri",
  abstract  = "Naturalistic experimental paradigms in neuroimaging arose from a
               pressure to test the validity of models we derive from
               highly-controlled experiments in real-world contexts. In many
               cases, however, such efforts led to the realization that models
               developed under particular experimental manipulations failed to
               capture much variance outside the context of that manipulation.
               The critique of non-naturalistic experiments is not a recent
               development; it echoes a persistent and subversive thread in the
               history of modern psychology. The brain has evolved to guide
               behavior in a multidimensional world with many interacting
               variables. The assumption that artificially decoupling and
               manipulating these variables will lead to a satisfactory
               understanding of the brain may be untenable. We develop an
               argument for the primacy of naturalistic paradigms, and point to
               recent developments in machine learning as an example of the
               transformative power of relinquishing control. Naturalistic
               paradigms should not be deployed as an afterthought if we hope
               to build models of brain and behavior that extend beyond the
               laboratory into the real world.",
  journal   = "Neuroimage",
  publisher = "Elsevier",
  volume    =  222,
  pages     = "117254",
  month     =  nov,
  year      =  2020,
  keywords  = "Ecological psychology; Ecological validity; Experimental design;
               Generalizability; Naturalistic stimuli; Representative design",
  language  = "en"
}

@ARTICLE{Streiner2006-ze,
  title     = "Building a better model: an introduction to structural equation
               modelling",
  author    = "Streiner, David L",
  abstract  = "Confirmatory factor analysis (CFA) and structural equation
               modelling (SEM) are powerful extensions of path analysis, which
               was described in a previous article in this series. CFA differs
               from the more traditional exploratory factor analysis in that
               the relations among the variables are specified a priori, which
               permits more powerful tests of construct validity for scales. It
               can also be used to compare different versions of a scale (for
               example, English and French) and to determine whether the scale
               performs equivalently in different groups (for example, men and
               women). SEM expands on path analysis by allowing paths to be
               drawn between latent variables (which, in other techniques, are
               called factors or hypothetical constructs), that is, variables
               that are not seen directly but, rather, through their effect on
               observable variables, such as questionnaires and behavioural
               measures. Each latent variable and its associated measured
               variables form small CFAs, with the added advantage that the
               correlations among the variables can be corrected for the
               unreliability of the measures.",
  journal   = "Can. J. Psychiatry",
  publisher = "journals.sagepub.com",
  volume    =  51,
  number    =  5,
  pages     = "317--324",
  month     =  apr,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Snoek2021-jx,
  title     = "The Amsterdam Open {MRI} Collection, a set of multimodal {MRI}
               datasets for individual difference analyses",
  author    = "Snoek, Lukas and van der Miesen, Maite M and Beemsterboer, Tinka
               and van der Leij, Andries and Eigenhuis, Annemarie and Steven
               Scholte, H",
  abstract  = "We present the Amsterdam Open MRI Collection (AOMIC): three
               datasets with multimodal (3 T) MRI data including structural
               (T1-weighted), diffusion-weighted, and (resting-state and
               task-based) functional BOLD MRI data, as well as detailed
               demographics and psychometric variables from a large set of
               healthy participants (N = 928, N = 226, and N = 216). Notably,
               task-based fMRI was collected during various robust paradigms
               (targeting naturalistic vision, emotion perception, working
               memory, face perception, cognitive conflict and control, and
               response inhibition) for which extensively annotated event-files
               are available. For each dataset and data modality, we provide
               the data in both raw and preprocessed form (both compliant with
               the Brain Imaging Data Structure), which were subjected to
               extensive (automated and manual) quality control. All data is
               publicly available from the OpenNeuro data sharing platform.",
  journal   = "Sci Data",
  publisher = "nature.com",
  volume    =  8,
  number    =  1,
  pages     = "85",
  month     =  mar,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Funder2019-ow,
  title     = "Evaluating Effect Size in Psychological Research: Sense and
               Nonsense",
  author    = "Funder, David C and Ozer, Daniel J",
  abstract  = "Effect sizes are underappreciated and often misinterpreted?the
               most common mistakes being to describe them in ways that are
               uninformative (e.g., using arbitrary standards) or misleading
               (e.g., squaring effect-size rs). We propose that effect sizes
               can be usefully evaluated by comparing them with well-understood
               benchmarks or by considering them in terms of concrete
               consequences. In that light, we conclude that when reliably
               estimated (a critical consideration), an effect-size r of .05
               indicates an effect that is very small for the explanation of
               single events but potentially consequential in the not-very-long
               run, an effect-size r of .10 indicates an effect that is still
               small at the level of single events but potentially more
               ultimately consequential, an effect-size r of .20 indicates a
               medium effect that is of some explanatory and practical use even
               in the short run and therefore even more important, and an
               effect-size r of .30 indicates a large effect that is
               potentially powerful in both the short and the long run. A very
               large effect size (r = .40 or greater) in the context of
               psychological research is likely to be a gross overestimate that
               will rarely be found in a large sample or in a replication. Our
               goal is to help advance the treatment of effect sizes so that
               rather than being numbers that are ignored, reported without
               interpretation, or interpreted superficially or incorrectly,
               they become aspects of research reports that can better inform
               the application and theoretical development of psychological
               research.",
  journal   = "Advances in Methods and Practices in Psychological Science",
  publisher = "SAGE Publications Inc",
  volume    =  2,
  number    =  2,
  pages     = "156--168",
  month     =  jun,
  year      =  2019
}

@ARTICLE{Van_der_Maas2021-rx,
  title   = "How much intelligence is there in artificial intelligence? A 2020
             update",
  author  = "van der Maas, Han L J and Snoek, Lukas and Stevenson, Claire E",
  journal = "Intelligence",
  volume  =  87,
  year    =  2021
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Krizhevsky2012-sy,
  title     = "Imagenet classification with deep convolutional neural networks",
  author    = "Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E",
  abstract  = "We trained a large, deep convolutional neural network to
               classify the 1.2 million high- resolution images in the ImageNet
               LSVRC-2010 contest into the 1000 different classes. On the test
               data, we achieved top-1 and top-5 error rates of 37.5\% and
               17.0\% which is …",
  journal   = "Adv. Neural Inf. Process. Syst.",
  publisher = "kr.nvidia.com",
  volume    =  25,
  pages     = "1097--1105",
  year      =  2012
}

@MISC{Lindelov2019-jk,
  title        = "Common statistical tests are linear models",
  author       = "Lindel{\o}v, Jonas Kristoffer",
  year         =  2019,
  howpublished = "\url{https://lindeloev.github.io/tests-as-linear/}",
  note         = "Accessed: 2021-4-30"
}

@ARTICLE{Kay2017-vr,
  title     = "Principles for models of neural information processing",
  author    = "Kay, Kendrick N",
  abstract  = "The goal of cognitive neuroscience is to understand how mental
               operations are performed by the brain. Given the complexity of
               the brain, this is a challenging endeavor that requires the
               development of formal models. Here, I provide a perspective on
               models of neural information processing in cognitive
               neuroscience. I define what these models are, explain why they
               are useful, and specify criteria for evaluating models. I also
               highlight the difference between functional and mechanistic
               models, and call attention to the value that neuroanatomy has
               for understanding brain function. Based on the principles I
               propose, I proceed to evaluate the merit of recently touted deep
               neural network models. I contend that these models are
               promising, but substantial work is necessary (i) to clarify what
               type of explanation these models provide, (ii) to determine what
               specific effects they accurately explain, and (iii) to improve
               our understanding of how they work.",
  journal   = "Neuroimage",
  publisher = "Elsevier",
  month     =  aug,
  year      =  2017,
  keywords  = "ComputationalNeuro",
  language  = "en"
}

@ARTICLE{Devezer2019-ha,
  title     = "Scientific discovery in a model-centric framework:
               Reproducibility, innovation, and epistemic diversity",
  author    = "Devezer, Berna and Nardin, Luis G and Baumgaertner, Bert and
               Buzbas, Erkan Ozge",
  abstract  = "Consistent confirmations obtained independently of each other
               lend credibility to a scientific result. We refer to results
               satisfying this consistency as reproducible and assume that
               reproducibility is a desirable property of scientific discovery.
               Yet seemingly science also progresses despite irreproducible
               results, indicating that the relationship between
               reproducibility and other desirable properties of scientific
               discovery is not well understood. These properties include early
               discovery of truth, persistence on truth once it is discovered,
               and time spent on truth in a long-term scientific inquiry. We
               build a mathematical model of scientific discovery that presents
               a viable framework to study its desirable properties including
               reproducibility. In this framework, we assume that scientists
               adopt a model-centric approach to discover the true model
               generating data in a stochastic process of scientific discovery.
               We analyze the properties of this process using Markov chain
               theory, Monte Carlo methods, and agent-based modeling. We show
               that the scientific process may not converge to truth even if
               scientific results are reproducible and that irreproducible
               results do not necessarily imply untrue results. The proportion
               of different research strategies represented in the scientific
               population, scientists' choice of methodology, the complexity of
               truth, and the strength of signal contribute to this
               counter-intuitive finding. Important insights include that
               innovative research speeds up the discovery of scientific truth
               by facilitating the exploration of model space and epistemic
               diversity optimizes across desirable properties of scientific
               discovery.",
  journal   = "PLoS One",
  publisher = "journals.plos.org",
  volume    =  14,
  number    =  5,
  pages     = "e0216125",
  month     =  may,
  year      =  2019,
  language  = "en"
}

@ARTICLE{Yarkoni2017-om,
  title     = "Choosing Prediction Over Explanation in Psychology: Lessons From
               Machine Learning",
  author    = "Yarkoni, Tal and Westfall, Jacob",
  abstract  = "Psychology has historically been concerned, first and foremost,
               with explaining the causal mechanisms that give rise to
               behavior. Randomized, tightly controlled experiments are
               enshrined as the gold standard of psychological research, and
               there are endless investigations of the various mediating and
               moderating variables that govern various behaviors. We argue
               that psychology's near-total focus on explaining the causes of
               behavior has led much of the field to be populated by research
               programs that provide intricate theories of psychological
               mechanism but that have little (or unknown) ability to predict
               future behaviors with any appreciable accuracy. We propose that
               principles and techniques from the field of machine learning can
               help psychology become a more predictive science. We review some
               of the fundamental concepts and tools of machine learning and
               point out examples where these concepts have been used to
               conduct interesting and important psychological research that
               focuses on predictive research questions. We suggest that an
               increased focus on prediction, rather than explanation, can
               ultimately lead us to greater understanding of behavior.",
  journal   = "Perspect. Psychol. Sci.",
  publisher = "pilab.psy.utexas.edu",
  pages     = "1745691617693393",
  month     =  aug,
  year      =  2017,
  keywords  = "explanation; machine learning; prediction;NeuroimagingMethods",
  language  = "en"
}

@ARTICLE{Wu2006-qs,
  title     = "Complete functional characterization of sensory neurons by
               system identification",
  author    = "Wu, Michael C-K and David, Stephen V and Gallant, Jack L",
  abstract  = "System identification is a growing approach to sensory
               neurophysiology that facilitates the development of quantitative
               functional models of sensory processing. This approach provides
               a clear set of guidelines for combining experimental data with
               other knowledge about sensory function to obtain a description
               that optimally predicts the way that neurons process sensory
               information. This prediction paradigm provides an objective
               method for evaluating and comparing computational models. In
               this chapter we review many of the system identification
               algorithms that have been used in sensory neurophysiology, and
               we show how they can be viewed as variants of a single
               statistical inference problem. We then review many of the
               practical issues that arise when applying these methods to
               neurophysiological experiments: stimulus selection, behavioral
               control, model visualization, and validation. Finally we discuss
               several problems to which system identification has been applied
               recently, including one important long-term goal of sensory
               neuroscience: developing models of sensory systems that
               accurately predict neuronal responses under completely natural
               conditions.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  29,
  pages     = "477--505",
  year      =  2006,
  language  = "en"
}

@ARTICLE{Hess2009-xo,
  title     = "The face is not an empty canvas: how facial expressions interact
               with facial appearance",
  author    = "Hess, Ursula and Adams, Jr, Reginald B and Kleck, Robert E",
  abstract  = "Faces are not simply blank canvases upon which facial
               expressions write their emotional messages. In fact, facial
               appearance and facial movement are both important social
               signalling systems in their own right. We here provide multiple
               lines of evidence for the notion that the social signals derived
               from facial appearance on the one hand and facial movement on
               the other interact in a complex manner, sometimes reinforcing
               and sometimes contradicting one another. Faces provide
               information on who a person is. Sex, age, ethnicity, personality
               and other characteristics that can define a person and the
               social group the person belongs to can all be derived from the
               face alone. The present article argues that faces interact with
               the perception of emotion expressions because this information
               informs a decoder's expectations regarding an expresser's
               probable emotional reactions. Facial appearance also interacts
               more directly with the interpretation of facial movement because
               some of the features that are used to derive personality or sex
               information are also features that closely resemble certain
               emotional expressions, thereby enhancing or diluting the
               perceived strength of particular expressions.",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "royalsocietypublishing.org",
  volume    =  364,
  number    =  1535,
  pages     = "3497--3504",
  month     =  dec,
  year      =  2009,
  language  = "en"
}

@ARTICLE{Cichy2019-hk,
  title     = "The Algonauts Project",
  author    = "Cichy, Radoslaw Martin and Roig, Gemma and Oliva, Aude",
  abstract  = "A new open challenge tests whether algorithmic models can
               explain human brain activity in cognitive tasks and encourages
               interaction between researchers studying natural and artificial
               intelligence.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    =  12,
  pages     = "613--613",
  month     =  dec,
  year      =  2019,
  language  = "en"
}

@ARTICLE{Kriegeskorte2018-om,
  title     = "Cognitive computational neuroscience",
  author    = "Kriegeskorte, Nikolaus and Douglas, Pamela K",
  abstract  = "To learn how cognition is implemented in the brain, we must
               build computational models that can perform cognitive tasks, and
               test such models with brain and behavioral experiments.
               Cognitive science has developed computational models that
               decompose cognition into functional components. Computational
               neuroscience has modeled how interacting neurons can implement
               elementary components of cognition. It is time to assemble the
               pieces of the puzzle of brain computation and to better
               integrate these separate disciplines. Modern technologies enable
               us to measure and manipulate brain activity in unprecedentedly
               rich ways in animals and humans. However, experiments will yield
               theoretical insight only when employed to test
               brain-computational models. Here we review recent work in the
               intersection of cognitive science, computational neuroscience
               and artificial intelligence. Computational models that mimic
               brain information processing during perceptual, cognitive and
               control tasks are beginning to be developed and tested with
               brain and behavioral data.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  21,
  number    =  9,
  pages     = "1148--1160",
  month     =  sep,
  year      =  2018,
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Gelfert2016-hd,
  title     = "How to Do Science with Models: A Philosophical Primer",
  author    = "Gelfert, Axel",
  abstract  = "After volcanic ash from the eruption of the Icelandic volcano
               Eyjafjallaj{\"o}kull in 2010 had shut down air traffic across
               the Atlantic Ocean for several days in a row, an angry airline
               CEO appeared in a television interview with the BBC and blamed
               civil aviation authorities for …",
  publisher = "Springer, Cham",
  year      =  2016
}

@ARTICLE{Jack2009-yy,
  title     = "Cultural confusions show that facial expressions are not
               universal",
  author    = "Jack, Rachael E and Blais, Caroline and Scheepers, Christoph and
               Schyns, Philippe G and Caldara, Roberto",
  abstract  = "Central to all human interaction is the mutual understanding of
               emotions, achieved primarily by a set of biologically rooted
               social signals evolved for this purpose-facial expressions of
               emotion. Although facial expressions are widely considered to be
               the universal language of emotion, some negative facial
               expressions consistently elicit lower recognition levels among
               Eastern compared to Western groups (see [4] for a meta-analysis
               and [5, 6] for review). Here, focusing on the decoding of facial
               expression signals, we merge behavioral and computational
               analyses with novel spatiotemporal analyses of eye movements,
               showing that Eastern observers use a culture-specific decoding
               strategy that is inadequate to reliably distinguish universal
               facial expressions of ``fear'' and ``disgust.'' Rather than
               distributing their fixations evenly across the face as
               Westerners do, Eastern observers persistently fixate the eye
               region. Using a model information sampler, we demonstrate that
               by persistently fixating the eyes, Eastern observers sample
               ambiguous information, thus causing significant confusion. Our
               results question the universality of human facial expressions of
               emotion, highlighting their true complexity, with critical
               consequences for cross-cultural communication and globalization.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  19,
  number    =  18,
  pages     = "1543--1548",
  month     =  sep,
  year      =  2009,
  language  = "en"
}

@ARTICLE{Schafer2019-ue,
  title     = "The Meaningfulness of Effect Sizes in Psychological Research:
               Differences Between {Sub-Disciplines} and the Impact of
               Potential Biases",
  author    = "Sch{\"a}fer, Thomas and Schwarz, Marcus A",
  abstract  = "Effect sizes are the currency of psychological research. They
               quantify the results of a study to answer the research question
               and are used to calculate statistical power. The interpretation
               of effect sizes-when is an effect small, medium, or large?-has
               been guided by the recommendations Jacob Cohen gave in his
               pioneering writings starting in 1962: Either compare an effect
               with the effects found in past research or use certain
               conventional benchmarks. The present analysis shows that neither
               of these recommendations is currently applicable. From past
               publications without pre-registration, 900 effects were randomly
               drawn and compared with 93 effects from publications with
               pre-registration, revealing a large difference: Effects from the
               former (median r = 0.36) were much larger than effects from the
               latter (median r = 0.16). That is, certain biases, such as
               publication bias or questionable research practices, have caused
               a dramatic inflation in published effects, making it difficult
               to compare an actual effect with the real population effects (as
               these are unknown). In addition, there were very large
               differences in the mean effects between psychological
               sub-disciplines and between different study designs, making it
               impossible to apply any global benchmarks. Many more
               pre-registered studies are needed in the future to derive a
               reliable picture of real population effects.",
  journal   = "Front. Psychol.",
  publisher = "frontiersin.org",
  volume    =  10,
  pages     = "813",
  month     =  apr,
  year      =  2019,
  keywords  = "Cohen; effect size; replicability; sample size; statistical
               power",
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ferguson2014-zh,
  title     = "Big data from small data: data-sharing in the'long tail'of
               neuroscience",
  author    = "Ferguson, Adam R and Nielson, Jessica L and Cragin, Melissa H
               and Bandrowski, Anita E and Martone, Maryann E",
  abstract  = "The launch of the US BRAIN and European Human Brain Projects
               coincides with growing international efforts toward transparency
               and increased access to publicly funded research in the
               neurosciences. The need for data-sharing standards and
               neuroinformatics infrastructure is more pressing than ever.
               However,'big science'efforts are not the only drivers of
               data-sharing needs, as neuroscientists across the full spectrum
               of research grapple with the overwhelming volume of data being
               generated daily and a scientific …",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  17,
  number    =  11,
  pages     = "1442--1447",
  year      =  2014
}

@ARTICLE{Seijdel2020-ff,
  title     = "Depth in convolutional neural networks solves scene segmentation",
  author    = "Seijdel, Noor and Tsakmakidis, Nikos and de Haan, Edward H F and
               Bohte, Sander M and Scholte, H Steven",
  abstract  = "Feed-forward deep convolutional neural networks (DCNNs) are,
               under specific conditions, matching and even surpassing human
               performance in object recognition in natural scenes. This
               performance suggests that the analysis of a loose collection of
               image features could support the recognition of natural object
               categories, without dedicated systems to solve specific visual
               subtasks. Research in humans however suggests that while
               feedforward activity may suffice for sparse scenes with isolated
               objects, additional visual operations ('routines') that aid the
               recognition process (e.g. segmentation or grouping) are needed
               for more complex scenes. Linking human visual processing to
               performance of DCNNs with increasing depth, we here explored if,
               how, and when object information is differentiated from the
               backgrounds they appear on. To this end, we controlled the
               information in both objects and backgrounds, as well as the
               relationship between them by adding noise, manipulating
               background congruence and systematically occluding parts of the
               image. Results indicate that with an increase in network depth,
               there is an increase in the distinction between object- and
               background information. For more shallow networks, results
               indicated a benefit of training on segmented objects. Overall,
               these results indicate that, de facto, scene segmentation can be
               performed by a network of sufficient depth. We conclude that the
               human brain could perform scene segmentation in the context of
               object identification without an explicit mechanism, by
               selecting or ``binding'' features that belong to the object and
               ignoring other features, in a manner similar to a very deep
               convolutional neural network.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  16,
  number    =  7,
  pages     = "e1008022",
  month     =  jul,
  year      =  2020,
  language  = "en"
}

@article{yamins2014performance,
  title={Performance-optimized hierarchical models predict neural responses in higher visual cortex},
  author={Yamins, Daniel LK and Hong, Ha and Cadieu, Charles F and Solomon, Ethan A and Seibert, Darren and DiCarlo, James J},
  journal={Proceedings of the national academy of sciences},
  volume={111},
  number={23},
  pages={8619--8624},
  year={2014},
  publisher={National Acad Sciences}
}

@article{khaligh2014deep,
  title={Deep supervised, but not unsupervised, models may explain IT cortical representation},
  author={Khaligh-Razavi, Seyed-Mahdi and Kriegeskorte, Nikolaus},
  journal={PLoS computational biology},
  volume={10},
  number={11},
  pages={e1003915},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
}

@BOOK{degroot,
  title     = "An Introduction to {Model-Based} Cognitive Neuroscience",
  author    = "de Groot, A.D.",
  publisher = "Mouton, 's-Gravenhage",
  year      =  1961
}
