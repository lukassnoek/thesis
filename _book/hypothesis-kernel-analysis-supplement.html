<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>E Supplement to Chapter 6 | Towards prediction</title>
  <meta name="description" content="E Supplement to Chapter 6 | Towards prediction" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="E Supplement to Chapter 6 | Towards prediction" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="E Supplement to Chapter 6 | Towards prediction" />
  
  
  

<meta name="author" content="Lukas Snoek" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="morbid-curiosity-supplement.html"/>
<link rel="next" href="static-vs-dynamic-supplement.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD thesis of Lukas Snoek</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> This paragraph begins with “This thesis was typeset using (R) Markdown,  and the  R-package”</a><ul>
<li class="chapter" data-level="1.0.1" data-path="index.html"><a href="index.html#title-page"><i class="fa fa-check"></i><b>1.0.1</b> Title page</a></li>
<li class="chapter" data-level="1.0.2" data-path="index.html"><a href="index.html#colophon"><i class="fa fa-check"></i><b>1.0.2</b> Colophon</a></li>
<li class="chapter" data-level="1.0.3" data-path="index.html"><a href="index.html#committee"><i class="fa fa-check"></i><b>1.0.3</b> Committee</a></li>
<li class="chapter" data-level="1.0.4" data-path="index.html"><a href="index.html#book-settings"><i class="fa fa-check"></i><b>1.0.4</b> Book settings</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="general-introduction.html"><a href="general-introduction.html#inference-done-differently"><i class="fa fa-check"></i><b>2.1</b> Inference done differently</a></li>
<li class="chapter" data-level="2.2" data-path="general-introduction.html"><a href="general-introduction.html#towards-prediction"><i class="fa fa-check"></i><b>2.2</b> Towards prediction</a></li>
<li class="chapter" data-level="2.3" data-path="general-introduction.html"><a href="general-introduction.html#outline-of-this-thesis"><i class="fa fa-check"></i><b>2.3</b> Outline of this thesis</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="shared-states.html"><a href="shared-states.html"><i class="fa fa-check"></i><b>3</b> Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding</a><ul>
<li class="chapter" data-level="3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-subjects"><i class="fa fa-check"></i><b>3.2.1</b> Subjects</a></li>
<li class="chapter" data-level="3.2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-experimental-design"><i class="fa fa-check"></i><b>3.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="3.2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-procedure"><i class="fa fa-check"></i><b>3.2.3</b> Procedure</a></li>
<li class="chapter" data-level="3.2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-image-acquisition"><i class="fa fa-check"></i><b>3.2.4</b> Image acquisition</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-model-optimization-procedure"><i class="fa fa-check"></i><b>3.3</b> Model optimization procedure</a><ul>
<li class="chapter" data-level="3.3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-preprocessing"><i class="fa fa-check"></i><b>3.3.1</b> Preprocessing and single-trial modeling</a></li>
<li class="chapter" data-level="3.3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-mvpa"><i class="fa fa-check"></i><b>3.3.2</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="3.3.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-additional-analyses"><i class="fa fa-check"></i><b>3.3.3</b> Additional analyses</a></li>
<li class="chapter" data-level="3.3.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-univariate-analysis"><i class="fa fa-check"></i><b>3.3.4</b> Univariate analysis</a></li>
<li class="chapter" data-level="3.3.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-code-availability"><i class="fa fa-check"></i><b>3.3.5</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-results"><i class="fa fa-check"></i><b>3.4</b> Results</a><ul>
<li class="chapter" data-level="3.4.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-mvpa"><i class="fa fa-check"></i><b>3.4.1</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="3.4.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-univariate"><i class="fa fa-check"></i><b>3.4.2</b> Univariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-discussion"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="confounds-decoding.html"><a href="confounds-decoding.html"><i class="fa fa-check"></i><b>4</b> How to control for confounds in decoding analyses of neuroimaging data</a><ul>
<li class="chapter" data-level="4.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-true-vs-confounded"><i class="fa fa-check"></i><b>4.1.1</b> Partitioning effects into <em>true</em> signal and <em>confounded</em> signal</a></li>
<li class="chapter" data-level="4.1.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-methods"><i class="fa fa-check"></i><b>4.1.2</b> Methods for confound control</a></li>
<li class="chapter" data-level="4.1.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-current-study"><i class="fa fa-check"></i><b>4.1.3</b> Current study</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods"><i class="fa fa-check"></i><b>4.2</b> Methods</a><ul>
<li class="chapter" data-level="4.2.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-data"><i class="fa fa-check"></i><b>4.2.1</b> Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-pipeline"><i class="fa fa-check"></i><b>4.2.2</b> Decoding pipeline</a></li>
<li class="chapter" data-level="4.2.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-evaluated-methods"><i class="fa fa-check"></i><b>4.2.3</b> Evaluated methods for confound control</a></li>
<li class="chapter" data-level="4.2.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#analyses-of-simulated-data"><i class="fa fa-check"></i><b>4.2.4</b> Analyses of simulated data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#results"><i class="fa fa-check"></i><b>4.3</b> Results</a><ul>
<li class="chapter" data-level="4.3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#influence-of-brain-size"><i class="fa fa-check"></i><b>4.3.1</b> Influence of brain size</a></li>
<li class="chapter" data-level="4.3.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#baseline-model-no-confound-control"><i class="fa fa-check"></i><b>4.3.2</b> Baseline model: no confound control</a></li>
<li class="chapter" data-level="4.3.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#post-hoc-counterbalancing"><i class="fa fa-check"></i><b>4.3.3</b> Post hoc counterbalancing</a></li>
<li class="chapter" data-level="4.3.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#whole-dataset-confound-regression-wdcr"><i class="fa fa-check"></i><b>4.3.4</b> Whole-dataset confound regression (WDCR)</a></li>
<li class="chapter" data-level="4.3.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#cross-validated-confound-regression-cvcr"><i class="fa fa-check"></i><b>4.3.5</b> Cross-validated confound regression (CVCR)</a></li>
<li class="chapter" data-level="4.3.6" data-path="confounds-decoding.html"><a href="confounds-decoding.html#summary-methods-for-confound-control"><i class="fa fa-check"></i><b>4.3.6</b> Summary methods for confound control</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-discussion"><i class="fa fa-check"></i><b>4.4</b> Discussion</a><ul>
<li class="chapter" data-level="4.4.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#relevance-and-consequences-for-previous-and-future-research"><i class="fa fa-check"></i><b>4.4.1</b> Relevance and consequences for previous and future research</a></li>
<li class="chapter" data-level="4.4.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#choosing-a-confound-model-linear-vs.-nonlinear-models"><i class="fa fa-check"></i><b>4.4.2</b> Choosing a confound model: linear vs. nonlinear models</a></li>
<li class="chapter" data-level="4.4.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#practical-recommendations"><i class="fa fa-check"></i><b>4.4.3</b> Practical recommendations</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#conclusions"><i class="fa fa-check"></i><b>4.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="aomic.html"><a href="aomic.html"><i class="fa fa-check"></i><b>5</b> The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses</a><ul>
<li class="chapter" data-level="5.1" data-path="aomic.html"><a href="aomic.html#background-summary"><i class="fa fa-check"></i><b>5.1</b> Background &amp; summary</a></li>
<li class="chapter" data-level="5.2" data-path="aomic.html"><a href="aomic.html#methods"><i class="fa fa-check"></i><b>5.2</b> Methods</a><ul>
<li class="chapter" data-level="5.2.1" data-path="aomic.html"><a href="aomic.html#scanner-details-and-general-scanning-protocol-all-datasets"><i class="fa fa-check"></i><b>5.2.1</b> Scanner details and general scanning protocol (all datasets)</a></li>
<li class="chapter" data-level="5.2.2" data-path="aomic.html"><a href="aomic.html#id1000-specifics"><i class="fa fa-check"></i><b>5.2.2</b> ID1000 specifics</a></li>
<li class="chapter" data-level="5.2.3" data-path="aomic.html"><a href="aomic.html#piop1-and-piop2-specifics"><i class="fa fa-check"></i><b>5.2.3</b> PIOP1 and PIOP2 specifics</a></li>
<li class="chapter" data-level="5.2.4" data-path="aomic.html"><a href="aomic.html#subject-variables-all-datasets"><i class="fa fa-check"></i><b>5.2.4</b> Subject variables (all datasets)</a></li>
<li class="chapter" data-level="5.2.5" data-path="aomic.html"><a href="aomic.html#psychometric-variables-all-datasets"><i class="fa fa-check"></i><b>5.2.5</b> Psychometric variables (all datasets)</a></li>
<li class="chapter" data-level="5.2.6" data-path="aomic.html"><a href="aomic.html#aomic-derivatives"><i class="fa fa-check"></i><b>5.2.6</b> Data standardization, preprocessing, and derivatives</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="aomic.html"><a href="aomic.html#data-records"><i class="fa fa-check"></i><b>5.3</b> Data Records</a><ul>
<li class="chapter" data-level="5.3.1" data-path="aomic.html"><a href="aomic.html#data-formats-and-types"><i class="fa fa-check"></i><b>5.3.1</b> Data formats and types</a></li>
<li class="chapter" data-level="5.3.2" data-path="aomic.html"><a href="aomic.html#data-repositories-used"><i class="fa fa-check"></i><b>5.3.2</b> Data repositories used</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="aomic.html"><a href="aomic.html#technical-validation"><i class="fa fa-check"></i><b>5.4</b> Technical validation</a><ul>
<li class="chapter" data-level="5.4.1" data-path="aomic.html"><a href="aomic.html#t1-weighted-scans"><i class="fa fa-check"></i><b>5.4.1</b> T1-weighted scans</a></li>
<li class="chapter" data-level="5.4.2" data-path="aomic.html"><a href="aomic.html#functional-bold-scans"><i class="fa fa-check"></i><b>5.4.2</b> Functional (BOLD) scans</a></li>
<li class="chapter" data-level="5.4.3" data-path="aomic.html"><a href="aomic.html#diffusion-weighted-scans"><i class="fa fa-check"></i><b>5.4.3</b> Diffusion-weighted scans</a></li>
<li class="chapter" data-level="5.4.4" data-path="aomic.html"><a href="aomic.html#physiological-data"><i class="fa fa-check"></i><b>5.4.4</b> Physiological data</a></li>
<li class="chapter" data-level="5.4.5" data-path="aomic.html"><a href="aomic.html#psychometric-data"><i class="fa fa-check"></i><b>5.4.5</b> Psychometric data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="aomic.html"><a href="aomic.html#aomic-code-availability"><i class="fa fa-check"></i><b>5.5</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html"><i class="fa fa-check"></i><b>6</b> Choosing to view morbid information involves reward circuitry</a><ul>
<li class="chapter" data-level="6.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods"><i class="fa fa-check"></i><b>6.2</b> Methods</a><ul>
<li class="chapter" data-level="6.2.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-participants"><i class="fa fa-check"></i><b>6.2.1</b> Participants</a></li>
<li class="chapter" data-level="6.2.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-design"><i class="fa fa-check"></i><b>6.2.2</b> Design</a></li>
<li class="chapter" data-level="6.2.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-materials"><i class="fa fa-check"></i><b>6.2.3</b> Materials</a></li>
<li class="chapter" data-level="6.2.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-procedure"><i class="fa fa-check"></i><b>6.2.4</b> Procedure</a></li>
<li class="chapter" data-level="6.2.5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-behavioral-analysis"><i class="fa fa-check"></i><b>6.2.5</b> Behavioral analysis</a></li>
<li class="chapter" data-level="6.2.6" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-imaging-details"><i class="fa fa-check"></i><b>6.2.6</b> Imaging details</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-data-availability"><i class="fa fa-check"></i><b>6.3</b> Data availability</a></li>
<li class="chapter" data-level="6.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results"><i class="fa fa-check"></i><b>6.4</b> Results</a><ul>
<li class="chapter" data-level="6.4.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results-participants"><i class="fa fa-check"></i><b>6.4.1</b> Participants</a></li>
<li class="chapter" data-level="6.4.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#behavior-and-subjective-report"><i class="fa fa-check"></i><b>6.4.2</b> Behavior and subjective report</a></li>
<li class="chapter" data-level="6.4.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#roi-analyses"><i class="fa fa-check"></i><b>6.4.3</b> ROI analyses</a></li>
<li class="chapter" data-level="6.4.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#whole-brain-analyses"><i class="fa fa-check"></i><b>6.4.4</b> Whole-brain analyses</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-discussion"><i class="fa fa-check"></i><b>6.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html"><i class="fa fa-check"></i><b>7</b> Using predictive modeling to quantify the importance and limitations of action units in emotion perception</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-methods"><i class="fa fa-check"></i><b>7.1</b> Methods</a><ul>
<li class="chapter" data-level="7.1.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hypothesis-kernel-analysis-1"><i class="fa fa-check"></i><b>7.1.1</b> Hypothesis kernel analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#ablation-and-follow-up-exploration-analyses"><i class="fa fa-check"></i><b>7.1.2</b> Ablation and follow-up exploration analyses</a></li>
<li class="chapter" data-level="7.1.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-noise-ceiling"><i class="fa fa-check"></i><b>7.1.3</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="7.1.4" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#evaluated-mappings"><i class="fa fa-check"></i><b>7.1.4</b> Evaluated mappings</a></li>
<li class="chapter" data-level="7.1.5" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-dataset"><i class="fa fa-check"></i><b>7.1.5</b> Dataset used to evaluate mappings</a></li>
<li class="chapter" data-level="7.1.6" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-code"><i class="fa fa-check"></i><b>7.1.6</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-results"><i class="fa fa-check"></i><b>7.2</b> Results</a></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-discussion"><i class="fa fa-check"></i><b>7.3</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html"><i class="fa fa-check"></i><b>8</b> Affective face perception integrates both static and dynamic information</a><ul>
<li class="chapter" data-level="8.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-methods"><i class="fa fa-check"></i><b>8.2</b> Methods</a><ul>
<li class="chapter" data-level="8.2.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-participants"><i class="fa fa-check"></i><b>8.2.1</b> Participants</a></li>
<li class="chapter" data-level="8.2.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-experimental-design"><i class="fa fa-check"></i><b>8.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="8.2.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-procedure"><i class="fa fa-check"></i><b>8.2.3</b> Procedure</a></li>
<li class="chapter" data-level="8.2.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-data-preproc"><i class="fa fa-check"></i><b>8.2.4</b> Data preprocessing</a></li>
<li class="chapter" data-level="8.2.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-pred-analysis"><i class="fa fa-check"></i><b>8.2.5</b> Predictive analysis</a></li>
<li class="chapter" data-level="8.2.6" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#noise-ceiling-estimation"><i class="fa fa-check"></i><b>8.2.6</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="8.2.7" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-bayes"><i class="fa fa-check"></i><b>8.2.7</b> Bayesian reconstructions</a></li>
<li class="chapter" data-level="8.2.8" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-code"><i class="fa fa-check"></i><b>8.2.8</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-results"><i class="fa fa-check"></i><b>8.3</b> Results</a><ul>
<li class="chapter" data-level="8.3.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#encoding-model-performance"><i class="fa fa-check"></i><b>8.3.1</b> Encoding model performance</a></li>
<li class="chapter" data-level="8.3.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#reconstruction-model-visualizations"><i class="fa fa-check"></i><b>8.3.2</b> Reconstruction model visualizations</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-discussion"><i class="fa fa-check"></i><b>8.4</b> Discussion</a><ul>
<li class="chapter" data-level="8.4.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#facial-morphology-independently-contributes-to-affective-face-perception"><i class="fa fa-check"></i><b>8.4.1</b> Facial morphology independently contributes to affective face perception</a></li>
<li class="chapter" data-level="8.4.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#the-influence-of-facial-morphology-does-not-result-from-visual-similarity-to-facial-movements"><i class="fa fa-check"></i><b>8.4.2</b> The influence of facial morphology does not result from visual similarity to facial movements</a></li>
<li class="chapter" data-level="8.4.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#categorical-representations-of-experienced-valence-and-arousal-correlate-with-representations-of-perceived-emotions"><i class="fa fa-check"></i><b>8.4.3</b> Categorical representations of experienced valence and arousal correlate with representations of perceived emotions</a></li>
<li class="chapter" data-level="8.4.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#predictive-models-quantify-what-is-not-yet-known"><i class="fa fa-check"></i><b>8.4.4</b> Predictive models quantify what is (not yet) known</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a></li>
<li class="chapter" data-level="8.6" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#acknowledgements"><i class="fa fa-check"></i><b>8.6</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i><b>9</b> Discussion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html"><i class="fa fa-check"></i><b>A</b> Supplement to Chapter 2</a><ul>
<li class="chapter" data-level="A.1" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#instructions"><i class="fa fa-check"></i><b>A.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html"><i class="fa fa-check"></i><b>B</b> Supplement to Chapter 3</a><ul>
<li class="chapter" data-level="B.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-methods"><i class="fa fa-check"></i><b>B.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="B.1.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#functional-mri-simulation"><i class="fa fa-check"></i><b>B.1.1</b> Functional MRI simulation</a></li>
<li class="chapter" data-level="B.1.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data"><i class="fa fa-check"></i><b>B.1.2</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.1.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation"><i class="fa fa-check"></i><b>B.1.3</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.1.4" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs-nonlinear-confound-models-predicting-vbm-and-tbss-data-based-on-brain-size"><i class="fa fa-check"></i><b>B.1.4</b> Linear vs nonlinear confound models: predicting VBM and TBSS data based on brain size</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-results"><i class="fa fa-check"></i><b>B.2</b> Supplementary results</a><ul>
<li class="chapter" data-level="B.2.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data-1"><i class="fa fa-check"></i><b>B.2.1</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.2.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation-1"><i class="fa fa-check"></i><b>B.2.2</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.2.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs.-nonlinear-confound-models-predicting-vbm-and-tbss-intensity-using-brain-size"><i class="fa fa-check"></i><b>B.2.3</b> Linear vs. nonlinear confound models: predicting VBM and TBSS intensity using brain size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="aomic-supplement.html"><a href="aomic-supplement.html"><i class="fa fa-check"></i><b>C</b> Supplement to Chapter 4</a></li>
<li class="chapter" data-level="D" data-path="morbid-curiosity-supplement.html"><a href="morbid-curiosity-supplement.html"><i class="fa fa-check"></i><b>D</b> Supplement to Chapter 5</a></li>
<li class="chapter" data-level="E" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html"><i class="fa fa-check"></i><b>E</b> Supplement to Chapter 6</a><ul>
<li class="chapter" data-level="E.1" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-supplementary-methods"><i class="fa fa-check"></i><b>E.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="E.1.1" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hypothesis-kernel-analysis-in-detail"><i class="fa fa-check"></i><b>E.1.1</b> Hypothesis kernel analysis (in detail)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="F" data-path="static-vs-dynamic-supplement.html"><a href="static-vs-dynamic-supplement.html"><i class="fa fa-check"></i><b>F</b> Supplement to Chapter 6</a></li>
<li class="chapter" data-level="G" data-path="resources-supplement.html"><a href="resources-supplement.html"><i class="fa fa-check"></i><b>G</b> Data, code, software and educational materials</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="chapter" data-level="" data-path="contributions-to-the-chapters.html"><a href="contributions-to-the-chapters.html"><i class="fa fa-check"></i>Contributions to the chapters</a></li>
<li class="chapter" data-level="" data-path="list-of-other-publications.html"><a href="list-of-other-publications.html"><i class="fa fa-check"></i>List of other publications</a></li>
<li class="chapter" data-level="" data-path="nederlandse-samenvatting-summary-in-dutch.html"><a href="nederlandse-samenvatting-summary-in-dutch.html"><i class="fa fa-check"></i>Nederlandse samenvatting (Summary in Dutch)</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Towards prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-kernel-analysis-supplement" class="section level1">
<h1><span class="header-section-number">E</span> Supplement to Chapter 6</h1>
<div id="hka-supplementary-methods" class="section level2">
<h2><span class="header-section-number">E.1</span> Supplementary methods</h2>
<p>Below, we describe the methodology behind hypothesis kernel analysis and noise ceiling estimation in more detail.</p>
<div id="hypothesis-kernel-analysis-in-detail" class="section level3">
<h3><span class="header-section-number">E.1.1</span> Hypothesis kernel analysis (in detail)</h3>
<div id="step-1-encoding-mappings" class="section level4">
<h4><span class="header-section-number">E.1.1.1</span> Step 1: encoding mappings</h4>
<p>The first step in our method is the embedding of hypotheses in a common space. In the context of AU-emotion mappings, this amounts to formalizing these mappings as points in “AU space”. Here, AU space is a multidimensional space in which each of the AUs under consideration represents one dimension and each AU-emotion mapping (e.g., “disgust = AU9 + AU10”) can be represented as a single point in this space. For example, suppose that we only consider a limited set of five AUs (AU4, AU9, AU10, AU12, and AU23). We then can represent the hypothetical mapping “disgust = AU9 + AU10”, <span class="math inline">\(\mathbf{M}_{\mathrm{disgust}}\)</span>, as a point with five coordinates (i.e., a vector), which value indicates whether a given AU is part of the hypothesized configuration (1) or not (0):</p>
<p><span class="math display">\[\begin{equation}
\mathbf{M}_{\mathrm{disgust}} = \begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}
\end{equation}\]</span></p>
<p>Note that, in the above example, values at the positions of hypothesized AUs are all encoded as 1, which implies that each AU within the configuration is expressed equally intensely. This does not have to be the case; if, for example, the aforementioned mapping hypothesized that disgust is expressed with a combination of AU9 at 100% intensity but AU10 at 50% intensity, then its embedding can be expressed as follows:</p>
<p><span class="math display">\[\begin{equation}
\mathbf{M}_{\mathrm{disgust}} = \begin{bmatrix} 0 &amp; 1 &amp; .5 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}
\end{equation}\]</span></p>
<p>For simplicity, we assume in this example that each hypothesized AU is expressed at equal intensity (such that vectors are binary). Importantly, many studies outline mappings with regard to multiple emotions, which we will refer to here as classes. For this example, we assume that our hypothetical mapping <span class="math inline">\(\mathbf{M}\)</span> limits its mappings to the six basic emotions. Specifically, suppose that mapping <span class="math inline">\(\mathbf{M}\)</span> outlines, in addition the the previously defined happiness mapping, specific hypothetical AU-emotion mappings for the following categorical emotions:</p>
<ul>
<li>anger = AU4 + AU5 + AU7</li>
<li>disgust = AU9 + AU15</li>
<li>fear = AU1 + AU2 + AU4 + AU7 + AU26</li>
<li>sadness = AU1 + AU4 + AU15</li>
<li>surprise = AU1 + AU2 + AU5 + AU26</li>
</ul>
<p>Accordingly, we can encode the entire set of AU-emotion mappings for a given mapping, <span class="math inline">\(\mathbf{M}\)</span>, with <span class="math inline">\(C\)</span> classes and <span class="math inline">\(D\)</span> dimensions into a <span class="math inline">\(C \times D\)</span> matrix, by vertically stacking the <span class="math inline">\(C\)</span> different row mapping vectors. For our hypothetical mapping, <span class="math inline">\(\mathbf{M}\)</span>, its associated “mapping matrix” would look like the following:</p>
<p><span class="math display">\[\begin{equation}
\mathbf{M} = \begin{bmatrix}
0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\end{equation}\]</span></p>
<p>where its rows represent the different classes (categorical emotions) and the columns the involvement of a specific AU. Note that although the above represents a hypothetical mapping, its sparsity is something we would expect, as facial expressions are unlikely to be generated by a full (dense) set of action units <span class="citation">(Yu et al., <a href="bibliography.html#ref-Yu2012-ag" role="doc-biblioref">2012</a>)</span>.</p>
</div>
<div id="step-2-encoding-stimuli" class="section level4">
<h4><span class="header-section-number">E.1.1.2</span> Step 2: encoding stimuli</h4>
<p>In the previous section we outlined how to formalize AU-emotion mappings as points (or, equivalently, vectors) in AU space. One way to <em>evaluate</em> these formalized mappings is to subject them to actual categorical emotion ratings from human participants in response to stimuli with known AU configurations. Ideally, the stimuli from such an experiment sample the AU space as densely and uniformly as possible in order not to bias the results towards hypothesized mappings. Many experiments on facial emotion expressions, however, use posed and stereotyped stimuli (e.g., facial expressions of intense joy or anger), which cover only a small part of the entire AU space and thus do not allow for unbiased evaluation of AU-based theories. In contrast, reverse correlation-based experiments, which are characterized by randomly and parametrically varying the input space (defined by AU configurations) and collection of resulting percepts (here: perception of categorical emotion) do not impose such constraints <span class="citation">(R. Jack et al., <a href="bibliography.html#ref-Jack2017-qp" role="doc-biblioref">2017</a>)</span> and thus present an ideal type of dataset to subject to our formalized AU-emotion mappings.</p>
<p>In reference to our previously defined hypothetical 10-dimensional AU space, assume that we have categorical emotion ratings <span class="math inline">\(e\)</span> from a set of emotions <span class="math inline">\(E\)</span> (<span class="math inline">\(e \in E\)</span>) in response to a collection of <span class="math inline">\(N\)</span> facial expression stimuli parameterized with random AU configurations, drawn from the same 10-dimensional AU space discussed before. With such data, we can encode the stimuli in AU space in the same way we did in the previous section for AU-emotion mappings, i.e., we can quantify each stimulus, <span class="math inline">\(\mathbf{S}_{i}\)</span>, as a 10-dimensional “stimulus vector” containing nonzero values at positions associated with active AUs for that stimulus and zeros elsewhere. Note that, as is the case with mapping vectors, the stimulus vector’s nonzero values at positions associated with active AUs can be all ones (if assumed to be equally “active”) or be values proportional to the amplitude (or “activity”) of the active AUs.</p>
<p>For example, suppose that stimulus <span class="math inline">\(\mathbf{S}_{i}\)</span> contains AU1, AU5, and AU26 with amplitudes 0.1, 0.5, and 0.8 respectively (where an amplitude of 1 would represent an AU at maximum intensity). Then, formally, we can represent this particular stimulus, <span class="math inline">\(\mathbf{S}_{i}\)</span>, as the following stimulus vector:</p>
<p><span class="math display">\[\begin{equation}
\mathbf{S}_{i} = \begin{bmatrix} .1 &amp; 0 &amp; 0 &amp; .5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; .8 \end{bmatrix}
\end{equation}\]</span></p>
<p>In case of multiple stimuli (<span class="math inline">\(\mathbf{S}_{i}\)</span> for <span class="math inline">\(i = \{1, \dots, N\}\)</span>), their mapping vectors can be vertically stacked in a single <span class="math inline">\(N \times D\)</span> “stimulus matrix”, <span class="math inline">\(\mathbf{S}\)</span>.</p>
<p>Given that both a mapping (<span class="math inline">\(\mathbf{M}\)</span>) and set of stimuli (<span class="math inline">\(\mathbf{S}\)</span>) are encoded as matrices in the same <span class="math inline">\(D\)</span>-dimensional AU space, we can discuss using kernels to generate quantitative predictors for stimuli given a particular theory.</p>
</div>
<div id="step-3-kernel-functions" class="section level4">
<h4><span class="header-section-number">E.1.1.3</span> Step 3: kernel functions</h4>
<p>Kernel functions (or simply kernels) are functions that are, broadly speaking, measures of similarity between two vectors. Applied to our use case, we use kernel functions (<span class="math inline">\(\kappa\)</span>) to quantify the similarity, i.e. “closeness” in AU space, (<span class="math inline">\(\phi\)</span>) between a stimulus with a known AU configuration (<span class="math inline">\(\mathbf{S}_{i}\)</span>) and a mapping vector for a specific emotion, indexed by <span class="math inline">\(j\)</span> (<span class="math inline">\(\mathbf{M}_{j}\)</span>, e.g., happiness)<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>:</p>
<p><span class="math display">\[\begin{equation}
\phi_{ij} = \kappa(\mathbf{S}_{i}, \mathbf{M}_{j})
\end{equation}\]</span></p>
<p>Most (linear) kernel functions are based on the dot (inner) product between the two vectors. In the current study, we primarily use the cosine kernel, which normalizes the dot product between two vectors with the product of their L2 (Euclidean) norm:</p>
<p><span class="math display">\[\begin{equation}
\kappa(\mathbf{S}_{i}, \mathbf{M}_{j}) = \frac{\mathbf{S}_{i}\mathbf{M}_{j}^{T}}{\left\Vert \mathbf{S}_{i} \right\Vert \left\Vert \mathbf{M}_{j} \right\Vert}
\end{equation}\]</span></p>
<p>Without such normalization, similarity values monotonically increase with increasing magnitudes of the stimulus vector, even if the stimulus vector increasingly deviates from the mapping.</p>
</div>
<div id="step-4-computing-predictions" class="section level4">
<h4><span class="header-section-number">E.1.1.4</span> Step 4: computing predictions</h4>
<p>Although the similarity to a particular mapping vector can, generally speaking, be interpreted as being proportional to the evidence for that particular class, it is not strictly speaking a prediction. To generate a quantitative prediction for stimulus <span class="math inline">\(\mathbf{S}_{i}\)</span> (i.e., <span class="math inline">\(\hat{e}_{i}\)</span>), one needs to formulate a decision function that maps the data to a prediction. One possibility is to determine the prediction to be the emotion (across <span class="math inline">\(C\)</span> classes) that maximizes its similarity, for some kernel function (<span class="math inline">\(\kappa\)</span>), to the stimulus:</p>
<p><span class="math display">\[\begin{equation}
\hat{e}_{i} = \underset{j}{\operatorname{\argmax}} \kappa(\mathbf{S}_{i}, \mathbf{M}_{j})
\end{equation}\]</span></p>

</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Instead of using measures of similarity between two vectors (i.e., “kernels”), one could use measures of <em>distances</em> (<span class="math inline">\(\delta_{ij}\)</span>) between two vectors instead and subsequently invert it to get a similarity score again, i.e., <span class="math inline">\(\phi_{ij} = \delta_{ij}^{-1}\)</span>. In practice, we find that it does not make much of a difference in terms of predictive performance (see Supplementary Figure <a href="#fig:fig-hka-S3"><strong>??</strong></a>).<a href="hypothesis-kernel-analysis-supplement.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="morbid-curiosity-supplement.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="static-vs-dynamic-supplement.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
