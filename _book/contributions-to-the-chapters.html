<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Contributions to the chapters | Towards prediction</title>
  <meta name="description" content="Contributions to the chapters | Towards prediction" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Contributions to the chapters | Towards prediction" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Contributions to the chapters | Towards prediction" />
  
  
  

<meta name="author" content="Lukas Snoek" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bibliography.html"/>
<link rel="next" href="list-of-other-publications.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD thesis of Lukas Snoek</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> This paragraph begins with “This thesis was typeset using (R) Markdown,  and the  R-package”</a><ul>
<li class="chapter" data-level="1.0.1" data-path="index.html"><a href="index.html#title-page"><i class="fa fa-check"></i><b>1.0.1</b> Title page</a></li>
<li class="chapter" data-level="1.0.2" data-path="index.html"><a href="index.html#colophon"><i class="fa fa-check"></i><b>1.0.2</b> Colophon</a></li>
<li class="chapter" data-level="1.0.3" data-path="index.html"><a href="index.html#committee"><i class="fa fa-check"></i><b>1.0.3</b> Committee</a></li>
<li class="chapter" data-level="1.0.4" data-path="index.html"><a href="index.html#book-settings"><i class="fa fa-check"></i><b>1.0.4</b> Book settings</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#the-brain-is-not-a-dictionary"><i class="fa fa-check"></i><b>2.1</b> The brain is not a dictionary</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#the-brain-probably-does-not-care-about-your-hypothesis"><i class="fa fa-check"></i><b>2.2</b> The brain (probably) does not care about your hypothesis</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#interpretability-and-prediction-are-a-trade-off-for-now"><i class="fa fa-check"></i><b>2.3</b> Interpretability and prediction are a trade-off (for now)</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#exploration-should-be-embraced-more"><i class="fa fa-check"></i><b>2.4</b> Exploration should be embraced more</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#proper-generalization-is-hard"><i class="fa fa-check"></i><b>2.5</b> Proper generalization is hard</a></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#psychology-is-complex-so-it-needs-complex-models"><i class="fa fa-check"></i><b>2.6</b> Psychology is complex, so it needs complex models</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="shared-states.html"><a href="shared-states.html"><i class="fa fa-check"></i><b>3</b> Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding</a><ul>
<li class="chapter" data-level="3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-subjects"><i class="fa fa-check"></i><b>3.2.1</b> Subjects</a></li>
<li class="chapter" data-level="3.2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-experimental-design"><i class="fa fa-check"></i><b>3.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="3.2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-procedure"><i class="fa fa-check"></i><b>3.2.3</b> Procedure</a></li>
<li class="chapter" data-level="3.2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-image-acquisition"><i class="fa fa-check"></i><b>3.2.4</b> Image acquisition</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-model-optimization-procedure"><i class="fa fa-check"></i><b>3.3</b> Model optimization procedure</a><ul>
<li class="chapter" data-level="3.3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-preprocessing"><i class="fa fa-check"></i><b>3.3.1</b> Preprocessing and single-trial modeling</a></li>
<li class="chapter" data-level="3.3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-mvpa"><i class="fa fa-check"></i><b>3.3.2</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="3.3.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-additional-analyses"><i class="fa fa-check"></i><b>3.3.3</b> Additional analyses</a></li>
<li class="chapter" data-level="3.3.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-univariate-analysis"><i class="fa fa-check"></i><b>3.3.4</b> Univariate analysis</a></li>
<li class="chapter" data-level="3.3.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-code-availability"><i class="fa fa-check"></i><b>3.3.5</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-results"><i class="fa fa-check"></i><b>3.4</b> Results</a><ul>
<li class="chapter" data-level="3.4.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-mvpa"><i class="fa fa-check"></i><b>3.4.1</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="3.4.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-univariate"><i class="fa fa-check"></i><b>3.4.2</b> Univariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-discussion"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="confounds-decoding.html"><a href="confounds-decoding.html"><i class="fa fa-check"></i><b>4</b> How to control for confounds in decoding analyses of neuroimaging data</a><ul>
<li class="chapter" data-level="4.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-true-vs-confounded"><i class="fa fa-check"></i><b>4.1.1</b> Partitioning effects into <em>true</em> signal and <em>confounded</em> signal</a></li>
<li class="chapter" data-level="4.1.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-methods"><i class="fa fa-check"></i><b>4.1.2</b> Methods for confound control</a></li>
<li class="chapter" data-level="4.1.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-current-study"><i class="fa fa-check"></i><b>4.1.3</b> Current study</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods"><i class="fa fa-check"></i><b>4.2</b> Methods</a><ul>
<li class="chapter" data-level="4.2.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-data"><i class="fa fa-check"></i><b>4.2.1</b> Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-pipeline"><i class="fa fa-check"></i><b>4.2.2</b> Decoding pipeline</a></li>
<li class="chapter" data-level="4.2.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-evaluated-methods"><i class="fa fa-check"></i><b>4.2.3</b> Evaluated methods for confound control</a></li>
<li class="chapter" data-level="4.2.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#analyses-of-simulated-data"><i class="fa fa-check"></i><b>4.2.4</b> Analyses of simulated data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#results"><i class="fa fa-check"></i><b>4.3</b> Results</a><ul>
<li class="chapter" data-level="4.3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#influence-of-brain-size"><i class="fa fa-check"></i><b>4.3.1</b> Influence of brain size</a></li>
<li class="chapter" data-level="4.3.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#baseline-model-no-confound-control"><i class="fa fa-check"></i><b>4.3.2</b> Baseline model: no confound control</a></li>
<li class="chapter" data-level="4.3.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#post-hoc-counterbalancing"><i class="fa fa-check"></i><b>4.3.3</b> Post hoc counterbalancing</a></li>
<li class="chapter" data-level="4.3.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#whole-dataset-confound-regression-wdcr"><i class="fa fa-check"></i><b>4.3.4</b> Whole-dataset confound regression (WDCR)</a></li>
<li class="chapter" data-level="4.3.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#cross-validated-confound-regression-cvcr"><i class="fa fa-check"></i><b>4.3.5</b> Cross-validated confound regression (CVCR)</a></li>
<li class="chapter" data-level="4.3.6" data-path="confounds-decoding.html"><a href="confounds-decoding.html#summary-methods-for-confound-control"><i class="fa fa-check"></i><b>4.3.6</b> Summary methods for confound control</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-discussion"><i class="fa fa-check"></i><b>4.4</b> Discussion</a><ul>
<li class="chapter" data-level="4.4.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#relevance-and-consequences-for-previous-and-future-research"><i class="fa fa-check"></i><b>4.4.1</b> Relevance and consequences for previous and future research</a></li>
<li class="chapter" data-level="4.4.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#choosing-a-confound-model-linear-vs.-nonlinear-models"><i class="fa fa-check"></i><b>4.4.2</b> Choosing a confound model: linear vs. nonlinear models</a></li>
<li class="chapter" data-level="4.4.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#practical-recommendations"><i class="fa fa-check"></i><b>4.4.3</b> Practical recommendations</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#conclusions"><i class="fa fa-check"></i><b>4.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="aomic.html"><a href="aomic.html"><i class="fa fa-check"></i><b>5</b> The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses</a><ul>
<li class="chapter" data-level="5.1" data-path="aomic.html"><a href="aomic.html#background-summary"><i class="fa fa-check"></i><b>5.1</b> Background &amp; summary</a></li>
<li class="chapter" data-level="5.2" data-path="aomic.html"><a href="aomic.html#methods"><i class="fa fa-check"></i><b>5.2</b> Methods</a><ul>
<li class="chapter" data-level="5.2.1" data-path="aomic.html"><a href="aomic.html#scanner-details-and-general-scanning-protocol-all-datasets"><i class="fa fa-check"></i><b>5.2.1</b> Scanner details and general scanning protocol (all datasets)</a></li>
<li class="chapter" data-level="5.2.2" data-path="aomic.html"><a href="aomic.html#id1000-specifics"><i class="fa fa-check"></i><b>5.2.2</b> ID1000 specifics</a></li>
<li class="chapter" data-level="5.2.3" data-path="aomic.html"><a href="aomic.html#piop1-and-piop2-specifics"><i class="fa fa-check"></i><b>5.2.3</b> PIOP1 and PIOP2 specifics</a></li>
<li class="chapter" data-level="5.2.4" data-path="aomic.html"><a href="aomic.html#subject-variables-all-datasets"><i class="fa fa-check"></i><b>5.2.4</b> Subject variables (all datasets)</a></li>
<li class="chapter" data-level="5.2.5" data-path="aomic.html"><a href="aomic.html#psychometric-variables-all-datasets"><i class="fa fa-check"></i><b>5.2.5</b> Psychometric variables (all datasets)</a></li>
<li class="chapter" data-level="5.2.6" data-path="aomic.html"><a href="aomic.html#aomic-derivatives"><i class="fa fa-check"></i><b>5.2.6</b> Data standardization, preprocessing, and derivatives</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="aomic.html"><a href="aomic.html#data-records"><i class="fa fa-check"></i><b>5.3</b> Data Records</a><ul>
<li class="chapter" data-level="5.3.1" data-path="aomic.html"><a href="aomic.html#data-formats-and-types"><i class="fa fa-check"></i><b>5.3.1</b> Data formats and types</a></li>
<li class="chapter" data-level="5.3.2" data-path="aomic.html"><a href="aomic.html#data-repositories-used"><i class="fa fa-check"></i><b>5.3.2</b> Data repositories used</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="aomic.html"><a href="aomic.html#technical-validation"><i class="fa fa-check"></i><b>5.4</b> Technical validation</a><ul>
<li class="chapter" data-level="5.4.1" data-path="aomic.html"><a href="aomic.html#t1-weighted-scans"><i class="fa fa-check"></i><b>5.4.1</b> T1-weighted scans</a></li>
<li class="chapter" data-level="5.4.2" data-path="aomic.html"><a href="aomic.html#functional-bold-scans"><i class="fa fa-check"></i><b>5.4.2</b> Functional (BOLD) scans</a></li>
<li class="chapter" data-level="5.4.3" data-path="aomic.html"><a href="aomic.html#diffusion-weighted-scans"><i class="fa fa-check"></i><b>5.4.3</b> Diffusion-weighted scans</a></li>
<li class="chapter" data-level="5.4.4" data-path="aomic.html"><a href="aomic.html#physiological-data"><i class="fa fa-check"></i><b>5.4.4</b> Physiological data</a></li>
<li class="chapter" data-level="5.4.5" data-path="aomic.html"><a href="aomic.html#psychometric-data"><i class="fa fa-check"></i><b>5.4.5</b> Psychometric data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="aomic.html"><a href="aomic.html#aomic-code-availability"><i class="fa fa-check"></i><b>5.5</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html"><i class="fa fa-check"></i><b>6</b> Choosing to view morbid information involves reward circuitry</a><ul>
<li class="chapter" data-level="6.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods"><i class="fa fa-check"></i><b>6.2</b> Methods</a><ul>
<li class="chapter" data-level="6.2.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-participants"><i class="fa fa-check"></i><b>6.2.1</b> Participants</a></li>
<li class="chapter" data-level="6.2.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-design"><i class="fa fa-check"></i><b>6.2.2</b> Design</a></li>
<li class="chapter" data-level="6.2.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-materials"><i class="fa fa-check"></i><b>6.2.3</b> Materials</a></li>
<li class="chapter" data-level="6.2.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-procedure"><i class="fa fa-check"></i><b>6.2.4</b> Procedure</a></li>
<li class="chapter" data-level="6.2.5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-behavioral-analysis"><i class="fa fa-check"></i><b>6.2.5</b> Behavioral analysis</a></li>
<li class="chapter" data-level="6.2.6" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-imaging-details"><i class="fa fa-check"></i><b>6.2.6</b> Imaging details</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-data-availability"><i class="fa fa-check"></i><b>6.3</b> Data availability</a></li>
<li class="chapter" data-level="6.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results"><i class="fa fa-check"></i><b>6.4</b> Results</a><ul>
<li class="chapter" data-level="6.4.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results-participants"><i class="fa fa-check"></i><b>6.4.1</b> Participants</a></li>
<li class="chapter" data-level="6.4.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#behavior-and-subjective-report"><i class="fa fa-check"></i><b>6.4.2</b> Behavior and subjective report</a></li>
<li class="chapter" data-level="6.4.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#roi-analyses"><i class="fa fa-check"></i><b>6.4.3</b> ROI analyses</a></li>
<li class="chapter" data-level="6.4.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#whole-brain-analyses"><i class="fa fa-check"></i><b>6.4.4</b> Whole-brain analyses</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-discussion"><i class="fa fa-check"></i><b>6.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html"><i class="fa fa-check"></i><b>7</b> Using predictive modeling to quantify the importance and limitations of action units in emotion perception</a></li>
<li class="chapter" data-level="8" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html"><i class="fa fa-check"></i><b>8</b> Affective face perception integrates both static and dynamic information</a><ul>
<li class="chapter" data-level="8.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-methods"><i class="fa fa-check"></i><b>8.2</b> Methods</a><ul>
<li class="chapter" data-level="8.2.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-participants"><i class="fa fa-check"></i><b>8.2.1</b> Participants</a></li>
<li class="chapter" data-level="8.2.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-experimental-design"><i class="fa fa-check"></i><b>8.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="8.2.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-procedure"><i class="fa fa-check"></i><b>8.2.3</b> Procedure</a></li>
<li class="chapter" data-level="8.2.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-data-preproc"><i class="fa fa-check"></i><b>8.2.4</b> Data preprocessing</a></li>
<li class="chapter" data-level="8.2.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-pred-analysis"><i class="fa fa-check"></i><b>8.2.5</b> Predictive analysis</a></li>
<li class="chapter" data-level="8.2.6" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#noise-ceiling-estimation"><i class="fa fa-check"></i><b>8.2.6</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="8.2.7" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-bayes"><i class="fa fa-check"></i><b>8.2.7</b> Bayesian reconstructions</a></li>
<li class="chapter" data-level="8.2.8" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-code"><i class="fa fa-check"></i><b>8.2.8</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-results"><i class="fa fa-check"></i><b>8.3</b> Results</a><ul>
<li class="chapter" data-level="8.3.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#encoding-model-performance"><i class="fa fa-check"></i><b>8.3.1</b> Encoding model performance</a></li>
<li class="chapter" data-level="8.3.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#reconstruction-model-visualizations"><i class="fa fa-check"></i><b>8.3.2</b> Reconstruction model visualizations</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-discussion"><i class="fa fa-check"></i><b>8.4</b> Discussion</a><ul>
<li class="chapter" data-level="8.4.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#facial-morphology-independently-contributes-to-affective-face-perception"><i class="fa fa-check"></i><b>8.4.1</b> Facial morphology independently contributes to affective face perception</a></li>
<li class="chapter" data-level="8.4.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#the-influence-of-facial-morphology-does-not-result-from-visual-similarity-to-facial-movements"><i class="fa fa-check"></i><b>8.4.2</b> The influence of facial morphology does not result from visual similarity to facial movements</a></li>
<li class="chapter" data-level="8.4.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#categorical-representations-of-experienced-valence-and-arousal-correlate-with-representations-of-perceived-emotions"><i class="fa fa-check"></i><b>8.4.3</b> Categorical representations of experienced valence and arousal correlate with representations of perceived emotions</a></li>
<li class="chapter" data-level="8.4.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#predictive-models-quantify-what-is-not-yet-known"><i class="fa fa-check"></i><b>8.4.4</b> Predictive models quantify what is (not yet) known</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a></li>
<li class="chapter" data-level="8.6" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#acknowledgements"><i class="fa fa-check"></i><b>8.6</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html"><i class="fa fa-check"></i><b>9</b> Summary and general discussion</a><ul>
<li class="chapter" data-level="9.1" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html#explore"><i class="fa fa-check"></i><b>9.1</b> Explore!</a></li>
<li class="chapter" data-level="9.2" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html#think-big"><i class="fa fa-check"></i><b>9.2</b> Think <em>big</em></a></li>
<li class="chapter" data-level="9.3" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html#rethink-psychology-education"><i class="fa fa-check"></i><b>9.3</b> Rethink psychology education</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html"><i class="fa fa-check"></i><b>A</b> Supplement to Chapter 2</a><ul>
<li class="chapter" data-level="A.1" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#stimuli-used-for-sf-task"><i class="fa fa-check"></i><b>A.1</b> Stimuli used for SF-task</a></li>
<li class="chapter" data-level="A.2" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#instructions"><i class="fa fa-check"></i><b>A.2</b> Instructions</a><ul>
<li class="chapter" data-level="A.2.1" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#full-instruction-for-the-other-focused-emotion-understanding-task"><i class="fa fa-check"></i><b>A.2.1</b> Full instruction for the other-focused emotion understanding task</a></li>
<li class="chapter" data-level="A.2.2" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#full-instruction-for-the-self-focused-emotion-imagery-task"><i class="fa fa-check"></i><b>A.2.2</b> Full instruction for the self-focused emotion imagery task</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#behavioral-results"><i class="fa fa-check"></i><b>A.3</b> Behavioral results</a></li>
<li class="chapter" data-level="A.4" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#optimization-results"><i class="fa fa-check"></i><b>A.4</b> Optimization results</a></li>
<li class="chapter" data-level="A.5" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#bagging-procedure"><i class="fa fa-check"></i><b>A.5</b> Bagging procedure</a></li>
<li class="chapter" data-level="A.6" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#precision-vs.-recall"><i class="fa fa-check"></i><b>A.6</b> Precision vs. recall</a></li>
<li class="chapter" data-level="A.7" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#self-vs.-other-classification"><i class="fa fa-check"></i><b>A.7</b> Self vs. other classification</a></li>
<li class="chapter" data-level="A.8" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#condition-average-results"><i class="fa fa-check"></i><b>A.8</b> Condition-average results</a></li>
<li class="chapter" data-level="A.9" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#individual-subject-scores"><i class="fa fa-check"></i><b>A.9</b> Individual subject scores</a></li>
<li class="chapter" data-level="A.10" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#brain-region-importance"><i class="fa fa-check"></i><b>A.10</b> Brain region importance</a></li>
<li class="chapter" data-level="A.11" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#general-note-about-tables-with-voxel-coordinates"><i class="fa fa-check"></i><b>A.11</b> General note about tables with voxel-coordinates</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html"><i class="fa fa-check"></i><b>B</b> Supplement to Chapter 3</a><ul>
<li class="chapter" data-level="B.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-methods"><i class="fa fa-check"></i><b>B.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="B.1.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#functional-mri-simulation"><i class="fa fa-check"></i><b>B.1.1</b> Functional MRI simulation</a></li>
<li class="chapter" data-level="B.1.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data"><i class="fa fa-check"></i><b>B.1.2</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.1.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation"><i class="fa fa-check"></i><b>B.1.3</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.1.4" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs-nonlinear-confound-models-predicting-vbm-and-tbss-data-based-on-brain-size"><i class="fa fa-check"></i><b>B.1.4</b> Linear vs nonlinear confound models: predicting VBM and TBSS data based on brain size</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-results"><i class="fa fa-check"></i><b>B.2</b> Supplementary results</a><ul>
<li class="chapter" data-level="B.2.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data-1"><i class="fa fa-check"></i><b>B.2.1</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.2.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation-1"><i class="fa fa-check"></i><b>B.2.2</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.2.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs.-nonlinear-confound-models-predicting-vbm-and-tbss-intensity-using-brain-size"><i class="fa fa-check"></i><b>B.2.3</b> Linear vs. nonlinear confound models: predicting VBM and TBSS intensity using brain size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="aomic-supplement.html"><a href="aomic-supplement.html"><i class="fa fa-check"></i><b>C</b> Supplement to Chapter 4</a></li>
<li class="chapter" data-level="D" data-path="morbid-curiosity-supplement.html"><a href="morbid-curiosity-supplement.html"><i class="fa fa-check"></i><b>D</b> Supplement to Chapter 5</a></li>
<li class="chapter" data-level="E" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html"><i class="fa fa-check"></i><b>E</b> Supplement to Chapter 6</a></li>
<li class="chapter" data-level="F" data-path="static-vs-dynamic-supplement.html"><a href="static-vs-dynamic-supplement.html"><i class="fa fa-check"></i><b>F</b> Supplement to Chapter 6</a></li>
<li class="chapter" data-level="G" data-path="resources-supplement.html"><a href="resources-supplement.html"><i class="fa fa-check"></i><b>G</b> Data, code and (educational) materials</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="chapter" data-level="" data-path="contributions-to-the-chapters.html"><a href="contributions-to-the-chapters.html"><i class="fa fa-check"></i>Contributions to the chapters</a></li>
<li class="chapter" data-level="" data-path="list-of-other-publications.html"><a href="list-of-other-publications.html"><i class="fa fa-check"></i>List of other publications</a></li>
<li class="chapter" data-level="" data-path="nederlandse-samenvatting-summary-in-dutch.html"><a href="nederlandse-samenvatting-summary-in-dutch.html"><i class="fa fa-check"></i>Nederlandse samenvatting (Summary in Dutch)</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Towards prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="contributions-to-the-chapters" class="section level1 unnumbered">
<h1>Contributions to the chapters</h1>

<p><em>The contributions below were specified according to the</em> CRediT <em>system</em> <span class="citation">(Contributor Roles Taxonomy; <a href="https://www.casrai.org/credit.html" class="uri" role="doc-biblioref">https://www.casrai.org/credit.html</a>; Brand et al., <a href="bibliography.html#ref-brand2015beyond" role="doc-biblioref">2015</a>)</span>.</p>
<hr />
<p><strong>Chapter 2</strong>, published as:</p>
<p>Oosterwijk, S.*, Snoek, L.*, Rotteveel, M., Barrett, L. F., &amp; Scholte, H. S. (2017). Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding. <em>Social cognitive and affective neuroscience, 12</em>(7), 1025-1035.</p>
<p>S.O. developed the concept of the study. S.O., L.S., and H.S.S. developed the study design. L.S. and S.O. acquired the data. L.S. and S.O. analyzed the data and wrote the analysis code. S.O., L.S., and H.S.S. wrote the manuscript. M.R. and L.F.B. provided feedback on the first draft of the manuscript.</p>
<p>The authors would like to thank David Amodio for his helpful comments on a previous draft of this manuscript.</p>
<p><strong>Chapter 3</strong>, published as:</p>
<p>Snoek, L.*, Miletić, S.*, &amp; Scholte, H.S. (2019). How to control for confounds in decoding analyses of neuroimaging data. <em>NeuroImage</em>, 184, 741-760.</p>
<p>L.S. and S.M. were responsible for the conceptualization, formal analysis, and development of methods. L.S., S.M., and H.S.S. wrote the manuscript. H.S.S. supervised the study.</p>
<p><strong>Chapter 4</strong>, published as:</p>
<p>Snoek, L., van der Miesen, M.M., Beemsterboer, T., van der Leij, A., Eigenhuis, A., &amp; Scholte, H.S. (2021). The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses. <em>Nature Scientific Data, 8</em>, 85.</p>
<p>L.S. curated the datasets, did visual quality control, preprocessed and analyzed the data, and wrote the article. M.v.d.M. did visual quality control, analyzed the data, and wrote the article. T.B. designed the data acquisition protocol of PIOP1 and PIOP2, was responsible for subject recruitment of PIOP1 and PIOP2, collected the data, and did visual quality control for PIOP1 and PIOP2. A.v.d.L. designed the data acquisition protocol, collected data, and did visual quality control for ID1000. A.E. designed and implemented the questionnaires in ID1000, PIOP1 and PIOP2 and managed questionnaire data from ID1000. H.S.S. was principal investigator of the ID1000, PIOP1, and PIOP2 studies, designed the data acquisition protocol of PIOP1, PIOP2, and ID1000, and wrote the article.</p>
<p>We thank all research assistants and students who helped collecting the data of the three projects, Jasper Wijnen and Marco Teunisse for advice and guidance with respect to anonymization and GDPR-related concerns, Jos Bloemers, Sennay Ghebreab, Adriaan Tuiten, Joram van Driel, Christian Olivers, Ilja Sligte, Sara Jahfari, Guido van Wingen, and Suzanne Oosterwijk for help with designing the paradigms, Marcus Spaan for technical support, and Franklin Feingold and Joe Wexler for help with uploading the datasets to OpenNeuro.</p>
<p><strong>Chapter 5</strong>, published as:</p>
<p>Oosterwijk, S., Snoek, L., Tekoppele, J., Engelbert, L. H., &amp; Scholte, H. S. (2020). Choosing to view morbid information involves reward circuitry. <em>Scientific reports, 10</em>(1), 1-13.</p>
<p>S.O., L.S., J.T., L.E. and H.S. developed the concept of the study, including the study design. S.O., L.S., J.T. and L.E. contributed to stimulus selection and programming. J.T. and L.E. collected the data. All authors contributed to the preparation of the preregistered analysis protocol and the data-analysis. S.O., L.S. and J.T. wrote the manuscript.</p>
<p><strong>Chapter 6</strong>, submitted as:</p>
<p>Snoek, L., Jack, R., Schyns, P., Garrod, O., Mittenbühler, M., Scholte, H.S., &amp; Oosterwijk, S. (submitted). Evaluating the universality of action unit based theories of categorical emotions. Submitted to <em>Nature Human Behavior</em>.</p>
<p>L.S., R.J., P.S., M.M., H.S.S., and S.O. were responsible for the conceptualization of the study. L.S., O.G., and M.M. developed the methods and implemented the formal analyses. All authors wrote the article.</p>
<p><strong>Chapter 7</strong>, manuscript in preparation:</p>
<p>Snoek., L, Mittenbühler, M., Jack, R., Schyns, P., Fischer, A., Scholte, H.S., &amp; Oosterwijk, S. (in prep.). Affective face perception integrates both static and dynamic information.</p>
<p>L.S., S.O., A.F., and H.S.S. were responsible for the conceptualization of the study. L.S. and M.M. developed the methods and implemented the formal analyses. All authors wrote the manuscript.</p>
<p>We thank Maite van der Miesen and Sjoerd Evelo for their help with data acquisition and Steven Miletić for helpful discussions regarding the Bayesian multivariate reverse correlation analyses.</p>
<p>* Shared first authorship</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="bibliography.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="list-of-other-publications.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
