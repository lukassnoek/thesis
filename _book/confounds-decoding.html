<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 How to control for confounds in decoding analyses of neuroimaging data | Learning from the brain</title>
  <meta name="description" content="3 How to control for confounds in decoding analyses of neuroimaging data | Learning from the brain" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 How to control for confounds in decoding analyses of neuroimaging data | Learning from the brain" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 How to control for confounds in decoding analyses of neuroimaging data | Learning from the brain" />
  
  
  

<meta name="author" content="Lukas Snoek" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="shared-states.html"/>
<link rel="next" href="AOMIC.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD thesis of Lukas Snoek</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-brain-is-not-a-dictionary"><i class="fa fa-check"></i><b>1.1</b> The brain is not a dictionary</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-brain-probably-does-not-care-about-your-hypothesis"><i class="fa fa-check"></i><b>1.2</b> The brain (probably) does not care about your hypothesis</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#interpretability-and-prediction-are-a-trade-off-for-now"><i class="fa fa-check"></i><b>1.3</b> Interpretability and prediction are a trade-off (for now)</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#exploration-should-be-embraced-more"><i class="fa fa-check"></i><b>1.4</b> Exploration should be embraced more</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#proper-generalization-is-hard"><i class="fa fa-check"></i><b>1.5</b> Proper generalization is hard</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#psychology-is-complex-so-it-needs-complex-models"><i class="fa fa-check"></i><b>1.6</b> Psychology is complex, so it needs complex models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="shared-states.html"><a href="shared-states.html"><i class="fa fa-check"></i><b>2</b> Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding</a><ul>
<li class="chapter" data-level="2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods"><i class="fa fa-check"></i><b>2.2</b> Methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-subjects"><i class="fa fa-check"></i><b>2.2.1</b> Subjects</a></li>
<li class="chapter" data-level="2.2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-experimental-design"><i class="fa fa-check"></i><b>2.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="2.2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-procedure"><i class="fa fa-check"></i><b>2.2.3</b> Procedure</a></li>
<li class="chapter" data-level="2.2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-image-acquisition"><i class="fa fa-check"></i><b>2.2.4</b> Image acquisition</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-model-optimization-procedure"><i class="fa fa-check"></i><b>2.3</b> Model optimization procedure</a><ul>
<li class="chapter" data-level="2.3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-preprocessing"><i class="fa fa-check"></i><b>2.3.1</b> Preprocessing and single-trial modeling</a></li>
<li class="chapter" data-level="2.3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-mvpa"><i class="fa fa-check"></i><b>2.3.2</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="2.3.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-additional-analyses"><i class="fa fa-check"></i><b>2.3.3</b> Additional analyses</a></li>
<li class="chapter" data-level="2.3.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-univariate-analysis"><i class="fa fa-check"></i><b>2.3.4</b> Univariate analysis</a></li>
<li class="chapter" data-level="2.3.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-code-availability"><i class="fa fa-check"></i><b>2.3.5</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-results"><i class="fa fa-check"></i><b>2.4</b> Results</a><ul>
<li class="chapter" data-level="2.4.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-mvpa"><i class="fa fa-check"></i><b>2.4.1</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="2.4.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-univariate"><i class="fa fa-check"></i><b>2.4.2</b> Univariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-discussion"><i class="fa fa-check"></i><b>2.5</b> Discussion</a></li>
<li class="chapter" data-level="2.6" data-path="shared-states.html"><a href="shared-states.html#shared-states-acknowledgements"><i class="fa fa-check"></i><b>2.6</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="confounds-decoding.html"><a href="confounds-decoding.html"><i class="fa fa-check"></i><b>3</b> How to control for confounds in decoding analyses of neuroimaging data</a><ul>
<li class="chapter" data-level="3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="AOMIC.html"><a href="AOMIC.html"><i class="fa fa-check"></i><b>4</b> The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses</a></li>
<li class="chapter" data-level="5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html"><i class="fa fa-check"></i><b>5</b> Choosing to view morbid information involves reward circuitry</a></li>
<li class="chapter" data-level="6" data-path="au-limitations.html"><a href="au-limitations.html"><i class="fa fa-check"></i><b>6</b> Using predictive modeling to quantify the importance and limitations of action units in emotion perception</a></li>
<li class="chapter" data-level="7" data-path="facial-expression-models.html"><a href="facial-expression-models.html"><i class="fa fa-check"></i><b>7</b> Comparing models of dynamic facial expression perception</a></li>
<li class="chapter" data-level="8" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html"><i class="fa fa-check"></i><b>8</b> Summary and general discussion</a><ul>
<li class="chapter" data-level="8.1" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html#explore"><i class="fa fa-check"></i><b>8.1</b> Explore!</a></li>
<li class="chapter" data-level="8.2" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html#think-big"><i class="fa fa-check"></i><b>8.2</b> Think <em>big</em></a></li>
<li class="chapter" data-level="8.3" data-path="summary-and-general-discussion.html"><a href="summary-and-general-discussion.html#rethink-psychology-education"><i class="fa fa-check"></i><b>8.3</b> Rethink psychology education</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html"><i class="fa fa-check"></i><b>A</b> Supplement to Chapter 2</a><ul>
<li class="chapter" data-level="A.1" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#stimuli-used-for-sf-task"><i class="fa fa-check"></i><b>A.1</b> Stimuli used for SF-task</a></li>
<li class="chapter" data-level="A.2" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#instructions"><i class="fa fa-check"></i><b>A.2</b> Instructions</a><ul>
<li class="chapter" data-level="A.2.1" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#full-instruction-for-the-other-focused-emotion-understanding-task"><i class="fa fa-check"></i><b>A.2.1</b> Full instruction for the other-focused emotion understanding task</a></li>
<li class="chapter" data-level="A.2.2" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#full-instruction-for-the-self-focused-emotion-imagery-task"><i class="fa fa-check"></i><b>A.2.2</b> Full instruction for the self-focused emotion imagery task</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#behavioral-results"><i class="fa fa-check"></i><b>A.3</b> Behavioral results</a></li>
<li class="chapter" data-level="A.4" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#optimization-results"><i class="fa fa-check"></i><b>A.4</b> Optimization results</a></li>
<li class="chapter" data-level="A.5" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#bagging-procedure"><i class="fa fa-check"></i><b>A.5</b> Bagging procedure</a></li>
<li class="chapter" data-level="A.6" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#precision-vs.-recall"><i class="fa fa-check"></i><b>A.6</b> Precision vs. recall</a></li>
<li class="chapter" data-level="A.7" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#self-vs.-other-classification"><i class="fa fa-check"></i><b>A.7</b> Self vs. other classification</a></li>
<li class="chapter" data-level="A.8" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#condition-average-results"><i class="fa fa-check"></i><b>A.8</b> Condition-average results</a></li>
<li class="chapter" data-level="A.9" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#individual-subject-scores"><i class="fa fa-check"></i><b>A.9</b> Individual subject scores</a></li>
<li class="chapter" data-level="A.10" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#brain-region-importance"><i class="fa fa-check"></i><b>A.10</b> Brain region importance</a></li>
<li class="chapter" data-level="A.11" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html#general-note-about-tables-with-voxel-coordinates"><i class="fa fa-check"></i><b>A.11</b> General note about tables with voxel-coordinates</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html"><i class="fa fa-check"></i><b>B</b> Supplement to Chapter 4</a></li>
<li class="chapter" data-level="C" data-path="morbid-curiosity-supplement.html"><a href="morbid-curiosity-supplement.html"><i class="fa fa-check"></i><b>C</b> Supplement to Chapter 5</a></li>
<li class="chapter" data-level="D" data-path="au-limitations-supplement.html"><a href="au-limitations-supplement.html"><i class="fa fa-check"></i><b>D</b> Supplement to Chapter 6</a></li>
<li class="chapter" data-level="E" data-path="facial-expression-models-supplement.html"><a href="facial-expression-models-supplement.html"><i class="fa fa-check"></i><b>E</b> Supplement to Chapter 6</a></li>
<li class="chapter" data-level="F" data-path="resources-supplement.html"><a href="resources-supplement.html"><i class="fa fa-check"></i><b>F</b> Data, code and materials</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="chapter" data-level="" data-path="contributions-to-the-chapters.html"><a href="contributions-to-the-chapters.html"><i class="fa fa-check"></i>Contributions to the chapters</a></li>
<li class="chapter" data-level="" data-path="list-of-other-publications.html"><a href="list-of-other-publications.html"><i class="fa fa-check"></i>List of other publications</a></li>
<li class="chapter" data-level="" data-path="nederlandse-samenvatting-summary-in-dutch.html"><a href="nederlandse-samenvatting-summary-in-dutch.html"><i class="fa fa-check"></i>Nederlandse samenvatting (Summary in Dutch)</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning from the brain</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="confounds-decoding" class="section level1">
<h1><span class="header-section-number">3</span> How to control for confounds in decoding analyses of neuroimaging data</h1>


<hr />

<p>
<em>This chapter has been published as</em>: Snoek, L.*, Miletić, S.*, &amp; Scholte, H.S. (2019). How to control for confounds in decoding analyses of neuroimaging data. <em>NeuroImage</em>, 184, 741-760.</p>
<p>* Shared first authorship</p>

<p><strong>Abstract</strong></p>
<p>Over the past decade, multivariate “decoding analyses” have become a popular alternative to traditional mass-univariate analyses in neuroimaging research. However, a fundamental limitation of using decoding analyses is that it remains ambiguous which source of information drives decoding performance, which becomes problematic when the to-be-decoded variable is confounded by variables that are not of primary interest. In this study, we use a comprehensive set of simulations as well as analyses of empirical data to evaluate two methods that were previously proposed and used to control for confounding variables in decoding analyses: post hoc counterbalancing and confound regression. In our empirical analyses, we attempt to decode gender from structural MRI data while controlling for the confound “brain size”. We show that both methods introduce strong biases in decoding performance: post hoc counterbalancing leads to better performance than expected (i.e., positive bias), which we show in our simulations is due to the subsampling process that tends to remove samples that are hard to classify or would be wrongly classified; confound regression, on the other hand, leads to worse performance than expected (i.e., negative bias), even resulting in significant below chance performance in some realistic scenarios. In our simulations, we show that below chance accuracy can be predicted by the variance of the distribution of correlations between the features and the target. Importantly, we show that this negative bias disappears in both the empirical analyses and simulations when the confound regression procedure is performed in every fold of the cross-validation routine, yielding plausible (above chance) model performance. We conclude that, from the various methods tested, cross-validated confound regression is the only method that appears to appropriately control for confounds which thus can be used to gain more insight into the exact source(s) of information driving one’s decoding analysis.</p>
<div id="confounds-decoding-introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>In the past decade, multivariate pattern analysis (MVPA) has emerged as a popular alternative to traditional univariate analyses of neuroimaging data <span class="citation">(Haxby, <a href="bibliography.html#ref-Haxby2012-sd" role="doc-biblioref">2012</a>; Norman et al., <a href="bibliography.html#ref-Norman2006-bt" role="doc-biblioref">2006</a><a href="bibliography.html#ref-Norman2006-bt" role="doc-biblioref">b</a>)</span>. The defining feature of MVPA is that it considers patterns of brain activation instead of single units of activation (i.e., voxels in MRI, sensors in MEG/EEG). One of the most-often used type of MVPA is “decoding”, in which machine learning algorithms are applied to neuroimaging data to predict a particular stimulus, task, or psychometric feature. For example, decoding analyses have been used to successfully predict various experimental conditions within subjects, such as object category from fMRI activity patterns <span class="citation">(Haxby et al., <a href="bibliography.html#ref-Haxby2001-os" role="doc-biblioref">2001</a>)</span> and working memory representations from EEG data <span class="citation">(LaRocque et al., <a href="bibliography.html#ref-LaRocque2013-sh" role="doc-biblioref">2013</a>)</span>, as well between-subject factors such as Alzheimer’s disease (vs. healthy controls) from structural MRI data <span class="citation">(Cuingnet et al., <a href="bibliography.html#ref-Cuingnet2011-hv" role="doc-biblioref">2011</a>)</span> and major depressive disorder (vs. healthy controls) from resting-state functional connectivity <span class="citation">(Craddock et al., <a href="bibliography.html#ref-Craddock2009-kz" role="doc-biblioref">2009</a>)</span>. One reason for the popularity of MVPA, and especially decoding, is that these methods appear to be more sensitive than traditional mass-univariate methods in detecting effects of interest. This increased sensitivity is often attributed to the ability to pick up multidimensional, spatially distributed representations which univariate methods, by definition, cannot do <span class="citation">(Jimura &amp; Poldrack, <a href="bibliography.html#ref-Jimura2012-lv" role="doc-biblioref">2012</a>)</span>. A second important reason to use decoding analyses is that they allow researchers to make predictions about samples beyond the original dataset, which is more difficult using traditional univariate analyses <span class="citation">(Hebart &amp; Baker, <a href="bibliography.html#ref-Hebart2017-jn" role="doc-biblioref">2017</a>)</span>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="shared-states.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="AOMIC.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
