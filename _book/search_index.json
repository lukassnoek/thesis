[
["index.html", "Learning from the brain Preface", " Learning from the brain Best practices for the use of neuroimaging data in psychology research Lukas Snoek maandag 21 oktober 2021 Preface This is the html output of the University of Amsterdam PhD thesis template from the amsterdown package. You can view access the pdf version(s) of the output from the toolbar above. This section will only show in the html version. Here you can add some general info about your thesis that’s typically included in the pdf. For example: who your supervisors were where the project was conducted the license the thesis is published under funding info an image of the cover of your thesis etc. For these and other ideas, see what this section looks like in my PhD thesis (and also check out the source file here). "],
["introduction.html", "1 Introduction 1.1 Learning from the brain", " 1 Introduction The first chapter of the thesis, which introduces your PhD project. The filler-text below was created with the postmodernism generator. 1.1 Learning from the brain When reading this thesis’ title, some might think that it contains a typo. Scientists want to learn about the brain, right? Not from the brain. Well, yes, neuroscientists do. But I am a psychologist at heart, interested in human behavior, cognition, and above all, emotion. I’m interested in the mind, not the brain. I don’t care about axons, neurotransmitters, and the basal ganglia. Sure, I do believe, like any proper scientist, that everything we feel, perceive, and do is instantiated in the brain, but I do not necessarily think that just studying the brain in isolation is going to teach us anything useful about the human psyche. Mind you, in this PhD you’ll find several studies that analyze brain data, but realize that my ultimate goal has always been to understand the mind. "],
["shared-states.html", "2 Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding 2.1 Introduction 2.2 Methods", " 2 Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding This chapter has been published as: Oosterwijk, S.*, Snoek, L.*, Rotteveel, M., Barrett, L. F., &amp; Scholte, H. S. (2017). Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding. Social cognitive and affective neuroscience, 12(7), 1025-1035. * Shared first authorship Abstract The present study tested whether the neural patterns that support imagining “performing an action”, “feeling a bodily sensation” or “being in a situation” are directly involved in understanding other people’s actions, bodily sensations and situations. Subjects imagined the content of short sentences describing emotional actions, interoceptive sensations and situations (self-focused task), and processed scenes and focused on how the target person was expressing an emotion, what this person was feeling, and why this person was feeling an emotion (other-focused task). Using a linear support vector machine classifier on brain-wide multi-voxel patterns, we accurately decoded each individual class in the self-focused task. When generalizing the classifier from the self-focused task to the other-focused task, we also accurately decoded whether subjects focused on the emotional actions, interoceptive sensations and situations of others. These results show that the neural patterns that underlie self-imagined experience are involved in understanding the experience of other people. This supports the theoretical assumption that the basic components of emotion experience and understanding share resources in the brain. 2.1 Introduction To navigate the social world successfully it is crucial to understand other people. But how do people generate meaningful representations of other people’s actions, sensations, thoughts and emotions? The dominant view assumes that representations of other people’s experiences are supported by the same neural systems as those that are involved in generating experience in the self (e.g., Gallese et al., 2004; see for an overview Singer, 2012). We tested this principle of self-other neural overlap directly, using multi-voxel pattern analysis (MVPA), across three different aspects of experience that are central to emotions: actions, sensations from the body and situational knowledge. In recent years, evidence has accumulated that suggests a similarity between the neural patterns representing the self and others. For example, a great variety of studies have shown that observing actions and sensations in other people engages similar neural circuits as acting and feeling in the self (see for an overview Bastiaansen et al., 2009). Moreover, an extensive research program on pain has demonstrated an overlap between the experience of physical pain and the observation of pain in other people, utilizing both neuroimaging techniques (e.g., Lamm et al., 2011) and analgesic interventions (e.g., Rütgen et al., 2015; Mischkowski et al., 2016). This process of “vicarious experience” or “simulation” is viewed as an important component of empathy (Carr et al., 2003; Decety, 2011; Keysers &amp; Gazzola, 2014). In addition, it is argued that mentalizing (e.g. understanding the mental states of other people) involves the same brain networks as those involved in self-generated thoughts (Uddin et al., 2007; Waytz &amp; Mitchell, 2011). Specifying this idea further, a constructionist view on emotion proposes that both emotion experience and interpersonal emotion understanding are produced by the same large-scale distributed brain networks that support the processing of sensorimotor, interoceptive and situationally relevant information (Barrett &amp; Satpute, 2013; Oosterwijk &amp; Barrett, 2014). An implication of these views is that the representation of self- and other-focused emotional actions, interoceptive sensations and situations overlap in the brain. Although there is experimental and theoretical support for the idea of self-other neural overlap, the present study is the first to directly test this process using MVPA across three different aspects of experience (i.e. actions, interoceptive sensations and situational knowledge). Our experimental design consisted of two different tasks aimed at generating self- and other-focused representations with a relatively large weight given to either action information, interoceptive information or situational information. In the self-focused emotion imagery task (SF-task) subjects imagined performing or experiencing actions (e.g., pushing someone away), interoceptive sensations (e.g., increased heart rate) and situations (e.g., alone in a park at night) associated with emotion. Previous research has demonstrated that processing linguistic descriptions of (emotional) actions and feeling states can result in neural patterns of activation associated with, respectively, the representation and generation of actions and internal states (Oosterwijk et al., 2015; Pulvermüller &amp; Fadiga, 2010). Furthermore, imagery-based inductions of emotion have been successfully used in the MRI scanner before (Oosterwijk et al., 2012; Wilson-Mendenhall et al., 2011), and are seen as robust inducers of emotional experience (Lench et al., 2011). In the other-focused emotion understanding task (OF-task), subjects viewed images of people in emotional situations and focused on actions (i.e., How does this person express his/her emotions?), interoceptive sensations (i.e., What does this person feel in his/her body) or the situation (i.e., Why does this person feel an emotion?). This task is based on previous research studying the neural basis of emotion oriented mentalizing (Spunt &amp; Lieberman, 2012). With MVPA, we examined to what extent the SF- and OF-task evoked similar neural patterns. MVPA allows researchers to assess whether the neural pattern associated with one set of experimental conditions can be used to distinguish between another set of experimental conditions. This relatively novel technique has been successfully applied to the field of social neuroscience in general (e.g., Gilbert et al., 2012; Brosch et al., 2013; Parkinson et al., 2014), and the field of self-other neural overlap in particular. For example, several MVPA studies recently assessed whether experiencing pain and observing pain in others involved similar neural patterns (Corradi-Dell’Acqua et al., 2016; Krishnan et al., 2016). Although there is an ongoing discussion about the specifics of shared representation in pain based on these MVPA results (see for an overview Zaki et al., 2016), many authors emphasize the importance of this technique in the scientific study of self-other neural overlap (e.g., Corradi-Dell’Acqua et al., 2016; Krishnan et al., 2016). MVPA is an analysis technique that decodes latent categories from fMRI data in terms of multi-voxel patterns of activity (Norman et al., 2006). This technique is particularly suited for our research question for several reasons. First of all, although univariate techniques can demonstrate that tasks activate the same brain regions, only MVPA can statistically test for shared representation (Lamm &amp; Majdandžić, 2015). We will evaluate whether multivariate brain patterns that distinguish between mental events in the SF-task can be used to distinguish, above chance level, between mental events in the OF-task. Second, MVPA analyses are particularly useful in research that is aimed at examining distributed representations (Singer, 2012). Based on our constructionist framework, we indeed hypothesize that the neural patterns that will represent self- and other focused mental events are distributed across large-scale brain networks. To capture these distributed patterns, we used MVPA in combination with data-driven univariate feature selection on whole-brain voxel patterns, instead of limiting our analysis to specific regions-of-interest (Haynes, 2015). And third, in contrast to univariate analyses that aggregate data across subjects, MVPA can be performed within-subjects and is thus able to incorporate individual variation in the representational content of multivariate brain patterns. In that aspect within-subject MVPA is sensitive to individual differences in how people imagine actions, sensations and situations, and how they understand others. In short, for our purpose to explicitly test the assumption that self and other focused processes share neural resources, MVPA is the designated method. We tested the following two hypotheses. First, we tested whether we could classify self-imagined actions, interoceptive sensations and situations above chance level. Second, we tested whether the multivariate pattern underlying this classification could also be used to classify the how, what and why condition in the other-focused task. 2.2 Methods 2.2.1 Subjects In total, we tested 22 Dutch undergraduate students from the University of Amsterdam (14 females; Mage = 21.48, s.d.age = 1.75). Of those 22 subjects, 13 subjects were tested twice in 2 sessions about 1 week apart. Half of those sessions were used for the model optimization procedure. The other half of the sessions, combined with an additional nine subjects (who were tested only once), constituted the model validation set (see Model optimization procedure section). In total, two subjects were excluded from the model validation dataset: one subject was excluded because there was not enough time to complete the experimental protocol and another subject was excluded due to excessive movement (&gt;3 mm within data acquisition runs). All subjects signed informed consent prior to the experiment. The experiment was approved by the University of Amsterdam’s ethical review board. Subjects received 22.50 euro per session. Standard exclusion criteria regarding MRI safety were applied and people who were on psychopharmacological medication were excluded a priori. 2.2.2 Experimental design 2.2.2.1 Self-focused emotion imagery task The self-focused emotion imagery task (SF-task) was created to preferentially elicit self-focused processing of action, interoceptive or situational information associated with emotion. Subjects processed short linguistic cues that described actions (e.g., pushing someone away; making a fist), interoceptive sensations (e.g., being out of breath; an increased heart rate), or situations (e.g., alone in a park at night; being falsely accused) and were instructed to imagine performing or experiencing the content. The complete instruction is presented in the Supplementary Materials; all stimuli used in the SF-task are presented in Supplementary Table S1. Linguistic cues were selected from a pilot study performed on an independent sample of subjects (n = 24). Details about this pilot study are available on request. The descriptions generated in this pilot study were used as qualitative input to create short sentences that described actions, sensations or situations that were associated with negative emotions, without including discrete emotion terms. The cues did not differ in number of words, nor in number of characters (F &lt; 1). "],
["confounds-decoding.html", "3 How to control for confounds in decoding analyses of neuroimaging data", " 3 How to control for confounds in decoding analyses of neuroimaging data "],
["AOMIC.html", "4 The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses", " 4 The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses "],
["morbid-curiosity.html", "5 Choosing to view morbid information involves reward circuitry", " 5 Choosing to view morbid information involves reward circuitry "],
["au-limitations.html", "6 Using predictive modeling to quantify the importance and limitations of action units in emotion perception", " 6 Using predictive modeling to quantify the importance and limitations of action units in emotion perception "],
["facial-expression-models.html", "7 Comparing models of dynamic facial expression perception", " 7 Comparing models of dynamic facial expression perception "],
["summary-and-general-discussion.html", "8 Summary and general discussion", " 8 Summary and general discussion "],
["shared-states-supplement.html", "A Supplement to Chapter 2 A.1 Stimuli used for SF-task A.2 Full instruction for the other-focused emotion understanding task A.3 Full instruction for the self-focused emotion imagery task", " A Supplement to Chapter 2 A.1 Stimuli used for SF-task Table A.1: Stimuli used for SF-task Class Dutch English translation Action Hard wegrennen Running away fast Iemand wegduwen Pushing someone away Iemand stevig vastpakken Holding someone tightly Je hoofd schudden Shaking your head Heftige armgebaren maken Making big arm gestures Ergens voor terugdeinzen Recoiling from something Je ogen dichtknijpen Closing your eyes tightly Je ogen wijd open sperren Opening your eyes widely Je wenkbrauwen fronsen Frowning with your eyebrows Je schouders ophalen Raising your shoulders Op de vloer stampen Stamping on the floor In elkaar duiken Cowering Je schouders laten hangen Slumping your shoulders Je vuisten ballen Tighten your fists Je borst vooruit duwen Push your chest forward Je tanden op elkaar zetten Clench your teeth Je hand voor je mond slaan Put your hand in front of your mouth Onrustig bewegen Moving restlessly Heen en weer lopen Walking back and forth Je hoofd afkeren Turning your head away Interoception Een brok in je keel A lump in your throat Buiten adem zijn Being out of breath Een versnelde hartslag A fast beating heart Je hart klopt in de keel You heart is beating in your throat Een benauwd gevoel An oppressed feeling Een misselijk gevoel Being nauseous Druk op je borst A pressure on your chest Strak aangespannen spieren Tense muscles Een droge keel A dry throat Koude rillingen hebben Cold shivers Bloed stroomt naar je hoofd Blood is going to your head Een verdoofd gevoel A numb feeling Je hebt tintelende ledenmaten Tingling limbs Een verlaagde hartslag A slow heartbeat Je hebt zware ledematen Heavy limbs Een versnelde ademhaling Fast breathing Je hebt hoofdpijn Headache Je hebt buikpijn Stomachache Zweet staat in je handen Sweaty palms Je maag keert zich om Your stomach churns Situation Vals beschuldigd worden Being falsely accused Dierbare overlijdt A loved one dies Vlees is bedorven Meat that has gone off Je wordt bijna aangereden You are almost hit by a car Iemand naast je braakt Someone next to you vomits Huis staat in brand House is on fire Zonder reden ontslagen worden Being fired for no reason Een ongemakkelijke stilte An uncomfortable silence Alleen in donker park Alone in a dark park Inbraak in je huis A house burglary Een gewond dier zien Seeing a wounded animal Tentamen verknallen Messing up your exam Je partner bedriegt je You partner cheats on you Dierbare is vermist A loved one is missing Belangrijke sollicitatie vergeten Forgot a job interview Onvoorbereid presentatie geven Giving a presentation unprepared Je baas beledigt je Your boss offends you Goede vriend negeert je A good friend neglects you Slecht nieuws bij arts Bad news at the doctor Bommelding in metro A bomb alarm in the metro Note: The stimulus materials presented in Table S1 were selected from a pilot study. In this pilot study we asked an independent sample of twenty-four subjects to describe how they would express an emotion in their behavior, body posture or facial expression (action information), what specific sensations they would feel inside their body when they would experience an emotion (interoceptive information), and for what reason or in what situation they would experience an emotion (situational information). These three questions were asked in random order for twenty-eight different negative emotional states, including anger, fear, disgust, sadness, contempt, worry, disappointment, regret and shame. The descriptions generated by these subjects were used as qualitative input in order to create our stimulus set of twenty short sentences that described emotional actions, sensations or situations. With this procedure, we ensured that our stimulus set held sentences that were validated and ecologically appropriate for our sample. A.2 Full instruction for the other-focused emotion understanding task Translated from Dutch; task presented first. In this study we are interested in how the brain responds when people understand the emotions of others in different ways. In the scanner you will see images that display emotional situations, sometimes with multiple people. In every image one person will be marked with a red square. While viewing the image we ask you to focus on the emotion of that person in three different ways. With some images we ask you to focus on HOW this person expresses his or her emotion. Here we ask you to identify expressions in the face or body that are informative about the emotional state that the person is experiencing. With other images we ask you to focus on WHAT this person may feel in his or her body. Here we ask you to identify sensations, such as a change in heart rate, breathing or other internal feeling, that the person might feel in this situation. With other images we ask you to focus on WHY this person experiences an emotion. Here we ask you to identify a specific reason or cause that explains why the person feels what he or she feels. Every image will be presented for six seconds. During this period we ask you to silently focus on HOW this person expresses emotion, WHAT this person feels in his/her body, and WHY this person feels an emotion. Before you will enter the scanner we will practice. I will show you three images and will ask you to perform each of the three instructions out loud. It is important to note that there are no correct or incorrect answers, it is about how you interpret the image. For the success of the study it is very important that you apply the HOW, WHAT or WHY instruction for each image. Please do not skip any images and try to apply each instruction with the same motivation. It is also important to treat every image separately, although it is possible that you have similar interpretations for different images. The three instructions are combined with the images in blocks. In every block you will see five images with the same instruction. Each block will start with a cue that tells you what to focus on in that block. Each image is combined with all three instructions, so you will see the same image multiple times. In between images you will sometimes see a black screen for a longer period of time. Do you have any questions? A.3 Full instruction for the self-focused emotion imagery task Translated from Dutch; task presented second. In this study we are interested in how the brain responds when people imagine different aspects of emotion. In the scanner you will see sentences that describe aspects of emotional experience. We ask you to try to imagine the content of each sentence as rich and detailed as possible. Some sentences describe actions and expressions. We ask you to imagine that you are performing this action or expression. Other sentences describe sensations or feelings that you can have inside your body. We ask you to imagine that you are experiencing this sensation or feeling. Other sentences describe emotional situations. We ask you to imagine that you are experiencing this specific situation. We ask you to always imagine that YOU have the experience. Thus, it is about imagining an action or expression of your body, a sensation inside your body, or a situation that you are part of. I will give some examples now. For each sentence you have six seconds to imagine the content. All sentences will be presented twice. In between sentences you will sometimes see a black screen for a longer period of time. For this experiment to succeed it is important that you imagine each sentence with the same motivation, even if you have seen the sentence before. Please do not skip sentences. Do you have any questions? Figure A.1: Mean percentage of trials successfully executed for the SF-task (left panel) and OF-task (right panel). Error bars indicate 95% confidence intervals. A one-way ANOVA of the success-rates of the SF-task (left-panel) indicated no significant overall differences, F(2, 17) = 1.03, p = 0.38. In the OF-task (right panel) however, a one-way ANOVA indicated that success-rates differed significantly between classes, F(2, 17) = 17.74, p &lt; 0.001. Follow-up pairwise comparisons (Bonferroni corrected, two tailed) revealed that interoception-trials (M = 74.00, SE = 2.10) were significantly less successful (p &lt; 0.001) than both action-trials (M = 85.50, SE = 1.85) and situation trials (M = 90.00, SE = 1.92). "],
["confounds-decoding-supplement.html", "B Supplement to Chapter 4", " B Supplement to Chapter 4 "],
["morbid-curiosity-supplement.html", "C Supplement to Chapter 5", " C Supplement to Chapter 5 "],
["au-limitations-supplement.html", "D Supplement to Chapter 6", " D Supplement to Chapter 6 "],
["facial-expression-models-supplement.html", "E Supplement to Chapter 6", " E Supplement to Chapter 6 "],
["resources-supplement.html", "F Data, code and materials", " F Data, code and materials "],
["bibliography.html", "Bibliography", " Bibliography Barrett, L. F., &amp; Satpute, A. B. (2013). Large-scale brain networks in affective and social neuroscience: Towards an integrative functional architecture of the brain. Current Opinion in Neurobiology, 23(3), 361–372. Bastiaansen, J. A., Thioux, M., &amp; Keysers, C. (2009). Evidence for mirror systems in emotions. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1528), 2391–2404. Brosch, T., Bar-David, E., &amp; Phelps, E. A. (2013). Implicit race bias decreases the similarity of neural representations of black and white faces. Psychological Science, 24(2), 160–166. Carr, L., Iacoboni, M., Dubeau, M.-C., Mazziotta, J. C., &amp; Lenzi, G. L. (2003). Neural mechanisms of empathy in humans: A relay from neural systems for imitation to limbic areas. Proceedings of the National Academy of Sciences, 100(9), 5497–5502. Corradi-Dell’Acqua, C., Tusche, A., Vuilleumier, P., &amp; Singer, T. (2016). Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex. Nature Communications, 7(1), 1–12. Decety, J. (2011). Dissecting the neural mechanisms mediating empathy. Emotion Review, 3(1), 92–108. Gallese, V., Keysers, C., &amp; Rizzolatti, G. (2004). A unifying view of the basis of social cognition. Trends in Cognitive Sciences, 8(9), 396–403. Gilbert, S. J., Swencionis, J. K., &amp; Amodio, D. M. (2012). Evaluative vs. Trait representation in intergroup social judgments: Distinct roles of anterior temporal lobe and prefrontal cortex. Neuropsychologia, 50(14), 3600–3611. Haynes, J.-D. (2015). A primer on pattern-based approaches to fMRI: Principles, pitfalls, and perspectives. Neuron, 87(2), 257–270. Keysers, C., &amp; Gazzola, V. (2014). Dissociating the ability and propensity for empathy. Trends in Cognitive Sciences, 18(4), 163–166. Krishnan, A., Woo, C.-W., Chang, L. J., Ruzic, L., Gu, X., López-Solà, M., Jackson, P. L., Pujol, J., Fan, J., &amp; Wager, T. D. (2016). Somatic and vicarious pain are represented by dissociable multivariate brain patterns. Elife, 5, e15166. Lamm, C., Decety, J., &amp; Singer, T. (2011). Meta-analytic evidence for common and distinct neural networks associated with directly experienced pain and empathy for pain. Neuroimage, 54(3), 2492–2502. Lamm, C., &amp; Majdandžić, J. (2015). The role of shared neural activations, mirror neurons, and morality in empathy–a critical comment. Neuroscience Research, 90, 15–24. Lench, H. C., Flores, S. A., &amp; Bench, S. W. (2011). Discrete emotions predict changes in cognition, judgment, experience, behavior, and physiology: A meta-analysis of experimental emotion elicitations. Psychological Bulletin, 137(5), 834. Mischkowski, D., Crocker, J., &amp; Way, B. M. (2016). From painkiller to empathy killer: Acetaminophen (paracetamol) reduces empathy for pain. Social Cognitive and Affective Neuroscience, 11(9), 1345–1353. Norman, K. A., Polyn, S. M., Detre, G. J., &amp; Haxby, J. V. (2006). Beyond mind-reading: Multi-voxel pattern analysis of fMRI data. Trends in Cognitive Sciences, 10(9), 424–430. Oosterwijk, S., &amp; Barrett, L. F. (2014). Embodiment in the construction of emotion experience and emotion understanding. Routledge Handbook of Embodied Cognition. New York: Routledge, 250–260. Oosterwijk, S., Lindquist, K. A., Anderson, E., Dautoff, R., Moriguchi, Y., &amp; Barrett, L. F. (2012). States of mind: Emotions, body feelings, and thoughts share distributed neural networks. NeuroImage, 62(3), 2110–2128. Oosterwijk, S., Mackey, S., Wilson-Mendenhall, C., Winkielman, P., &amp; Paulus, M. P. (2015). Concepts in context: Processing mental state concepts with internal or external focus involves different neural systems. Social Neuroscience, 10(3), 294–307. Parkinson, C., Liu, S., &amp; Wheatley, T. (2014). A common cortical metric for spatial, temporal, and social distance. Journal of Neuroscience, 34(5), 1979–1987. Pulvermüller, F., &amp; Fadiga, L. (2010). Active perception: Sensorimotor circuits as a cortical basis for language. Nature Reviews Neuroscience, 11(5), 351–360. Rütgen, M., Seidel, E.-M., Silani, G., Riečansky, I., Hummer, A., Windischberger, C., Petrovic, P., &amp; Lamm, C. (2015). Placebo analgesia and its opioidergic regulation suggest that empathy for pain is grounded in self pain. Proceedings of the National Academy of Sciences, 112(41), E5638–E5646. Singer, T. (2012). The past, present and future of social neuroscience: A european perspective. Neuroimage, 61(2), 437–449. Spunt, R. P., &amp; Lieberman, M. D. (2012). An integrative model of the neural systems supporting the comprehension of observed emotional behavior. Neuroimage, 59(3), 3050–3059. Uddin, L. Q., Iacoboni, M., Lange, C., &amp; Keenan, J. P. (2007). The self and social cognition: The role of cortical midline structures and mirror neurons. Trends in Cognitive Sciences, 11(4), 153–157. Waytz, A., &amp; Mitchell, J. P. (2011). Two mechanisms for simulating other minds: Dissociations between mirroring and self-projection. Current Directions in Psychological Science, 20(3), 197–200. Wilson-Mendenhall, C. D., Barrett, L. F., Simmons, W. K., &amp; Barsalou, L. W. (2011). Grounding emotion in situated conceptualization. Neuropsychologia, 49(5), 1105–1127. Zaki, J., Wager, T. D., Singer, T., Keysers, C., &amp; Gazzola, V. (2016). The anatomy of suffering: Understanding the relationship between nociceptive and empathic pain. Trends in Cognitive Sciences, 20(4), 249–259. "],
["contributions-to-the-chapters.html", "Contributions to the chapters", " Contributions to the chapters "],
["list-of-other-publications.html", "List of other publications", " List of other publications Alilović, J., Timmermans, B., Reteig, L. C., van Gaal, S., &amp; Slagter, H. A. (2019). No evidence that predictions and attention modulate the first feedforward sweep of cortical information processing. Cerebral Cortex, 29 2261–2278. https://doi.org/10.1093/cercor/bhz038 van Schouwenburg, M. R., Sörensen, L. K. A., de Klerk, R., Reteig, L. C., &amp; Slagter, H. A. (2018). No differential effects of two different alpha-band electrical stimulation protocols over fronto-parietal regions on spatial attention. Frontiers in Neuroscience 12:433. https://doi.org/10.3389/fnins.2018.00433 Slagter, H. A., Mazaheri, A., Reteig, L. C., Smolders, R., Figee, M., Mantione, M., … Denys, D. (2017). Contributions of the Ventral Striatum to Conscious Perception: An Intracranial EEG Study of the Attentional Blink. Journal of Neuroscience, 37, 1081–1089. https://doi.org/10.1523/jneurosci.2282-16.2016 Slagter, H. A., Prinssen, S., Reteig, L. C., &amp; Mazaheri, A. (2016). Facilitation and inhibition in attention: Functional dissociation of pre-stimulus alpha activity, P1, and N1 components. NeuroImage, 125, 25–35. https://doi.org/10.1016/j.neuroimage.2015.09.058 "],
["nederlandse-samenvatting-summary-in-dutch.html", "Nederlandse samenvatting (Summary in Dutch)", " Nederlandse samenvatting (Summary in Dutch) Replace this with the Dutch title of your thesis The summary goes here. "],
["acknowledgments.html", "Acknowledgments", " Acknowledgments This section is optional, but theses typically include acknowledgments (dankwoord in Dutch) at the end. You may want to mix languages to thank people in their native tongue (though most Dutch speakers write it entirely in Dutch). But the standard language of the thesis template is English. You can switch temporarily by wrapping the text in language tags like so: [Your Dutch text here]{lang=nl}. This is important for things like hyphenation to work properly. "]
]
