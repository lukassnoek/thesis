```{r setup-hypothesis-kernel-analysis-supplement, include=FALSE}
knitr::opts_chunk$set(results = 'hide', echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(kableExtra)
```

`r if (knitr::is_html_output()) '
# Supplement to Chapter 6 {#hypothesis-kernel-analysis-supplement}
' else '
# Supplement to Chapter \\@ref(hypothesis-kernel-analysis) {#hypothesis-kernel-analysis-supplement}
'`

## Supplementary methods {#hka-supplementary-methods}

Below, we describe the methodology behind hypothesis kernel analysis and noise ceiling estimation in more detail.

### Hypothesis kernel analysis (in detail)

#### Step 1: encoding mappings

The first step in our method is the embedding of hypotheses in a common space. In the context of AU-emotion mappings, this amounts to formalizing these mappings as points in “AU space”. Here, AU space is a multidimensional space in which each of the AUs under consideration represents one dimension and each AU-emotion mapping (e.g., “disgust = AU9 + AU10”) can be represented as a single point in this space. For example, suppose that we only consider a limited set of five AUs (AU4, AU9, AU10, AU12, and AU23). We then can represent the hypothetical mapping “disgust = AU9 + AU10”, $\mathbf{M}_{\mathrm{disgust}}$, as a point with five coordinates (i.e., a vector), which value indicates whether a given AU is part of the hypothesized configuration (1) or not (0):

\begin{equation}
\mathbf{M}_{\mathrm{disgust}} = \begin{bmatrix} 0 & 1 & 1 & 0 & 0 & 0 \end{bmatrix}
\end{equation}

Note that, in the above example, values at the positions of hypothesized AUs are all encoded as 1, which implies that each AU within the configuration is expressed equally intensely. This does not have to be the case; if, for example, the aforementioned mapping hypothesized that disgust is expressed with a combination of AU9 at 100% intensity but AU10 at 50% intensity, then its embedding can be expressed as follows:

\begin{equation}
\mathbf{M}_{\mathrm{disgust}} = \begin{bmatrix} 0 & 1 & .5 & 0 & 0 & 0 \end{bmatrix}
\end{equation}

For simplicity, we assume in this example that each hypothesized AU is expressed at equal intensity (such that vectors are binary). Importantly, many studies outline mappings with regard to multiple emotions, which we will refer to here as classes. For this example, we assume that our hypothetical mapping $\mathbf{M}$ limits its mappings to the six basic emotions. Specifically, suppose that mapping $\mathbf{M}$ outlines, in addition the the previously defined happiness mapping, specific hypothetical AU-emotion mappings for the following categorical emotions:

* anger = AU4 + AU5 + AU7
* disgust = AU9 + AU15
* fear = AU1 + AU2 + AU4 + AU7 + AU26
* sadness = AU1 + AU4 + AU15
* surprise = AU1 + AU2 + AU5 + AU26

Accordingly, we can encode the entire set of AU-emotion mappings for a given mapping, $\mathbf{M}$, with $C$ classes and $D$ dimensions into a $C \times D$ matrix, by vertically stacking the $C$ different row mapping vectors. For our hypothetical mapping, $\mathbf{M}$, its associated “mapping matrix” would look like the following:

\begin{equation}
\mathbf{M} = \begin{bmatrix}
0 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\
1 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\end{equation}

where its rows represent the different classes (categorical emotions) and the columns the involvement of a specific AU. Note that although the above represents a hypothetical mapping, its sparsity is something we would expect, as facial expressions are unlikely to be generated by a full (dense) set of action units [@Yu2012-ag].

#### Step 2: encoding stimuli

In the previous section we outlined how to formalize AU-emotion mappings as points (or, equivalently, vectors) in AU space. One way to *evaluate* these formalized mappings is to subject them to actual categorical emotion ratings from human participants in response to stimuli with known AU configurations. Ideally, the stimuli from such an experiment sample the AU space as densely and uniformly as possible in order not to bias the results towards hypothesized mappings. Many experiments on facial emotion expressions, however, use posed and stereotyped stimuli (e.g., facial expressions of intense joy or anger), which cover only a small part of the entire AU space and thus do not allow for unbiased evaluation of AU-based theories. In contrast, reverse correlation-based experiments, which are characterized by randomly and parametrically varying the input space (defined by AU configurations) and collection of resulting percepts (here: perception of categorical emotion) do not impose such constraints [@Jack2017-qp] and thus present an ideal type of dataset to subject to our formalized AU-emotion mappings.

In reference to our previously defined hypothetical 10-dimensional AU space, assume that we have categorical emotion ratings $e$ from a set of emotions $E$ ($e \in E$) in response to a collection of $N$ facial expression stimuli parameterized with random AU configurations, drawn from the same 10-dimensional AU space discussed before. With such data, we can encode the stimuli in AU space in the same way we did in the previous section for AU-emotion mappings, i.e., we can quantify each stimulus, $\mathbf{S}_{i}$, as a 10-dimensional “stimulus vector” containing nonzero values at positions associated with active AUs for that stimulus and zeros elsewhere. Note that, as is the case with mapping vectors, the stimulus vector’s nonzero values at positions associated with active AUs can be all ones (if assumed to be equally “active”) or be values proportional to the amplitude (or “activity”) of the active AUs.

For example, suppose that stimulus $\mathbf{S}_{i}$ contains AU1, AU5, and AU26 with amplitudes 0.1, 0.5, and 0.8 respectively (where an amplitude of 1 would represent an AU at maximum intensity). Then, formally, we can represent this particular stimulus, $\mathbf{S}_{i}$, as the following stimulus vector:

\begin{equation}
\mathbf{S}_{i} = \begin{bmatrix} .1 & 0 & 0 & .5 & 0 & 0 & 0 & 0 & 0 & .8 \end{bmatrix}
\end{equation}

In case of multiple stimuli ($\mathbf{S}_{i}$ for $i = \{1, \dots, N\}$), their mapping vectors can be vertically stacked in a single $N \times D$ “stimulus matrix”, $\mathbf{S}$.

Given that both a mapping ($\mathbf{M}$) and set of stimuli ($\mathbf{S}$) are encoded as matrices in the same $D$-dimensional AU space, we can discuss using kernels to generate quantitative predictors for stimuli given a particular theory.

#### Step 3: kernel functions

Kernel functions (or simply kernels) are functions that are, broadly speaking, measures of similarity between two vectors. Applied to our use case, we use kernel functions ($\kappa$) to quantify the similarity, i.e. “closeness” in AU space, ($\phi$) between a stimulus with a known AU configuration ($\mathbf{S}_{i}$) and a mapping vector for a specific emotion, indexed by $j$ ($\mathbf{M}_{j}$, e.g., happiness)^[Instead of using measures of similarity between two vectors (i.e., “kernels”), one could use measures of *distances* ($\delta_{ij}$) between two vectors instead and subsequently invert it to get a similarity score again, i.e., $\phi_{ij} = \delta_{ij}^{-1}$. In practice, we find that it does not make much of a difference in terms of predictive performance (see Supplementary Figure \@ref(fig:fig-hka-S3)).]:

\begin{equation}
\phi_{ij} = \kappa(\mathbf{S}_{i}, \mathbf{M}_{j})
\end{equation}

Most (linear) kernel functions are based on the dot (inner) product between the two vectors. In the current study, we primarily use the cosine kernel, which normalizes the dot product between two vectors with the product of their L2 (Euclidean) norm:

\begin{equation}
\kappa(\mathbf{S}_{i}, \mathbf{M}_{j}) = \frac{\mathbf{S}_{i}\mathbf{M}_{j}^{T}}{\left\Vert \mathbf{S}_{i} \right\Vert \left\Vert \mathbf{M}_{j} \right\Vert}
\end{equation}

Without such normalization, similarity values monotonically increase with increasing magnitudes of the stimulus vector, even if the stimulus vector increasingly deviates from the mapping.

#### Step 4: computing predictions

Although the similarity to a particular mapping vector can, generally speaking, be interpreted as being proportional to the evidence for that particular class, it is not strictly speaking a prediction. To generate a quantitative prediction for stimulus $\mathbf{S}_{i}$ (i.e., $\hat{e}_{i}$), one needs to formulate a decision function that maps the data to a prediction. One possibility is to determine the prediction to be the emotion (across $C$ classes) that maximizes its similarity, for some kernel function ($\kappa$), to the stimulus:

\begin{equation}
\hat{e}_{i} = \underset{j}{\operatorname{\argmax}} \kappa(\mathbf{S}_{i}, \mathbf{M}_{j})
\end{equation}