<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Bibliography | Towards prediction</title>
  <meta name="description" content="Bibliography | Towards prediction" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Bibliography | Towards prediction" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bibliography | Towards prediction" />
  
  
  

<meta name="author" content="Lukas Snoek" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="resources-supplement.html"/>
<link rel="next" href="contributions-to-the-chapters.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD thesis of Lukas Snoek</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="general-introduction.html"><a href="general-introduction.html#inference-done-differently"><i class="fa fa-check"></i><b>1.1</b> Inference done differently</a></li>
<li class="chapter" data-level="1.2" data-path="general-introduction.html"><a href="general-introduction.html#towards-prediction"><i class="fa fa-check"></i><b>1.2</b> Towards prediction</a></li>
<li class="chapter" data-level="1.3" data-path="general-introduction.html"><a href="general-introduction.html#outline-of-this-thesis"><i class="fa fa-check"></i><b>1.3</b> Outline of this thesis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="shared-states.html"><a href="shared-states.html"><i class="fa fa-check"></i><b>2</b> Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding</a><ul>
<li class="chapter" data-level="2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods"><i class="fa fa-check"></i><b>2.2</b> Methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-subjects"><i class="fa fa-check"></i><b>2.2.1</b> Subjects</a></li>
<li class="chapter" data-level="2.2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-experimental-design"><i class="fa fa-check"></i><b>2.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="2.2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-procedure"><i class="fa fa-check"></i><b>2.2.3</b> Procedure</a></li>
<li class="chapter" data-level="2.2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-image-acquisition"><i class="fa fa-check"></i><b>2.2.4</b> Image acquisition</a></li>
<li class="chapter" data-level="2.2.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-model-optimization-procedure"><i class="fa fa-check"></i><b>2.2.5</b> Model optimization procedure</a></li>
<li class="chapter" data-level="2.2.6" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-preprocessing"><i class="fa fa-check"></i><b>2.2.6</b> Preprocessing and single-trial modeling</a></li>
<li class="chapter" data-level="2.2.7" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-mvpa"><i class="fa fa-check"></i><b>2.2.7</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="2.2.8" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-additional-analyses"><i class="fa fa-check"></i><b>2.2.8</b> Additional analyses</a></li>
<li class="chapter" data-level="2.2.9" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-univariate-analysis"><i class="fa fa-check"></i><b>2.2.9</b> Univariate analysis</a></li>
<li class="chapter" data-level="2.2.10" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-code-availability"><i class="fa fa-check"></i><b>2.2.10</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-results"><i class="fa fa-check"></i><b>2.3</b> Results</a><ul>
<li class="chapter" data-level="2.3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-mvpa"><i class="fa fa-check"></i><b>2.3.1</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="2.3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-univariate"><i class="fa fa-check"></i><b>2.3.2</b> Univariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-discussion"><i class="fa fa-check"></i><b>2.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="confounds-decoding.html"><a href="confounds-decoding.html"><i class="fa fa-check"></i><b>3</b> How to control for confounds in decoding analyses of neuroimaging data</a><ul>
<li class="chapter" data-level="3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-true-vs-confounded"><i class="fa fa-check"></i><b>3.1.1</b> Partitioning effects into <em>true</em> signal and <em>confounded</em> signal</a></li>
<li class="chapter" data-level="3.1.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-methods"><i class="fa fa-check"></i><b>3.1.2</b> Methods for confound control</a></li>
<li class="chapter" data-level="3.1.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-current-study"><i class="fa fa-check"></i><b>3.1.3</b> Current study</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-data"><i class="fa fa-check"></i><b>3.2.1</b> Data</a></li>
<li class="chapter" data-level="3.2.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-pipeline"><i class="fa fa-check"></i><b>3.2.2</b> Decoding pipeline</a></li>
<li class="chapter" data-level="3.2.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-evaluated-methods"><i class="fa fa-check"></i><b>3.2.3</b> Evaluated methods for confound control</a></li>
<li class="chapter" data-level="3.2.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#analyses-of-simulated-data"><i class="fa fa-check"></i><b>3.2.4</b> Analyses of simulated data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#results"><i class="fa fa-check"></i><b>3.3</b> Results</a><ul>
<li class="chapter" data-level="3.3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#influence-of-brain-size"><i class="fa fa-check"></i><b>3.3.1</b> Influence of brain size</a></li>
<li class="chapter" data-level="3.3.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#baseline-model-no-confound-control"><i class="fa fa-check"></i><b>3.3.2</b> Baseline model: no confound control</a></li>
<li class="chapter" data-level="3.3.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#post-hoc-counterbalancing"><i class="fa fa-check"></i><b>3.3.3</b> Post hoc counterbalancing</a></li>
<li class="chapter" data-level="3.3.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#whole-dataset-confound-regression-wdcr"><i class="fa fa-check"></i><b>3.3.4</b> Whole-dataset confound regression (WDCR)</a></li>
<li class="chapter" data-level="3.3.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#cross-validated-confound-regression-cvcr"><i class="fa fa-check"></i><b>3.3.5</b> Cross-validated confound regression (CVCR)</a></li>
<li class="chapter" data-level="3.3.6" data-path="confounds-decoding.html"><a href="confounds-decoding.html#summary-methods-for-confound-control"><i class="fa fa-check"></i><b>3.3.6</b> Summary methods for confound control</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-discussion"><i class="fa fa-check"></i><b>3.4</b> Discussion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#relevance-and-consequences-for-previous-and-future-research"><i class="fa fa-check"></i><b>3.4.1</b> Relevance and consequences for previous and future research</a></li>
<li class="chapter" data-level="3.4.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#choosing-a-confound-model-linear-vs.-nonlinear-models"><i class="fa fa-check"></i><b>3.4.2</b> Choosing a confound model: linear vs. nonlinear models</a></li>
<li class="chapter" data-level="3.4.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#practical-recommendations"><i class="fa fa-check"></i><b>3.4.3</b> Practical recommendations</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#conclusion"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="aomic.html"><a href="aomic.html"><i class="fa fa-check"></i><b>4</b> The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses</a><ul>
<li class="chapter" data-level="4.1" data-path="aomic.html"><a href="aomic.html#background-summary"><i class="fa fa-check"></i><b>4.1</b> Background &amp; summary</a></li>
<li class="chapter" data-level="4.2" data-path="aomic.html"><a href="aomic.html#methods"><i class="fa fa-check"></i><b>4.2</b> Methods</a><ul>
<li class="chapter" data-level="4.2.1" data-path="aomic.html"><a href="aomic.html#scanner-details-and-general-scanning-protocol-all-datasets"><i class="fa fa-check"></i><b>4.2.1</b> Scanner details and general scanning protocol (all datasets)</a></li>
<li class="chapter" data-level="4.2.2" data-path="aomic.html"><a href="aomic.html#id1000-specifics"><i class="fa fa-check"></i><b>4.2.2</b> ID1000 specifics</a></li>
<li class="chapter" data-level="4.2.3" data-path="aomic.html"><a href="aomic.html#piop1-and-piop2-specifics"><i class="fa fa-check"></i><b>4.2.3</b> PIOP1 and PIOP2 specifics</a></li>
<li class="chapter" data-level="4.2.4" data-path="aomic.html"><a href="aomic.html#subject-variables-all-datasets"><i class="fa fa-check"></i><b>4.2.4</b> Subject variables (all datasets)</a></li>
<li class="chapter" data-level="4.2.5" data-path="aomic.html"><a href="aomic.html#psychometric-variables-all-datasets"><i class="fa fa-check"></i><b>4.2.5</b> Psychometric variables (all datasets)</a></li>
<li class="chapter" data-level="4.2.6" data-path="aomic.html"><a href="aomic.html#aomic-derivatives"><i class="fa fa-check"></i><b>4.2.6</b> Data standardization, preprocessing, and derivatives</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="aomic.html"><a href="aomic.html#data-records"><i class="fa fa-check"></i><b>4.3</b> Data records</a><ul>
<li class="chapter" data-level="4.3.1" data-path="aomic.html"><a href="aomic.html#data-formats-and-types"><i class="fa fa-check"></i><b>4.3.1</b> Data formats and types</a></li>
<li class="chapter" data-level="4.3.2" data-path="aomic.html"><a href="aomic.html#data-repositories-used"><i class="fa fa-check"></i><b>4.3.2</b> Data repositories used</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="aomic.html"><a href="aomic.html#technical-validation"><i class="fa fa-check"></i><b>4.4</b> Technical validation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="aomic.html"><a href="aomic.html#t1-weighted-scans"><i class="fa fa-check"></i><b>4.4.1</b> T1-weighted scans</a></li>
<li class="chapter" data-level="4.4.2" data-path="aomic.html"><a href="aomic.html#functional-bold-scans"><i class="fa fa-check"></i><b>4.4.2</b> Functional (BOLD) scans</a></li>
<li class="chapter" data-level="4.4.3" data-path="aomic.html"><a href="aomic.html#diffusion-weighted-scans"><i class="fa fa-check"></i><b>4.4.3</b> Diffusion-weighted scans</a></li>
<li class="chapter" data-level="4.4.4" data-path="aomic.html"><a href="aomic.html#physiological-data"><i class="fa fa-check"></i><b>4.4.4</b> Physiological data</a></li>
<li class="chapter" data-level="4.4.5" data-path="aomic.html"><a href="aomic.html#psychometric-data"><i class="fa fa-check"></i><b>4.4.5</b> Psychometric data</a></li>
<li class="chapter" data-level="4.4.6" data-path="aomic.html"><a href="aomic.html#aomic-code-availability"><i class="fa fa-check"></i><b>4.4.6</b> Code availability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html"><i class="fa fa-check"></i><b>5</b> Choosing to view morbid information involves reward circuitry</a><ul>
<li class="chapter" data-level="5.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods"><i class="fa fa-check"></i><b>5.2</b> Methods</a><ul>
<li class="chapter" data-level="5.2.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-participants"><i class="fa fa-check"></i><b>5.2.1</b> Participants</a></li>
<li class="chapter" data-level="5.2.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-design"><i class="fa fa-check"></i><b>5.2.2</b> Design</a></li>
<li class="chapter" data-level="5.2.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-materials"><i class="fa fa-check"></i><b>5.2.3</b> Materials</a></li>
<li class="chapter" data-level="5.2.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-procedure"><i class="fa fa-check"></i><b>5.2.4</b> Procedure</a></li>
<li class="chapter" data-level="5.2.5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-behavioral-analysis"><i class="fa fa-check"></i><b>5.2.5</b> Behavioral analysis</a></li>
<li class="chapter" data-level="5.2.6" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-imaging-details"><i class="fa fa-check"></i><b>5.2.6</b> Imaging details</a></li>
<li class="chapter" data-level="5.2.7" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-data-availability"><i class="fa fa-check"></i><b>5.2.7</b> Data availability</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results"><i class="fa fa-check"></i><b>5.3</b> Results</a><ul>
<li class="chapter" data-level="5.3.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results-participants"><i class="fa fa-check"></i><b>5.3.1</b> Participants</a></li>
<li class="chapter" data-level="5.3.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#behavior-and-subjective-report"><i class="fa fa-check"></i><b>5.3.2</b> Behavior and subjective report</a></li>
<li class="chapter" data-level="5.3.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#roi-analyses"><i class="fa fa-check"></i><b>5.3.3</b> ROI analyses</a></li>
<li class="chapter" data-level="5.3.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#whole-brain-analyses"><i class="fa fa-check"></i><b>5.3.4</b> Whole-brain analyses</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-discussion"><i class="fa fa-check"></i><b>5.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html"><i class="fa fa-check"></i><b>6</b> Explainable models of facial movements predict emotion perception behavior</a><ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#the-prediction-explanation-exploration-framework"><i class="fa fa-check"></i><b>6.1.1</b> The prediction-explanation-exploration framework</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-methods"><i class="fa fa-check"></i><b>6.2</b> Methods</a><ul>
<li class="chapter" data-level="6.2.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hypothesis-kernel-analysis-1"><i class="fa fa-check"></i><b>6.2.1</b> Hypothesis kernel analysis</a></li>
<li class="chapter" data-level="6.2.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#ablation-and-follow-up-exploration-analyses"><i class="fa fa-check"></i><b>6.2.2</b> Ablation and follow-up exploration analyses</a></li>
<li class="chapter" data-level="6.2.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-noise-ceiling"><i class="fa fa-check"></i><b>6.2.3</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="6.2.4" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#evaluated-mappings"><i class="fa fa-check"></i><b>6.2.4</b> Evaluated mappings</a></li>
<li class="chapter" data-level="6.2.5" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-dataset"><i class="fa fa-check"></i><b>6.2.5</b> Dataset used to evaluate mappings</a></li>
<li class="chapter" data-level="6.2.6" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-code"><i class="fa fa-check"></i><b>6.2.6</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-results"><i class="fa fa-check"></i><b>6.3</b> Results</a><ul>
<li class="chapter" data-level="6.3.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#prediction"><i class="fa fa-check"></i><b>6.3.1</b> Prediction</a></li>
<li class="chapter" data-level="6.3.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#explanation"><i class="fa fa-check"></i><b>6.3.2</b> Explanation</a></li>
<li class="chapter" data-level="6.3.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#exploration"><i class="fa fa-check"></i><b>6.3.3</b> Exploration</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-discussion"><i class="fa fa-check"></i><b>6.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html"><i class="fa fa-check"></i><b>7</b> Affective face perception integrates both static and dynamic information</a><ul>
<li class="chapter" data-level="7.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-methods"><i class="fa fa-check"></i><b>7.2</b> Methods</a><ul>
<li class="chapter" data-level="7.2.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-participants"><i class="fa fa-check"></i><b>7.2.1</b> Participants</a></li>
<li class="chapter" data-level="7.2.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-experimental-design"><i class="fa fa-check"></i><b>7.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="7.2.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-procedure"><i class="fa fa-check"></i><b>7.2.3</b> Procedure</a></li>
<li class="chapter" data-level="7.2.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-data-preproc"><i class="fa fa-check"></i><b>7.2.4</b> Data preprocessing</a></li>
<li class="chapter" data-level="7.2.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-pred-analysis"><i class="fa fa-check"></i><b>7.2.5</b> Predictive analysis</a></li>
<li class="chapter" data-level="7.2.6" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#noise-ceiling-estimation"><i class="fa fa-check"></i><b>7.2.6</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="7.2.7" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-bayes"><i class="fa fa-check"></i><b>7.2.7</b> Bayesian reconstructions</a></li>
<li class="chapter" data-level="7.2.8" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-code"><i class="fa fa-check"></i><b>7.2.8</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-results"><i class="fa fa-check"></i><b>7.3</b> Results</a><ul>
<li class="chapter" data-level="7.3.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#encoding-model-performance"><i class="fa fa-check"></i><b>7.3.1</b> Encoding model performance</a></li>
<li class="chapter" data-level="7.3.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#reconstruction-model-visualizations"><i class="fa fa-check"></i><b>7.3.2</b> Reconstruction model visualizations</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-discussion"><i class="fa fa-check"></i><b>7.4</b> Discussion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#facial-morphology-independently-contributes-to-affective-face-perception"><i class="fa fa-check"></i><b>7.4.1</b> Facial morphology independently contributes to affective face perception</a></li>
<li class="chapter" data-level="7.4.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#the-influence-of-facial-morphology-does-not-result-from-visual-similarity-to-facial-movements"><i class="fa fa-check"></i><b>7.4.2</b> The influence of facial morphology does not result from visual similarity to facial movements</a></li>
<li class="chapter" data-level="7.4.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#categorical-representations-of-experienced-valence-and-arousal-correlate-with-representations-of-perceived-emotions"><i class="fa fa-check"></i><b>7.4.3</b> Categorical representations of experienced valence and arousal correlate with representations of perceived emotions</a></li>
<li class="chapter" data-level="7.4.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#predictive-models-quantify-what-is-not-yet-known"><i class="fa fa-check"></i><b>7.4.4</b> Predictive models quantify what is (not yet) known</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i><b>8</b> Discussion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html"><i class="fa fa-check"></i><b>A</b> Supplement to Chapter 2</a></li>
<li class="chapter" data-level="B" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html"><i class="fa fa-check"></i><b>B</b> Supplement to Chapter 3</a><ul>
<li class="chapter" data-level="B.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-methods"><i class="fa fa-check"></i><b>B.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="B.1.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#functional-mri-simulation"><i class="fa fa-check"></i><b>B.1.1</b> Functional MRI simulation</a></li>
<li class="chapter" data-level="B.1.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data"><i class="fa fa-check"></i><b>B.1.2</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.1.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation"><i class="fa fa-check"></i><b>B.1.3</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.1.4" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs-nonlinear-confound-models-predicting-vbm-and-tbss-data-based-on-brain-size"><i class="fa fa-check"></i><b>B.1.4</b> Linear vs nonlinear confound models: predicting VBM and TBSS data based on brain size</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-results"><i class="fa fa-check"></i><b>B.2</b> Supplementary results</a><ul>
<li class="chapter" data-level="B.2.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data-1"><i class="fa fa-check"></i><b>B.2.1</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.2.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation-1"><i class="fa fa-check"></i><b>B.2.2</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.2.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs.-nonlinear-confound-models-predicting-vbm-and-tbss-intensity-using-brain-size"><i class="fa fa-check"></i><b>B.2.3</b> Linear vs. nonlinear confound models: predicting VBM and TBSS intensity using brain size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="aomic-supplement.html"><a href="aomic-supplement.html"><i class="fa fa-check"></i><b>C</b> Supplement to Chapter 4</a></li>
<li class="chapter" data-level="D" data-path="morbid-curiosity-supplement.html"><a href="morbid-curiosity-supplement.html"><i class="fa fa-check"></i><b>D</b> Supplement to Chapter 5</a></li>
<li class="chapter" data-level="E" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html"><i class="fa fa-check"></i><b>E</b> Supplement to Chapter 6</a><ul>
<li class="chapter" data-level="E.1" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-supplementary-methods"><i class="fa fa-check"></i><b>E.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="E.1.1" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hypothesis-kernel-analysis-in-detail"><i class="fa fa-check"></i><b>E.1.1</b> Hypothesis kernel analysis (in detail)</a></li>
<li class="chapter" data-level="E.1.2" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-noise-ceiling-detail"><i class="fa fa-check"></i><b>E.1.2</b> Noise ceiling estimation (in detail)</a></li>
</ul></li>
<li class="chapter" data-level="E.2" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-supp-fig"><i class="fa fa-check"></i><b>E.2</b> Supplementary figures</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="static-vs-dynamic-supplement.html"><a href="static-vs-dynamic-supplement.html"><i class="fa fa-check"></i><b>F</b> Supplement to Chapter 7</a></li>
<li class="chapter" data-level="G" data-path="resources-supplement.html"><a href="resources-supplement.html"><i class="fa fa-check"></i><b>G</b> Data, code, and educational materials</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="chapter" data-level="" data-path="contributions-to-the-chapters.html"><a href="contributions-to-the-chapters.html"><i class="fa fa-check"></i>Contributions to the chapters</a></li>
<li class="chapter" data-level="" data-path="list-of-other-publications.html"><a href="list-of-other-publications.html"><i class="fa fa-check"></i>List of other publications</a></li>
<li class="chapter" data-level="" data-path="nederlandse-samenvatting-summary-in-dutch.html"><a href="nederlandse-samenvatting-summary-in-dutch.html"><i class="fa fa-check"></i>Nederlandse samenvatting (Summary in Dutch)</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Towards prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bibliography" class="section level1 unnumbered">
<h1>Bibliography</h1>

<div id="refs">
<div id="ref-Abdulkadir2014-bh">
<p>Abdulkadir, A., Ronneberger, O., Tabrizi, S. J., &amp; Klöppel, S. (2014). Reduction of confounding effects with voxel-wise gaussian process regression in structural MRI. <em>2014 International Workshop on Pattern Recognition in Neuroimaging</em>, 1–4.</p>
</div>
<div id="ref-abdulrahman2016effect">
<p>Abdulrahman, H., &amp; Henson, R. N. (2016). Effect of trial-to-trial variability on optimal event-related fMRI design: Implications for beta-series correlation and multi-voxel pattern analysis. <em>NeuroImage</em>, <em>125</em>, 756–766.</p>
</div>
<div id="ref-Abraham2014-ef">
<p>Abraham, A., Pedregosa, F., Eickenberg, M., Gervais, P., Mueller, A., Kossaifi, J., Gramfort, A., Thirion, B., &amp; Varoquaux, G. (2014). Machine learning for neuroimaging with scikit-learn. <em>Front. Neuroinform.</em>, <em>8</em>, 14.</p>
</div>
<div id="ref-Adams2016-tz">
<p>Adams, R. B., Jr, Garrido, C. O., Albohn, D. N., Hess, U., &amp; Kleck, R. E. (2016). What facial appearance reveals over time: When perceived expressions in neutral faces reveal stable emotion dispositions. <em>Front. Psychol.</em>, <em>7</em>, 986.</p>
</div>
<div id="ref-Adams2012-dl">
<p>Adams, R. B., Jr, Nelson, A. J., Soto, J. A., Hess, U., &amp; Kleck, R. E. (2012). Emotion in the neutral face: A mechanism for impression formation? <em>Cogn. Emot.</em>, <em>26</em>(3), 431–441.</p>
</div>
<div id="ref-Adjerid2018-vs">
<p>Adjerid, I., &amp; Kelley, K. (2018). Big data in psychology: A framework for research advancement. <em>Am. Psychol.</em>, <em>73</em>(7), 899–917.</p>
</div>
<div id="ref-Aliko2020-ry">
<p>Aliko, S., Huang, J., Gheorghiu, F., Meliss, S., &amp; Skipper, J. I. (2020). A naturalistic neuroimaging database for understanding the brain using ecological stimuli. <em>Sci Data</em>, <em>7</em>(1), 347.</p>
</div>
<div id="ref-alizadeh2017decoding">
<p>Alizadeh, S., Jamalabadi, H., Schönauer, M., Leibold, C., &amp; Gais, S. (2017). Decoding cognitive concepts from neuroimaging data using multivariate pattern analysis. <em>Neuroimage</em>, <em>159</em>, 449–458.</p>
</div>
<div id="ref-Allefeld2016-xp">
<p>Allefeld, C., Görgen, K., &amp; Haynes, J.-D. (2016). Valid population inference for information-based imaging: From the second-level t-test to prevalence inference. <em>Neuroimage</em>, <em>141</em>, 378–392.</p>
</div>
<div id="ref-allefeld2014searchlight">
<p>Allefeld, C., &amp; Haynes, J.-D. (2014). Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated manova. <em>Neuroimage</em>, <em>89</em>, 345–357.</p>
</div>
<div id="ref-Allen2021-zd">
<p>Allen, E. J., St-Yves, G., Wu, Y., Breedlove, J. L., Dowdle, L. T., &amp; others. (2021). A massive 7T fMRI dataset to bridge cognitive and computational neuroscience. <em>bioRxiv</em>.</p>
</div>
<div id="ref-amat2005medial">
<p>Amat, J., Baratta, M. V., Paul, E., Bland, S. T., Watkins, L. R., &amp; Maier, S. F. (2005). Medial prefrontal cortex determines how stressor controllability affects behavior and dorsal raphe nucleus. <em>Nature Neuroscience</em>, <em>8</em>(3), 365–371.</p>
</div>
<div id="ref-Amthauer2001-yg">
<p>Amthauer, R., Brocke, B., Liepmann, D., &amp; Beauducel, A. (2001). <em>Intelligenz-Struktur-Test 2000 R</em> (Vol. 2). Hogrefe.</p>
</div>
<div id="ref-anderson2016precis">
<p>Anderson, M. L. (2016). Précis of after phrenology: Neural reuse and the interactive brain. <em>Behavioral and Brain Sciences</em>, <em>39</em>.</p>
</div>
<div id="ref-Andersson2016-nm">
<p>Andersson, J. L. R., Graham, M. S., Zsoldos, E., &amp; Sotiropoulos, S. N. (2016). Incorporating outlier detection and replacement into a non-parametric framework for movement and distortion correction of diffusion MR images. <em>Neuroimage</em>, <em>141</em>, 556–572.</p>
</div>
<div id="ref-Andersson2007-st">
<p>Andersson, J. L. R., Jenkinson, M., Smith, S., &amp; Others. (2007). Non-linear registration, aka spatial normalisation FMRIB technical report TR07JA2. <em>FMRIB Analysis Group of the University of Oxford</em>, <em>2</em>(1), e21.</p>
</div>
<div id="ref-Andersson2016-pg">
<p>Andersson, J. L. R., &amp; Sotiropoulos, S. N. (2016). An integrated approach to correction for off-resonance effects and subject movement in diffusion MR imaging. <em>Neuroimage</em>, <em>125</em>, 1063–1078.</p>
</div>
<div id="ref-andrews2014default">
<p>Andrews-Hanna, J. R., Smallwood, J., &amp; Spreng, R. N. (2014). The default network and self-generated thought: Component processes, dynamic control, and clinical relevance. <em>Annals of the New York Academy of Sciences</em>, <em>1316</em>(1), 29.</p>
</div>
<div id="ref-Atkinson1997-eu">
<p>Atkinson, D., Hill, D. L., Stoyle, P. N., Summers, P. E., &amp; Keevil, S. F. (1997). Automatic correction of motion artifacts in magnetic resonance images using an entropy focus criterion. <em>IEEE Trans. Med. Imaging</em>, <em>16</em>(6), 903–910.</p>
</div>
<div id="ref-Avants2008-bv">
<p>Avants, B. B., Epstein, C. L., Grossman, M., &amp; Gee, J. C. (2008). Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain. <em>Med. Image Anal.</em>, <em>12</em>(1), 26–41.</p>
</div>
<div id="ref-Babayan2019-mo">
<p>Babayan, A., Erbey, M., Kumral, D., Reinelt, J. D., Reiter, A. M. F., Röbbig, J., Schaare, H. L., Uhlig, M., Anwander, A., Bazin, P.-L., Horstmann, A., Lampe, L., Nikulin, V. V., Okon-Singer, H., Preusser, S., Pampel, A., Rohr, C. S., Sacher, J., Thöne-Otto, A., … Villringer, A. (2019). A mind-brain-body dataset of MRI, EEG, cognition, emotion, and peripheral physiology in young and old adults. <em>Sci Data</em>, <em>6</em>, 180308.</p>
</div>
<div id="ref-bach2012knowing">
<p>Bach, D. R., &amp; Dolan, R. J. (2012). Knowing how much you don’t know: A neural organization of uncertainty estimates. <em>Nature Reviews Neuroscience</em>, <em>13</em>(8), 572–586.</p>
</div>
<div id="ref-baker2018deep">
<p>Baker, N., Lu, H., Erlikhman, G., &amp; Kellman, P. J. (2018). Deep convolutional networks do not classify based on global object shape. <em>PLoS Computational Biology</em>, <em>14</em>(12), e1006613.</p>
</div>
<div id="ref-Bangalore2008-kc">
<p>Bangalore, S. S., Prasad, K. M. R., Montrose, D. M., Goradia, D. D., Diwadkar, V. A., &amp; Keshavan, M. S. (2008). Cannabis use and brain structural alterations in first episode schizophrenia—a region of interest, voxel based morphometric study. <em>Schizophr. Res.</em>, <em>99</em>(1), 1–6.</p>
</div>
<div id="ref-Barman2019-af">
<p>Barman, A., &amp; Dutta, P. (2019). Facial expression recognition using distance and texture signature relevant features. <em>Appl. Soft Comput.</em>, <em>77</em>, 88–105.</p>
</div>
<div id="ref-Barnes2010-pu">
<p>Barnes, J., Ridgway, G. R., Bartlett, J., Henley, S. M. D., Lehmann, M., Hobbs, N., Clarkson, M. J., MacManus, D. G., Ourselin, S., &amp; Fox, N. C. (2010). Head size, age and gender adjustment in MRI studies: A necessary nuisance? <em>Neuroimage</em>, <em>53</em>(4), 1244–1255.</p>
</div>
<div id="ref-barrett2012emotions">
<p>Barrett, L. F. (2012). Emotions are real. <em>Emotion</em>, <em>12</em>(3), 413.</p>
</div>
<div id="ref-Barrett2019-bc">
<p>Barrett, L. F., Adolphs, R., Marsella, S., Martinez, A. M., &amp; Pollak, S. D. (2019). Emotional expressions reconsidered: Challenges to inferring emotion from human facial movements. <em>Psychol. Sci. Public Interest</em>, <em>20</em>(1), 1–68.</p>
</div>
<div id="ref-barrett2013large">
<p>Barrett, L. F., &amp; Satpute, A. B. (2013). Large-scale brain networks in affective and social neuroscience: Towards an integrative functional architecture of the brain. <em>Current Opinion in Neurobiology</em>, <em>23</em>(3), 361–372.</p>
</div>
<div id="ref-barrett2015interoceptive">
<p>Barrett, L. F., &amp; Simmons, W. K. (2015). Interoceptive predictions in the brain. <em>Nature Reviews Neuroscience</em>, <em>16</em>(7), 419–429.</p>
</div>
<div id="ref-barsalou2009simulation">
<p>Barsalou, L. W. (2009). Simulation, situated conceptualization, and prediction. <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em>, <em>364</em>(1521), 1281–1289.</p>
</div>
<div id="ref-bartra2013valuation">
<p>Bartra, O., McGuire, J. T., &amp; Kable, J. W. (2013). The valuation system: A coordinate-based meta-analysis of bold fMRI experiments examining neural correlates of subjective value. <em>Neuroimage</em>, <em>76</em>, 412–427.</p>
</div>
<div id="ref-bastiaansen2009evidence">
<p>Bastiaansen, J. A., Thioux, M., &amp; Keysers, C. (2009). Evidence for mirror systems in emotions. <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em>, <em>364</em>(1528), 2391–2404.</p>
</div>
<div id="ref-Bastiani2019-sm">
<p>Bastiani, M., Cottaar, M., Fitzgibbon, S. P., Suri, S., Alfaro-Almagro, F., Sotiropoulos, S. N., Jbabdi, S., &amp; Andersson, J. L. R. (2019). Automated quality control for within and between studies diffusion MRI data using a non-parametric framework for movement and distortion correction. <em>Neuroimage</em>, <em>184</em>, 801–812.</p>
</div>
<div id="ref-baumeister2001bad">
<p>Baumeister, R. F., Bratslavsky, E., Finkenauer, C., &amp; Vohs, K. D. (2001). Bad is stronger than good. <em>Review of General Psychology</em>, <em>5</em>(4), 323–370.</p>
</div>
<div id="ref-Beckmann2009-rs">
<p>Beckmann, C. F., Mackay, C. E., Filippini, N., &amp; Smith, S. M. (2009). Group comparison of resting-state FMRI data using multi-subject ICA and dual regression. <em>Neuroimage</em>, <em>47</em>, S148.</p>
</div>
<div id="ref-Behzadi2007-eb">
<p>Behzadi, Y., Restom, K., Liau, J., &amp; Liu, T. T. (2007). A component based noise correction method (CompCor) for BOLD and perfusion based fMRI. <em>Neuroimage</em>, <em>37</em>(1), 90–101.</p>
</div>
<div id="ref-bench2019boredom">
<p>Bench, S. W., &amp; Lench, H. C. (2019). Boredom as a seeking state: Boredom prompts the pursuit of novel (even negative) experiences. <em>Emotion</em>, <em>19</em>(2), 242.</p>
</div>
<div id="ref-Benitez-Quiroz2018-vr">
<p>Benitez-Quiroz, C. F., Srinivasan, R., &amp; Martinez, A. M. (2018). Facial color is an efficient mechanism to visually transmit emotion. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>115</em>(14), 3581–3586.</p>
</div>
<div id="ref-Van_Bergen2015-kl">
<p>Bergen, R. S. van, Ma, W. J., Pratte, M. S., &amp; Jehee, J. F. M. (2015). Sensory uncertainty decoded from visual cortex predicts behavior. <em>Nat. Neurosci.</em>, <em>18</em>(12), 1728–1730.</p>
</div>
<div id="ref-berlyne1966curiosity">
<p>Berlyne, D. E. (1966). Curiosity and exploration. <em>Science</em>, <em>153</em>(3731), 25–33.</p>
</div>
<div id="ref-berridge2009dissecting">
<p>Berridge, K. C., Robinson, T. E., &amp; Aldridge, J. W. (2009). Dissecting components of reward:“Liking”,“wanting”, and learning. <em>Current Opinion in Pharmacology</em>, <em>9</em>(1), 65–73.</p>
</div>
<div id="ref-Betancourt2017-rj">
<p>Betancourt, M. (2017). <em>A conceptual introduction to hamiltonian monte carlo</em>. <a href="http://arxiv.org/abs/1701.02434">http://arxiv.org/abs/1701.02434</a></p>
</div>
<div id="ref-binder2009semantic">
<p>Binder, J. R., Desai, R. H., Graves, W. W., &amp; Conant, L. L. (2009). Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. <em>Cerebral Cortex</em>, <em>19</em>(12), 2767–2796.</p>
</div>
<div id="ref-Birn2008-ti">
<p>Birn, R. M., Smith, M. A., Jones, T. B., &amp; Bandettini, P. A. (2008). The respiration response function: The temporal dynamics of fMRI signal fluctuations related to changes in respiration. <em>Neuroimage</em>, <em>40</em>(2), 644–654.</p>
</div>
<div id="ref-Borsboom2013-wb">
<p>Borsboom, D., &amp; Cramer, A. O. J. (2013). Network analysis: An integrative approach to the structure of psychopathology. <em>Annu. Rev. Clin. Psychol.</em>, <em>9</em>, 91–121.</p>
</div>
<div id="ref-Borsboom2020-xg">
<p>Borsboom, D., Maas, H. van der, Dalege, J., Kievit, R., &amp; Haig, B. (2020). <em>Theory construction methodology: A practical framework for theory formation in psychology</em>.</p>
</div>
<div id="ref-brand2015beyond">
<p>Brand, A., Allen, L., Altman, M., Hlava, M., &amp; Scott, J. (2015). Beyond authorship: Attribution, contribution, collaboration, and credit. <em>Learned Publishing</em>, <em>28</em>(2), 151–155.</p>
</div>
<div id="ref-braver2014mechanisms">
<p>Braver, T. S., Krug, M. K., Chiew, K. S., Kool, W., Westbrook, J. A., Clement, N. J., Adcock, R. A., Barch, D. M., Botvinick, M. M., Carver, C. S., &amp; others. (2014). Mechanisms of motivation–cognition interaction: Challenges and opportunities. <em>Cognitive, Affective, &amp; Behavioral Neuroscience</em>, <em>14</em>(2), 443–472.</p>
</div>
<div id="ref-breiman1996bagging">
<p>Breiman, L. (1996). Bagging predictors. <em>Machine Learning</em>, <em>24</em>(2), 123–140.</p>
</div>
<div id="ref-Breiman2001-lf">
<p>Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). <em>SSO Schweiz. Monatsschr. Zahnheilkd.</em>, <em>16</em>(3), 199–231.</p>
</div>
<div id="ref-Brinkman2017-hg">
<p>Brinkman, L., Todorov, A., &amp; Dotsch, R. (2017). Visualising mental representations: A primer on noise-based reverse correlation in social psychology. <em>European Review of Social Psychology</em>, <em>28</em>(1), 333–361.</p>
</div>
<div id="ref-brodtmann2009regional">
<p>Brodtmann, A., Puce, A., Darby, D., &amp; Donnan, G. (2009). Regional fMRI brain activation does correlate with global brain volume. <em>Brain Research</em>, <em>1259</em>, 17–25.</p>
</div>
<div id="ref-Brooks2018-ao">
<p>Brooks, J. A., Stolier, R. M., &amp; Freeman, J. B. (2018). Stereotypes bias visual prototypes for sex and emotion categories. <em>Soc. Cogn.</em>, <em>36</em>(5), 481–493.</p>
</div>
<div id="ref-brosch2013implicit">
<p>Brosch, T., Bar-David, E., &amp; Phelps, E. A. (2013). Implicit race bias decreases the similarity of neural representations of black and white faces. <em>Psychological Science</em>, <em>24</em>(2), 160–166.</p>
</div>
<div id="ref-Bryant2019-sg">
<p>Bryant, D., &amp; Howard, A. (2019). A comparative analysis of Emotion-Detecting AI systems with respect to algorithm performance and dataset diversity. <em>Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society</em>, 377–382.</p>
</div>
<div id="ref-buhle2014cognitive">
<p>Buhle, J. T., Silvers, J. A., Wager, T. D., Lopez, R., Onyemekwu, C., Kober, H., Weber, J., &amp; Ochsner, K. N. (2014). Cognitive reappraisal of emotion: A meta-analysis of human neuroimaging studies. <em>Cerebral Cortex</em>, <em>24</em>(11), 2981–2990.</p>
</div>
<div id="ref-Button2013-zu">
<p>Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., &amp; Munafò, M. R. (2013). Power failure: Why small sample size undermines the reliability of neuroscience. <em>Nat. Rev. Neurosci.</em>, <em>14</em>(5), 365–376.</p>
</div>
<div id="ref-Bzdok2017-li">
<p>Bzdok, D. (2017). Classical statistics and statistical learning in imaging neuroscience. <em>Front. Neurosci.</em>, <em>11</em>, 543.</p>
</div>
<div id="ref-Carlson2015-bz">
<p>Carlson, T. A., &amp; Wardle, S. G. (2015). Sensible decoding. <em>Neuroimage</em>, <em>110</em>, 217–218.</p>
</div>
<div id="ref-carr2003neural">
<p>Carr, L., Iacoboni, M., Dubeau, M.-C., Mazziotta, J. C., &amp; Lenzi, G. L. (2003). Neural mechanisms of empathy in humans: A relay from neural systems for imitation to limbic areas. <em>Proceedings of the National Academy of Sciences</em>, <em>100</em>(9), 5497–5502.</p>
</div>
<div id="ref-Carver1994-wp">
<p>Carver, C. S., &amp; White, T. L. (1994). Behavioral inhibition, behavioral activation, and affective responses to impending reward and punishment: The BIS/BAS scales. <em>J. Pers. Soc. Psychol.</em>, <em>67</em>(2), 319–333.</p>
</div>
<div id="ref-Chang2009-vu">
<p>Chang, C., Cunningham, J. P., &amp; Glover, G. H. (2009). Influence of heart rate on the BOLD signal: The cardiac response function. <em>Neuroimage</em>, <em>44</em>(3), 857–869.</p>
</div>
<div id="ref-Chekroud2016-tc">
<p>Chekroud, A. M., Ward, E. J., Rosenberg, M. D., &amp; Holmes, A. J. (2016). Patterns in the human brain mosaic discriminate males from females. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>113</em>(14), E1968.</p>
</div>
<div id="ref-chen2018distinct">
<p>Chen, C., Crivelli, C., Garrod, O. G., Schyns, P. G., Fernández-Dols, J.-M., &amp; Jack, R. E. (2018). Distinct facial expressions represent pain and pleasure across cultures. <em>Proceedings of the National Academy of Sciences</em>, <em>115</em>(43), E10013–E10021.</p>
</div>
<div id="ref-chu2012does">
<p>Chu, C., Hsu, A.-L., Chou, K.-H., Bandettini, P., Lin, C., Initiative, A. D. N., &amp; others. (2012). Does feature selection improve classification accuracy? Impact of sample size and feature selection on classification using anatomical magnetic resonance images. <em>Neuroimage</em>, <em>60</em>(1), 59–70.</p>
</div>
<div id="ref-Cichy2019-zf">
<p>Cichy, R. M., &amp; Kaiser, D. (2019). Deep neural networks as scientific models. <em>Trends Cogn. Sci.</em>, <em>23</em>(4), 305–317.</p>
</div>
<div id="ref-citron2014emotional">
<p>Citron, F. M., Gray, M. A., Critchley, H. D., Weekes, B. S., &amp; Ferstl, E. C. (2014). Emotional valence and arousal affect reading in an interactive way: Neuroimaging evidence for an approach-withdrawal framework. <em>Neuropsychologia</em>, <em>56</em>, 79–89.</p>
</div>
<div id="ref-Cohn2007-az">
<p>Cohn, J. F., Ambadar, Z., &amp; Ekman, P. (2007). Observer-based measurement of facial expression with the facial action coding system. <em>The Handbook of Emotion Elicitation and Assessment</em>, <em>1</em>(3), 203–221.</p>
</div>
<div id="ref-Cohn2007-xe">
<p>Cohn, J., &amp; Kanade, T. (2007). Use of automated facial image analysis for measurement of emotion expression. <em>Handbook of Emotion Elicitation and Assessment</em>, 222–238.</p>
</div>
<div id="ref-Cordaro2018-xm">
<p>Cordaro, D. T., Sun, R., Keltner, D., Kamble, S., Huddar, N., &amp; McNeil, G. (2018). Universals and cultural variations in 22 emotional expressions across five cultures. <em>Emotion</em>, <em>18</em>(1), 75–93.</p>
</div>
<div id="ref-corradi2016cross">
<p>Corradi-Dell’Acqua, C., Tusche, A., Vuilleumier, P., &amp; Singer, T. (2016). Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex. <em>Nature Communications</em>, <em>7</em>(1), 1–12.</p>
</div>
<div id="ref-Cowen2017-vz">
<p>Cowen, A. S., &amp; Keltner, D. (2017). Self-report captures 27 distinct categories of emotion bridged by continuous gradients. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>114</em>(38), E7900–E7909.</p>
</div>
<div id="ref-Cowen2021-ld">
<p>Cowen, A. S., Keltner, D., Schroff, F., Jou, B., Adam, H., &amp; Prasad, G. (2021). Sixteen facial expressions occur in similar contexts worldwide. <em>Nature</em>, <em>589</em>(7841), 251–257.</p>
</div>
<div id="ref-Craddock2009-kz">
<p>Craddock, R. C., Holtzheimer, P. E., 3rd, Hu, X. P., &amp; Mayberg, H. S. (2009). Disease state prediction from resting state functional connectivity. <em>Magn. Reson. Med.</em>, <em>62</em>(6), 1619–1628.</p>
</div>
<div id="ref-craddock2012whole">
<p>Craddock, R. C., James, G. A., Holtzheimer III, P. E., Hu, X. P., &amp; Mayberg, H. S. (2012). A whole brain fMRI atlas generated via spatially constrained spectral clustering. <em>Human Brain Mapping</em>, <em>33</em>(8), 1914–1928.</p>
</div>
<div id="ref-craig2009you">
<p>Craig, A. D., &amp; Craig, A. (2009). How do you feel–now? The anterior insula and human awareness. <em>Nature Reviews Neuroscience</em>, <em>10</em>(1).</p>
</div>
<div id="ref-Craig2017-db">
<p>Craig, B. M., Koch, S., &amp; Lipp, O. V. (2017). The influence of social category cues on the happy categorisation advantage depends on expression valence. <em>Cogn. Emot.</em>, <em>31</em>(7), 1493–1501.</p>
</div>
<div id="ref-Craig2018-jm">
<p>Craig, B. M., &amp; Lipp, O. V. (2018). The influence of multiple social categories on emotion perception. <em>J. Exp. Soc. Psychol.</em>, <em>75</em>, 27–35.</p>
</div>
<div id="ref-Cuingnet2011-hv">
<p>Cuingnet, R., Gerardin, E., Tessieras, J., Auzias, G., Lehéricy, S., Habert, M.-O., Chupin, M., Benali, H., Colliot, O., &amp; Alzheimer’s Disease Neuroimaging Initiative. (2011). Automatic classification of patients with alzheimer’s disease from structural MRI: A comparison of ten methods using the ADNI database. <em>Neuroimage</em>, <em>56</em>(2), 766–781.</p>
</div>
<div id="ref-Cummins2000-pk">
<p>Cummins, R. (2000). How does it work?“ Versus” what are the laws?“: Two conceptions of psychological explanation. <em>Explanation and Cognition</em>, 117–144.</p>
</div>
<div id="ref-Dale1999-rk">
<p>Dale, A. M., Fischl, B., &amp; Sereno, M. I. (1999). Cortical surface-based analysis. I. Segmentation and surface reconstruction. <em>Neuroimage</em>, <em>9</em>(2), 179–194.</p>
</div>
<div id="ref-Darwin1872-nv">
<p>Darwin, C. (1872). The expression of the emotions in man and animals, new york: D. <em>Appleton and Company</em>.</p>
</div>
<div id="ref-Davis2014-lw">
<p>Davis, T., LaRocque, K. F., Mumford, J. A., Norman, K. A., Wagner, A. D., &amp; Poldrack, R. A. (2014). What do differences between multi-voxel and univariate analysis mean? How subject-, voxel-, and trial-level variance impact fMRI analysis. <em>Neuroimage</em>, <em>97</em>, 271–283.</p>
</div>
<div id="ref-decety2011dissecting">
<p>Decety, J. (2011). Dissecting the neural mechanisms mediating empathy. <em>Emotion Review</em>, <em>3</em>(1), 92–108.</p>
</div>
<div id="ref-de2007measuring">
<p>De Corte, K., Buysse, A., Verhofstadt, L. L., Roeyers, H., Ponnet, K., &amp; Davis, M. H. (2007). Measuring empathic tendencies: Reliability and validity of the dutch version of the interpersonal reactivity index. <em>Psychologica Belgica</em>, <em>47</em>(4), 235–260.</p>
</div>
<div id="ref-Del_Giudice2016-ns">
<p>Del Giudice, M., Lippa, R. A., Puts, D. A., Bailey, D. H., Bailey, J. M., &amp; Schmitt, D. P. (2016). Joel et al.’s method systematically fails to detect large, consistent sex differences. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>113</em>(14), E1965.</p>
</div>
<div id="ref-Delis2016-zl">
<p>Delis, I., Chen, C., Jack, R. E., Garrod, O. G. B., Panzeri, S., &amp; Schyns, P. G. (2016). Space-by-time manifold representation of dynamic facial expressions for emotion categorization. <em>J. Vis.</em>, <em>16</em>(8), 14–14.</p>
</div>
<div id="ref-Demetriou2018-xp">
<p>Demetriou, L., Kowalczyk, O. S., Tyson, G., Bello, T., Newbould, R. D., &amp; Wall, M. B. (2018). A comprehensive evaluation of increasing temporal resolution with multiband-accelerated protocols and effects on statistical outcome measures in fMRI. <em>Neuroimage</em>, <em>176</em>, 404–416.</p>
</div>
<div id="ref-Deng2009-bp">
<p>Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., &amp; Fei-Fei, L. (2009). ImageNet: A large-scale hierarchical image database. <em>2009 IEEE Conference on Computer Vision and Pattern Recognition</em>, 248–255.</p>
</div>
<div id="ref-Dennett2006-el">
<p>Dennett, D. C. (2006). The frame problem of AI. <em>Philosophy of Psychology: Contemporary Readings</em>, <em>433</em>, 67–83.</p>
</div>
<div id="ref-denny2012meta">
<p>Denny, B. T., Kober, H., Wager, T. D., &amp; Ochsner, K. N. (2012). A meta-analysis of functional neuroimaging studies of self-and other judgments reveals a spatial gradient for mentalizing in medial prefrontal cortex. <em>Journal of Cognitive Neuroscience</em>, <em>24</em>(8), 1742–1752.</p>
</div>
<div id="ref-Desikan2006-gh">
<p>Desikan, R. S., Ségonne, F., Fischl, B., Quinn, B. T., Dickerson, B. C., Blacker, D., Buckner, R. L., Dale, A. M., Maguire, R. P., Hyman, B. T., Albert, M. S., &amp; Killiany, R. J. (2006). An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest. <em>Neuroimage</em>, <em>31</em>(3), 968–980.</p>
</div>
<div id="ref-Deska2018-hx">
<p>Deska, J. C., Lloyd, E. P., &amp; Hugenberg, K. (2018). The face of fear and anger: Facial width-to-height ratio biases recognition of angry and fearful expressions. <em>Emotion</em>, <em>18</em>(3), 453–464.</p>
</div>
<div id="ref-Destrieux2010-rd">
<p>Destrieux, C., Fischl, B., Dale, A., &amp; Halgren, E. (2010). Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. <em>Neuroimage</em>, <em>53</em>(1), 1–15.</p>
</div>
<div id="ref-Dhollander2016-dx">
<p>Dhollander, T., Raffelt, D., &amp; Connelly, A. (2016). Unsupervised 3-tissue response function estimation from single-shell or multi-shell diffusion MR data without a co-registered T1 image. <em>ISMRM Workshop on Breaking the Barriers of Diffusion MRI</em>, <em>5</em>, 5.</p>
</div>
<div id="ref-diekhof2012role">
<p>Diekhof, E. K., Kaps, L., Falkai, P., &amp; Gruber, O. (2012). The role of the human ventral striatum and the medial orbitofrontal cortex in the representation of reward magnitude–an activation likelihood estimation meta-analysis of neuroimaging studies of passive reward expectancy and outcome processing. <em>Neuropsychologia</em>, <em>50</em>(7), 1252–1266.</p>
</div>
<div id="ref-Dinga2020-si">
<p>Dinga, R., Schmaal, L., Penninx, B. W. J., Veltman, D. J., &amp; Marquand, A. F. (2020). Controlling for effects of confounding variables on machine learning predictions. In <em>bioRxiv</em> (p. 2020.08.17.255034).</p>
</div>
<div id="ref-Dixon1999-kl">
<p>Dixon, L. (1999). Dual diagnosis of substance abuse in schizophrenia: Prevalence and impact on outcomes. <em>Schizophr. Res.</em>, <em>35 Suppl</em>, S93–100.</p>
</div>
<div id="ref-Douaud2007-sw">
<p>Douaud, G., Smith, S., Jenkinson, M., Behrens, T., Johansen-Berg, H., Vickers, J., James, S., Voets, N., Watkins, K., Matthews, P. M., &amp; James, A. (2007). Anatomically related grey and white matter abnormalities in adolescent-onset schizophrenia. <em>Brain</em>, <em>130</em>(Pt 9), 2375–2386.</p>
</div>
<div id="ref-Dubois2016-zz">
<p>Dubois, J., &amp; Adolphs, R. (2016). Building a science of individual differences from fMRI. <em>Trends Cogn. Sci.</em>, <em>20</em>(6), 425–443.</p>
</div>
<div id="ref-dubois2018resting">
<p>Dubois, J., Galdi, P., Han, Y., Paul, L. K., &amp; Adolphs, R. (2018). Resting-state functional brain connectivity best predicts the personality dimension of openness to experience. <em>Personality Neuroscience</em>, <em>1</em>.</p>
</div>
<div id="ref-Dukart2011-aq">
<p>Dukart, J., Schroeter, M. L., Mueller, K., Initiative, A. D. N., &amp; Others. (2011). Age correction in dementia–matching to a healthy brain. <em>PLoS One</em>, <em>6</em>(7), e22193.</p>
</div>
<div id="ref-Ebersole2016-cr">
<p>Ebersole, C. R., Atherton, O. E., Belanger, A. L., Skulborstad, H. M., Allen, J. M., Banks, J. B., Baranski, E., Bernstein, M. J., Bonfiglio, D. B. V., Boucher, L., Brown, E. R., Budiman, N. I., Cairo, A. H., Capaldi, C. A., Chartier, C. R., Chung, J. M., Cicero, D. C., Coleman, J. A., Conway, J. G., … Nosek, B. A. (2016). Many labs 3: Evaluating participant pool quality across the academic semester via replication. <em>J. Exp. Soc. Psychol.</em>, <em>67</em>, 68–82.</p>
</div>
<div id="ref-efron1987better">
<p>Efron, B. (1987). Better bootstrap confidence intervals. <em>Journal of the American Statistical Association</em>, <em>82</em>(397), 171–185.</p>
</div>
<div id="ref-Egner2010-ot">
<p>Egner, T., Ely, S., &amp; Grinband, J. (2010). Going, going, gone: Characterizing the time-course of congruency sequence effects. <em>Front. Psychol.</em>, <em>1</em>, 154.</p>
</div>
<div id="ref-Eigenhuis2013-xo">
<p>Eigenhuis, A., Kamphuis, J. H., &amp; Noordhof, A. (2013). Development and validation of the dutch brief form of the multidimensional personality questionnaire (MPQ-BF-NL). <em>Assessment</em>, <em>20</em>(5), 565–575.</p>
</div>
<div id="ref-Ekman1980-of">
<p>Ekman, P., Freisen, W. V., &amp; Ancoli, S. (1980). Facial signs of emotional experience. <em>J. Pers. Soc. Psychol.</em>, <em>39</em>(6), 1125–1134.</p>
</div>
<div id="ref-Ekman1976-hm">
<p>Ekman, P., &amp; Friesen, W. V. (1976). Measuring facial movement. <em>Environmental Psychology and Nonverbal Behavior</em>, <em>1</em>(1), 56–75.</p>
</div>
<div id="ref-Ekman1997-bk">
<p>Ekman, P., &amp; Keltner, D. (1997). Universal facial expressions of emotion. <em>Segerstrale U, P. Molnar P, Eds. Nonverbal Communication: Where Nature Meets Culture</em>, 27–46.</p>
</div>
<div id="ref-Ekman1969-pu">
<p>Ekman, P., Sorenson, E. R., &amp; Friesen, W. V. (1969). Pan-cultural elements in facial displays of emotion. <em>Science</em>, <em>164</em>(3875), 86–88.</p>
</div>
<div id="ref-Van_Elk2020-xo">
<p>Elk, M. van, &amp; Snoek, L. (2020). The relationship between individual differences in gray matter volume and religiosity and mystical experiences: A preregistered voxel-based morphometry study. <em>Eur. J. Neurosci.</em>, <em>51</em>(3), 850–865.</p>
</div>
<div id="ref-elliot2006hierarchical">
<p>Elliot, A. J. (2006). The hierarchical model of approach-avoidance motivation. <em>Motivation and Emotion</em>, <em>30</em>(2), 111–116.</p>
</div>
<div id="ref-Esteban2017-mv">
<p>Esteban, O., Birman, D., Schaer, M., Koyejo, O. O., Poldrack, R. A., &amp; Gorgolewski, K. J. (2017). MRIQC: Advancing the automatic prediction of image quality in MRI from unseen sites. <em>PLoS One</em>, <em>12</em>(9), e0184661.</p>
</div>
<div id="ref-esteban_oscar_2017_1095198">
<p>Esteban, O., Blair, R., Markiewicz, C. J., Berleant, S. L., Moodie, C., Ma, F., Isik, A. I., Erramuzpe, A., Kent, J. D., Goncalves, M., Poldrack, R. A., &amp; Gorgolewski, K. J. (2017). <em>Poldracklab/fmriprep: 1.0.0</em> (Version 1.0.0) [Computer software]. Zenodo. <a href="https://doi.org/10.5281/zenodo.1095198">https://doi.org/10.5281/zenodo.1095198</a></p>
</div>
<div id="ref-Esteban2020-qw">
<p>Esteban, O., Ciric, R., Finc, K., Blair, R. W., Markiewicz, C. J., Moodie, C. A., Kent, J. D., Goncalves, M., DuPre, E., Gomez, D. E. P., Ye, Z., Salo, T., Valabregue, R., Amlien, I. K., Liem, F., Jacoby, N., Stojić, H., Cieslak, M., Urchs, S., … Gorgolewski, K. J. (2020). Analysis of task-based functional MRI data preprocessed with fMRIPrep. <em>Nat. Protoc.</em>, <em>15</em>(7), 2186–2202.</p>
</div>
<div id="ref-esteban2019fmriprep">
<p>Esteban, O., Markiewicz, C. J., Blair, R. W., Moodie, C. A., Isik, A. I., Erramuzpe, A., Kent, J. D., Goncalves, M., DuPre, E., Snyder, M., &amp; others. (2019). FMRIPrep: A robust preprocessing pipeline for functional mri. <em>Nature Methods</em>, <em>16</em>(1), 111–116.</p>
</div>
<div id="ref-Esteban2019-ri">
<p>Esteban, O., Markiewicz, C. J., Blair, R. W., Moodie, C. A., Isik, A. I., Erramuzpe, A., Kent, J. D., Goncalves, M., DuPre, E., Snyder, M., Oya, H., Ghosh, S. S., Wright, J., Durnez, J., Poldrack, R. A., &amp; Gorgolewski, K. J. (2019). fMRIPrep: A robust preprocessing pipeline for functional MRI. <em>Nat. Methods</em>, <em>16</em>(1), 111–116.</p>
</div>
<div id="ref-ethofer2009decoding">
<p>Ethofer, T., Van De Ville, D., Scherer, K., &amp; Vuilleumier, P. (2009). Decoding of emotional information in voice-sensitive cortices. <em>Current Biology</em>, <em>19</em>(12), 1028–1033.</p>
</div>
<div id="ref-etzel2011impact">
<p>Etzel, J. A., Valchev, N., &amp; Keysers, C. (2011). The impact of certain methodological choices on multivariate analysis of fMRI data with support vector machines. <em>Neuroimage</em>, <em>54</em>(2), 1159–1167.</p>
</div>
<div id="ref-floresco2015nucleus">
<p>Floresco, S. B. (2015). The nucleus accumbens: An interface between cognition, emotion, and action. <em>Annual Review of Psychology</em>, <em>66</em>, 25–52.</p>
</div>
<div id="ref-Fonov2009-sr">
<p>Fonov, V. S., Evans, A. C., McKinstry, R. C., Almli, C. R., &amp; Collins, D. L. (2009). Unbiased nonlinear average age-appropriate brain templates from birth to adulthood. <em>Neuroimage</em>, <em>Supplement 1</em>(47), S102.</p>
</div>
<div id="ref-Forstmann2015-rz">
<p>Forstmann, B. U., &amp; Wagenmakers, E.-J. (2015). <em>An introduction to Model-Based cognitive neuroscience</em> (B. U. Forstmann &amp; E.-J. Wagenmakers, Eds.). Springer, New York, NY.</p>
</div>
<div id="ref-Folster2014-zy">
<p>Fölster, M., Hess, U., &amp; Werheid, K. (2014). Facial age affects emotional expression decoding. <em>Front. Psychol.</em>, <em>5</em>, 30.</p>
</div>
<div id="ref-Franken2005-jg">
<p>Franken, I. H. A., Muris, P., &amp; Rassin, E. (2005). Psychometric properties of the dutch bis/bas scales. <em>J. Psychopathol. Behav. Assess.</em>, <em>27</em>(1), 25–30.</p>
</div>
<div id="ref-Franklin2019-qo">
<p>Franklin, R. G., Adams, R. B., Steiner, T. G., &amp; Zebrowitz, L. A. (2019). Reading the lines in the face: The contribution of angularity and roundness to perceptions of facial anger and joy. <em>Emotion</em>, <em>19</em>(2), 209–218.</p>
</div>
<div id="ref-Friesen1978-tp">
<p>Friesen, W., &amp; Ekman, P. (1978). Facial action coding system: A technique for the measurement of facial movement. <em>Palo Alto</em>, <em>3</em>.</p>
</div>
<div id="ref-Friesen1983-ft">
<p>Friesen, W. V., &amp; Ekman. (1983). EMFACS-7: Emotional facial action coding system. <em>Unpublished Manuscript, University of California at San Francisco</em>, <em>2</em>(36), 1.</p>
</div>
<div id="ref-Frigg2020-hp">
<p>Frigg, R., &amp; Hartmann, S. (2020). Models in Science. In E. N. Zalta (Ed.), <em>The Stanford encyclopedia of philosophy</em> (Spring 2020). Metaphysics Research Lab, Stanford University.</p>
</div>
<div id="ref-Funder2019-ow">
<p>Funder, D. C., &amp; Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. <em>Advances in Methods and Practices in Psychological Science</em>, <em>2</em>(2), 156–168.</p>
</div>
<div id="ref-gallese2004unifying">
<p>Gallese, V., Keysers, C., &amp; Rizzolatti, G. (2004). A unifying view of the basis of social cognition. <em>Trends in Cognitive Sciences</em>, <em>8</em>(9), 396–403.</p>
</div>
<div id="ref-Ganzetti2016-yy">
<p>Ganzetti, M., Wenderoth, N., &amp; Mantini, D. (2016). Intensity inhomogeneity correction of structural MR images: A Data-Driven approach to define input algorithm parameters. <em>Front. Neuroinform.</em>, <em>10</em>, 10.</p>
</div>
<div id="ref-Gazendam2015-fr">
<p>Gazendam, F. J., Kamphuis, J. H., Eigenhuis, A., Huizenga, H. M. H., Soeter, M., Bos, M. G. N., Sevenster, D., &amp; Kindt, M. (2015). Personality predicts individual variation in fear learning: A multilevel growth modeling approach. <em>Clin. Psychol. Sci.</em>, <em>3</em>(2), 175–188.</p>
</div>
<div id="ref-Geirhos2020-af">
<p>Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge, M., &amp; Wichmann, F. A. (2020). Shortcut learning in deep neural networks. <em>Nature Machine Intelligence</em>, <em>2</em>(11), 665–673.</p>
</div>
<div id="ref-de2010standing">
<p>Gelder, B. de, Van den Stock, J., Meeren, H. K., Sinke, C. B., Kret, M. E., &amp; Tamietto, M. (2010). Standing up for the body. Recent progress in uncovering the networks involved in the perception of bodies and bodily expressions. <em>Neuroscience &amp; Biobehavioral Reviews</em>, <em>34</em>(4), 513–527.</p>
</div>
<div id="ref-Gelfert2016-hd">
<p>Gelfert, A. (2016). <em>How to do science with models: A philosophical primer</em>. Springer, Cham.</p>
</div>
<div id="ref-Gescheider2013-zm">
<p>Gescheider, G. A. (2013). <em>Psychophysics: The fundamentals</em>. Psychology Press.</p>
</div>
<div id="ref-Gewin2016-ff">
<p>Gewin, V. (2016). Data sharing: An open mind on open data. <em>Nature</em>, <em>529</em>(7584), 117–119.</p>
</div>
<div id="ref-ghiasi2017exploring">
<p>Ghiasi, G., Lee, H., Kudlur, M., Dumoulin, V., &amp; Shlens, J. (2017). Exploring the structure of a real-time, arbitrary neural artistic stylization network. <em>arXiv Preprint arXiv:1705.06830</em>.</p>
</div>
<div id="ref-gilbert2012evaluative">
<p>Gilbert, S. J., Swencionis, J. K., &amp; Amodio, D. M. (2012). Evaluative vs. Trait representation in intergroup social judgments: Distinct roles of anterior temporal lobe and prefrontal cortex. <em>Neuropsychologia</em>, <em>50</em>(14), 3600–3611.</p>
</div>
<div id="ref-Gill2014-hx">
<p>Gill, D., Garrod, O. G. B., Jack, R. E., &amp; Schyns, P. G. (2014). Facial movements strategically camouflage involuntary social signals of face morphology. <em>Psychol. Sci.</em>, <em>25</em>(5), 1079–1086.</p>
</div>
<div id="ref-gilron2016addressing">
<p>Gilron, R., Rosenblatt, J. D., &amp; Mukamel, R. (2016). Addressing the" problem" of temporal correlations in mvpa analysis. <em>2016 International Workshop on Pattern Recognition in Neuroimaging (Prni)</em>, 1–4.</p>
</div>
<div id="ref-Gilron2017-tl">
<p>Gilron, R., Rosenblatt, J., Koyejo, O., Poldrack, R. A., &amp; Mukamel, R. (2017). What’s in a pattern? Examining the type of signal multivariate analysis uncovers at the group level. <em>Neuroimage</em>, <em>146</em>, 113–120.</p>
</div>
<div id="ref-Glezerman2016-xl">
<p>Glezerman, M. (2016). Yes, there is a female and a male brain: Morphology versus functionality. <em>Proceedings of the National Academy of Sciences</em>, <em>113</em>(14), E1971–E1971.</p>
</div>
<div id="ref-Glover2000-or">
<p>Glover, G. H., Li, T.-Q., &amp; Ress, D. (2000). Image-based method for retrospective correction of physiological motion effects in fMRI: RETROICOR. <em>Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine</em>, <em>44</em>(1), 162–167.</p>
</div>
<div id="ref-Goldstein2001-dy">
<p>Goldstein, J. M., Seidman, L. J., Horton, N. J., Makris, N., Kennedy, D. N., Caviness, V. S., Jr, Faraone, S. V., &amp; Tsuang, M. T. (2001). Normal sexual dimorphism of the adult human brain assessed by in vivo magnetic resonance imaging. <em>Cereb. Cortex</em>, <em>11</em>(6), 490–497.</p>
</div>
<div id="ref-golman2015curiosity">
<p>Golman, R., &amp; Loewenstein, G. (2015). Curiosity, information gaps, and the utility of knowledge. <em>Information Gaps, and the Utility of Knowledge (April 16, 2015)</em>, 96–135.</p>
</div>
<div id="ref-Good2001-ak">
<p>Good, C. D., Johnsrude, I., Ashburner, J., Henson, R. N., Friston, K. J., &amp; Frackowiak, R. S. (2001a). Cerebral asymmetry and the effects of sex and handedness on brain structure: A voxel-based morphometric analysis of 465 normal adult human brains. <em>Neuroimage</em>, <em>14</em>(3), 685–700.</p>
</div>
<div id="ref-Good2001-kv">
<p>Good, C. D., Johnsrude, I. S., Ashburner, J., Henson, R. N., Friston, K. J., &amp; Frackowiak, R. S. (2001b). A voxel-based morphometric study of ageing in 465 normal adult human brains. <em>Neuroimage</em>, <em>14</em>(1 Pt 1), 21–36.</p>
</div>
<div id="ref-Gorgolewski2011-aa">
<p>Gorgolewski, K., Burns, C. D., Madison, C., Clark, D., Halchenko, Y. O., Waskom, M. L., &amp; Ghosh, S. S. (2011). Nipype: A flexible, lightweight and extensible neuroimaging data processing framework in python. <em>Front. Neuroinform.</em>, <em>5</em>, 13.</p>
</div>
<div id="ref-Gorgolewski2017-uu">
<p>Gorgolewski, K., Esteban, O., Schaefer, G., Wandell, B., &amp; Poldrack, R. (2017). OpenNeuro—a free online platform for sharing and analysis of neuroimaging data. <em>Organization for Human Brain Mapping. Vancouver, Canada</em>, 1677.</p>
</div>
<div id="ref-Gorgolewski2016-in">
<p>Gorgolewski, K. J., Auer, T., Calhoun, V. D., Craddock, R. C., Das, S., Duff, E. P., Flandin, G., Ghosh, S. S., Glatard, T., Halchenko, Y. O., Handwerker, D. A., Hanke, M., Keator, D., Li, X., Michael, Z., Maumet, C., Nichols, B. N., Nichols, T. E., Pellman, J., … Poldrack, R. A. (2016). The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. <em>Sci Data</em>, <em>3</em>, 160044.</p>
</div>
<div id="ref-Gorgolewski2017-gb">
<p>Gorgolewski, K. J., Esteban, O., Ellis, D. G., Notter, M. P., Ziegler, E., Johnson, H., Hamalainen, C., Yvernault, B., Burns, C., Manhães-Savio, A., Jarecka, D., Markiewicz, C. J., Salo, T., Clark, D., Waskom, M., Wong, J., Modat, M., Dewey, B. E., Clark, M. G., … Ghosh, S. (2017). <em>Nipype: A flexible, lightweight and extensible neuroimaging data processing framework in python. 0.13.1</em>.</p>
</div>
<div id="ref-gorgolewski_krzysztof_j_2017_581704">
<p>Gorgolewski, K. J., Esteban, O., Ellis, D. G., Notter, M. P., Ziegler, E., Johnson, H., Hamalainen, C., Yvernault, B., Burns, C., Manhães-Savio, A., Jarecka, D., Markiewicz, C. J., Salo, T., Clark, D., Waskom, M., Wong, J., Modat, M., Dewey, B. E., Clark, M. G., … Ghosh, S. (2017). <em>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python. 0.13.1</em> (Version 0.13.1) [Computer software]. Zenodo. <a href="https://doi.org/10.5281/zenodo.581704">https://doi.org/10.5281/zenodo.581704</a></p>
</div>
<div id="ref-gorgolewski2015neurovault">
<p>Gorgolewski, K. J., Varoquaux, G., Rivera, G., Schwarz, Y., Ghosh, S. S., Maumet, C., Sochat, V. V., Nichols, T. E., Poldrack, R. A., Poline, J.-B., &amp; others. (2015). NeuroVault. Org: A web-based repository for collecting and sharing unthresholded statistical maps of the human brain. <em>Frontiers in Neuroinformatics</em>, <em>9</em>, 8.</p>
</div>
<div id="ref-Gorgolewski2015-hj">
<p>Gorgolewski, K. J., Varoquaux, G., Rivera, G., Schwarz, Y., Ghosh, S. S., Maumet, C., Sochat, V. V., Nichols, T. E., Poldrack, R. A., Poline, J.-B., Yarkoni, T., &amp; Margulies, D. S. (2015). NeuroVault.org: A web-based repository for collecting and sharing unthresholded statistical maps of the human brain. <em>Front. Neuroinform.</em>, <em>9</em>, 8.</p>
</div>
<div id="ref-gottlieb2018towards">
<p>Gottlieb, J., &amp; Oudeyer, P.-Y. (2018). Towards a neuroscience of active sampling and curiosity. <em>Nature Reviews Neuroscience</em>, <em>19</em>(12), 758–770.</p>
</div>
<div id="ref-gottlieb2013information">
<p>Gottlieb, J., Oudeyer, P.-Y., Lopes, M., &amp; Baranes, A. (2013). Information-seeking, curiosity, and attention: Computational and neural mechanisms. <em>Trends in Cognitive Sciences</em>, <em>17</em>(11), 585–593.</p>
</div>
<div id="ref-Gorgen2017-sy">
<p>Görgen, K., Hebart, M. N., Allefeld, C., &amp; Haynes, J.-D. (2017). The same analysis approach: Practical protection against the pitfalls of novel neuroimaging analysis methods. <em>Neuroimage</em>.</p>
</div>
<div id="ref-Greve2009-da">
<p>Greve, D. N., &amp; Fischl, B. (2009). Accurate and robust brain image alignment using boundary-based registration. <em>Neuroimage</em>, <em>48</em>(1), 63–72.</p>
</div>
<div id="ref-Groen2018-qo">
<p>Groen, I. I., Greene, M. R., Baldassano, C., Fei-Fei, L., Beck, D. M., &amp; Baker, C. I. (2018). Distinct contributions of functional and deep neural network features to representational similarity of scenes in human brain and behavior. <em>Elife</em>, <em>7</em>.</p>
</div>
<div id="ref-degroot">
<p>Groot, A. D. de. (1961). <em>An introduction to Model-Based cognitive neuroscience</em>. Mouton, ’s-Gravenhage.</p>
</div>
<div id="ref-gruber2014states">
<p>Gruber, M. J., Gelman, B. D., &amp; Ranganath, C. (2014). States of curiosity modulate hippocampus-dependent learning via the dopaminergic circuit. <em>Neuron</em>, <em>84</em>(2), 486–496.</p>
</div>
<div id="ref-gruber2019curiosity">
<p>Gruber, M. J., &amp; Ranganath, C. (2019). How curiosity enhances hippocampus-dependent memory: The prediction, appraisal, curiosity, and exploration (pace) framework. <em>Trends in Cognitive Sciences</em>, <em>23</em>(12), 1014–1025.</p>
</div>
<div id="ref-Guan2018-hq">
<p>Guan, J., Ryali, C. K., &amp; Angela, J. Y. (2018). Computational modeling of social face perception in humans: Leveraging the active appearance model. <em>bioRxiv</em>.</p>
</div>
<div id="ref-Guest2020-ef">
<p>Guest, O., &amp; Martin, A. E. (). How computational modeling can force theory building in psychological science. <em>Perspectives on Psychological Science</em>, <em>0</em>(0), 1745691620970585. <a href="https://doi.org/10.1177/1745691620970585">https://doi.org/10.1177/1745691620970585</a></p>
</div>
<div id="ref-Guggenmos2018-rr">
<p>Guggenmos, M., Sterzer, P., &amp; Cichy, R. M. (2018). Multivariate pattern analysis for MEG: A comparison of dissimilarity measures. <em>Neuroimage</em>, <em>173</em>, 434–447.</p>
</div>
<div id="ref-Gulban2019-sv">
<p>Gulban, O. F., Nielson, D., Poldrack, R., Lee, J., Gorgolewski, C., Vanessasaurus, &amp; Ghosh, S. (2019). <em>Poldracklab/pydeface: V2.0.0</em>.</p>
</div>
<div id="ref-Gur1999-qj">
<p>Gur, R. C., Turetsky, B. I., Matsui, M., Yan, M., Bilker, W., Hughett, P., &amp; Gur, R. E. (1999). Sex differences in brain gray and white matter in healthy young adults: Correlations with cognitive performance. <em>J. Neurosci.</em>, <em>19</em>(10), 4065–4072.</p>
</div>
<div id="ref-guyon2002gene">
<p>Guyon, I., Weston, J., Barnhill, S., &amp; Vapnik, V. (2002). Gene selection for cancer classification using support vector machines. <em>Machine Learning</em>, <em>46</em>(1), 389–422.</p>
</div>
<div id="ref-Guclu2015-qj">
<p>Güçlü, U., &amp; Gerven, M. A. J. van. (2015). Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. <em>J. Neurosci.</em>, <em>35</em>(27), 10005–10014.</p>
</div>
<div id="ref-Halevy2009-cv">
<p>Halevy, A., Norvig, P., &amp; Pereira, F. (2009). The unreasonable effectiveness of data. <em>IEEE Intell. Syst.</em>, <em>24</em>(2), 8–12.</p>
</div>
<div id="ref-Hariri2000-sc">
<p>Hariri, A. R., Bookheimer, S. Y., &amp; Mazziotta, J. C. (2000). Modulating emotional responses: Effects of a neocortical network on the limbic system. <em>Neuroreport</em>, <em>11</em>(1), 43–48.</p>
</div>
<div id="ref-Harris2020-en">
<p>Harris, C. R., Millman, K. J., Walt, S. J. van der, Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., Kerkwijk, M. H. van, Brett, M., Haldane, A., Del Rı́o, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. <em>Nature</em>, <em>585</em>(7825), 357–362.</p>
</div>
<div id="ref-harris2008functional">
<p>Harris, S., Sheth, S. A., &amp; Cohen, M. S. (2008). Functional neuroimaging of belief, disbelief, and uncertainty. <em>Annals of Neurology</em>, <em>63</em>(2), 141–147.</p>
</div>
<div id="ref-Harvey2008-nt">
<p>Harvey, A. K., Pattinson, K. T. S., Brooks, J. C. W., Mayhew, S. D., Jenkinson, M., &amp; Wise, R. G. (2008). Brainstem functional magnetic resonance imaging: Disentangling signal from physiological noise. <em>J. Magn. Reson. Imaging</em>, <em>28</em>(6), 1337–1344.</p>
</div>
<div id="ref-Hasson2004-xb">
<p>Hasson, U., Nir, Y., Levy, I., Fuhrmann, G., &amp; Malach, R. (2004). Intersubject synchronization of cortical activity during natural vision. <em>Science</em>, <em>303</em>(5664), 1634–1640.</p>
</div>
<div id="ref-Haufe2014-el">
<p>Haufe, S., Meinecke, F., Görgen, K., Dähne, S., Haynes, J.-D., Blankertz, B., &amp; Bießmann, F. (2014). On the interpretation of weight vectors of linear models in multivariate neuroimaging. <em>Neuroimage</em>, <em>87</em>, 96–110.</p>
</div>
<div id="ref-Haxby2012-sd">
<p>Haxby, J. V. (2012). Multivariate pattern analysis of fMRI: The early beginnings. <em>Neuroimage</em>, <em>62</em>(2), 852–855.</p>
</div>
<div id="ref-Haxby2001-os">
<p>Haxby, J. V., Gobbini, M. I., Furey, M. L., Ishai, A., Schouten, J. L., &amp; Pietrini, P. (2001). Distributed and overlapping representations of faces and objects in ventral temporal cortex. <em>Science</em>, <em>293</em>(5539), 2425–2430.</p>
</div>
<div id="ref-haynes2015primer">
<p>Haynes, J.-D. (2015). A primer on pattern-based approaches to fMRI: Principles, pitfalls, and perspectives. <em>Neuron</em>, <em>87</em>(2), 257–270.</p>
</div>
<div id="ref-Hebart2017-jn">
<p>Hebart, M. N., &amp; Baker, C. I. (2017). Deconstructing multivariate decoding for the study of brain function. <em>Neuroimage</em>.</p>
</div>
<div id="ref-Hebart2018-dz">
<p>Hebart, M. N., Bankson, B. B., Harel, A., Baker, C. I., &amp; Cichy, R. M. (2018). The representational dynamics of task and object processing in humans. <em>Elife</em>, <em>7</em>.</p>
</div>
<div id="ref-Hebart2020-wp">
<p>Hebart, M. N., Zheng, C. Y., Pereira, F., &amp; Baker, C. I. (2020). Revealing the multidimensional mental representations of natural objects underlying human similarity judgements. <em>Nat Hum Behav</em>, <em>4</em>(11), 1173–1185.</p>
</div>
<div id="ref-Hess2009-jz">
<p>Hess, U., Adams, R. B., Jr, Grammer, K., &amp; Kleck, R. E. (2009). Face gender and emotion expression: Are angry women more like men? <em>J. Vis.</em>, <em>9</em>(12), 19.1–8.</p>
</div>
<div id="ref-Hess2009-xo">
<p>Hess, U., Adams, R. B., Jr, &amp; Kleck, R. E. (2009). The face is not an empty canvas: How facial expressions interact with facial appearance. <em>Philos. Trans. R. Soc. Lond. B Biol. Sci.</em>, <em>364</em>(1535), 3497–3504.</p>
</div>
<div id="ref-Hess2009-br">
<p>Hess, U., Adams, R. B., &amp; Kleck, R. E. (2009). The categorical perception of emotions and traits. <em>Soc. Cogn.</em>, <em>27</em>(2), 320–326.</p>
</div>
<div id="ref-Hoekstra1996-kv">
<p>Hoekstra, H. A., Ormel, H., &amp; De Fruyt, F. (1996). <em>Persoonlijkheidsvragenlijsten: NEO-pi-r &amp; neo-ffi</em>. Swets &amp; Zeitlinger.</p>
</div>
<div id="ref-Holdgraf2017-eu">
<p>Holdgraf, C. R., Rieger, J. W., Micheli, C., Martin, S., Knight, R. T., &amp; Theunissen, F. E. (2017). Encoding and decoding models in cognitive electrophysiology. <em>Front. Syst. Neurosci.</em>, <em>11</em>, 61.</p>
</div>
<div id="ref-Hoogeveen2020-qp">
<p>Hoogeveen, S., Snoek, L., &amp; Elk, M. van. (2020). Religious belief and cognitive conflict sensitivity: A preregistered fMRI study. <em>Cortex</em>, <em>129</em>, 247–265.</p>
</div>
<div id="ref-Hofling2020-mk">
<p>Höfling, T. T. A., Gerdes, A. B. M., Föhl, U., &amp; Alpers, G. W. (2020). Read my face: Automatic facial coding versus psychophysiological indicators of emotional valence and arousal. <em>Front. Psychol.</em>, <em>11</em>, 1388.</p>
</div>
<div id="ref-hsee2016pandora">
<p>Hsee, C. K., &amp; Ruan, B. (2016). The pandora effect: The power and peril of curiosity. <em>Psychological Science</em>, <em>27</em>(5), 659–666.</p>
</div>
<div id="ref-Hsu2004-hs">
<p>Hsu, A., Borst, A., &amp; Theunissen, F. E. (2004). Quantifying variability in neural responses and its application for the validation of model predictions. <em>Network</em>, <em>15</em>(2), 91–109.</p>
</div>
<div id="ref-Huntenburg2014-ps">
<p>Huntenburg, J. M. (2014). <em>Evaluating nonlinear coregistration of BOLD EPI and t1w images</em> [PhD thesis]. Freie Universität Berlin; pure.mpg.de.</p>
</div>
<div id="ref-Hunter2007-at">
<p>Hunter. (2007). Matplotlib: A 2D graphics environment. <em>IEEE Ann. Hist. Comput.</em>, <em>9</em>, 90–95.</p>
</div>
<div id="ref-Huth2012-yc">
<p>Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2012). A continuous semantic space describes the representation of thousands of object and action categories across the human brain. <em>Neuron</em>, <em>76</em>(6), 1210–1224.</p>
</div>
<div id="ref-Ince2020-mr">
<p>Ince, R. A. A., Kay, J. W., &amp; Schyns, P. G. (2020). Bayesian inference of population prevalence. In <em>bioRxiv</em> (p. 2020.07.08.191106).</p>
</div>
<div id="ref-Ivanova2021-wk">
<p>Ivanova, A. A., Schrimpf, M., Anzellotti, S., Zaslavsky, N., &amp; others. (2021). Is it that simple? Linear mapping models in cognitive neuroscience. <em>bioRxiv</em>.</p>
</div>
<div id="ref-Izard1994-ca">
<p>Izard, C. E. (1994). Innate and universal facial expressions: Evidence from developmental and cross-cultural research. <em>Psychol. Bull.</em>, <em>115</em>(2), 288–299.</p>
</div>
<div id="ref-Jack2017-qp">
<p>Jack, R., Crivelli, C., &amp; Wheatley, T. (2017). Data-Driven methods to diversify knowledge of human psychology. <em>Trends Cogn. Sci.</em></p>
</div>
<div id="ref-Jack2009-yy">
<p>Jack, R. E., Blais, C., Scheepers, C., Schyns, P. G., &amp; Caldara, R. (2009). Cultural confusions show that facial expressions are not universal. <em>Curr. Biol.</em>, <em>19</em>(18), 1543–1548.</p>
</div>
<div id="ref-Jack2014-ku">
<p>Jack, R. E., Garrod, O. G. B., &amp; Schyns, P. G. (2014). Dynamic facial expressions of emotion transmit an evolving hierarchy of signals over time. <em>Curr. Biol.</em>, <em>24</em>(2), 187–192.</p>
</div>
<div id="ref-Jack2012-eq">
<p>Jack, R. E., Garrod, O. G. B., Yu, H., Caldara, R., &amp; Schyns, P. G. (2012). Facial expressions of emotion are not culturally universal. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>109</em>(19), 7241–7244.</p>
</div>
<div id="ref-Jack2015-sh">
<p>Jack, R. E., &amp; Schyns, P. G. (2015). The human face as a dynamic tool for social communication. <em>Curr. Biol.</em>, <em>25</em>(14), R621–34.</p>
</div>
<div id="ref-Jack2016-jq">
<p>Jack, R. E., Sun, W., Delis, I., Garrod, O. G. B., &amp; Schyns, P. G. (2016). Four not six: Revealing culturally common facial expressions of emotion. <em>J. Exp. Psychol. Gen.</em>, <em>145</em>(6), 708–730.</p>
</div>
<div id="ref-Jack2017-gt">
<p>Jack, R., &amp; Schyns, P. G. (2017). Toward a social psychophysics of face communication. <em>Annu. Rev. Psychol.</em>, <em>68</em>, 269–297.</p>
</div>
<div id="ref-Jaeger2020-sr">
<p>Jaeger, B., Oud, B., Williams, T., Krumhuber, E., Fehr, E., &amp; Engelmann, J. B. (2020). <em>Can people detect the trustworthiness of strangers based on their facial appearance?</em></p>
</div>
<div id="ref-Jaeger2020-bn">
<p>Jaeger, B., Sleegers, W., Stern, J., Penke, L., &amp; Jones, A. (2020). <em>The accuracy and meta-accuracy of personality impressions from faces</em>.</p>
</div>
<div id="ref-Jahfari2015-ix">
<p>Jahfari, S., Waldorp, L., Ridderinkhof, K. R., &amp; Scholte, H. S. (2015). Visual information shapes the dynamics of corticobasal ganglia pathways during response selection and inhibition. <em>J. Cogn. Neurosci.</em>, <em>27</em>(7), 1344–1359.</p>
</div>
<div id="ref-Jamalabadi2016-gr">
<p>Jamalabadi, H., Alizadeh, S., Schönauer - Human brain …, M., &amp; 2016. (2016). Classification based hypothesis testing in neuroscience: Below‐chance level classification rates and overlooked statistical properties of linear parametric classifiers. <em>Wiley Online Library</em>.</p>
</div>
<div id="ref-jenkinson2003fast">
<p>Jenkinson, M. (2003). Fast, automated, n-dimensional phase-unwrapping algorithm. <em>Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine</em>, <em>49</em>(1), 193–197.</p>
</div>
<div id="ref-Jenkinson2002-wm">
<p>Jenkinson, M., Bannister, P., Brady, M., &amp; Smith, S. (2002). Improved optimization for the robust and accurate linear registration and motion correction of brain images. <em>Neuroimage</em>, <em>17</em>(2), 825–841.</p>
</div>
<div id="ref-Jenkinson2012-ui">
<p>Jenkinson, M., Beckmann, C. F., Behrens, T. E. J., Woolrich, M. W., &amp; Smith, S. M. (2012). FSL. <em>Neuroimage</em>, <em>62</em>(2), 782–790.</p>
</div>
<div id="ref-jepma2012neural">
<p>Jepma, M., Verdonschot, R. G., Van Steenbergen, H., Rombouts, S. A., &amp; Nieuwenhuis, S. (2012). Neural mechanisms underlying the induction and relief of perceptual curiosity. <em>Frontiers in Behavioral Neuroscience</em>, <em>6</em>, 5.</p>
</div>
<div id="ref-Jeurissen2014-cd">
<p>Jeurissen, B., Leemans, A., &amp; Sijbers, J. (2014). Automated correction of improperly rotated diffusion gradient orientations in diffusion weighted MRI. <em>Med. Image Anal.</em>, <em>18</em>(7), 953–962.</p>
</div>
<div id="ref-Jimura2012-lv">
<p>Jimura, K., &amp; Poldrack, R. A. (2012). Analyses of regional-average activation and multivoxel pattern information tell complementary stories. <em>Neuropsychologia</em>, <em>50</em>(4), 544–552.</p>
</div>
<div id="ref-Joel2016-uo">
<p>Joel, D., &amp; Fausto-Sterling, A. (2016). Beyond sex differences: New approaches for thinking about variation in brain structure and function. <em>Philos. Trans. R. Soc. Lond. B Biol. Sci.</em>, <em>371</em>(1688), 20150451.</p>
</div>
<div id="ref-Johnstone2006-tn">
<p>Johnstone, T., Ores Walsh, K. S., Greischar, L. L., Alexander, A. L., Fox, A. S., Davidson, R. J., &amp; Oakes, T. R. (2006). Motion correction and the use of motion covariates in multiple-subject fMRI analysis. <em>Hum. Brain Mapp.</em>, <em>27</em>(10), 779–788.</p>
</div>
<div id="ref-Jolly2019-lx">
<p>Jolly, E., &amp; Chang, L. J. (2019). The flatland fallacy: Moving beyond low–dimensional thinking. <em>Top. Cogn. Sci.</em></p>
</div>
<div id="ref-kang2009wick">
<p>Kang, M. J., Hsu, M., Krajbich, I. M., Loewenstein, G., McClure, S. M., Wang, J. T.-y., &amp; Camerer, C. F. (2009). The wick in the candle of learning: Epistemic curiosity activates reward circuitry and enhances memory. <em>Psychological Science</em>, <em>20</em>(8), 963–973.</p>
</div>
<div id="ref-kashdan2009curiosity">
<p>Kashdan, T. B., &amp; Silvia, P. J. (2009). Curiosity and interest: The benefits of thriving on novelty and challenge. <em>Oxford Handbook of Positive Psychology</em>, <em>2</em>, 367–374.</p>
</div>
<div id="ref-Kasper2017-lp">
<p>Kasper, L., Bollmann, S., Diaconescu, A. O., Hutton, C., Heinzle, J., Iglesias, S., Hauser, T. U., Sebold, M., Manjaly, Z.-M., Pruessmann, K. P., &amp; Stephan, K. E. (2017). The PhysIO toolbox for modeling physiological noise in fMRI data. <em>J. Neurosci. Methods</em>, <em>276</em>, 56–72.</p>
</div>
<div id="ref-Kay2017-vr">
<p>Kay, K. N. (2017). Principles for models of neural information processing. <em>Neuroimage</em>.</p>
</div>
<div id="ref-kay2008identifying">
<p>Kay, K. N., Naselaris, T., Prenger, R. J., &amp; Gallant, J. L. (2008). Identifying natural images from human brain activity. <em>Nature</em>, <em>452</em>(7185), 352–355.</p>
</div>
<div id="ref-Kay2013-ch">
<p>Kay, K. N., Winawer, J., Mezer, A., &amp; Wandell, B. A. (2013). Compressive spatial summation in human visual cortex. <em>J. Neurophysiol.</em>, <em>110</em>(2), 481–494.</p>
</div>
<div id="ref-Kellen2019-af">
<p>Kellen, D. (2019). A model hierarchy for psychological science. <em>Computational Brain &amp; Behavior</em>, <em>2</em>(3), 160–165.</p>
</div>
<div id="ref-Kellner2016-xb">
<p>Kellner, E., Dhital, B., Kiselev, V. G., &amp; Reisert, M. (2016). Gibbs-ringing artifact removal based on local subvoxel-shifts. <em>Magn. Reson. Med.</em>, <em>76</em>(5), 1574–1581.</p>
</div>
<div id="ref-Keltner2019-tm">
<p>Keltner, D., Sauter, D., Tracy, J., &amp; Cowen, A. (2019). Emotional expression: Advances in basic emotion theory. <em>J. Nonverbal Behav.</em>, <em>43</em>(2), 133–160.</p>
</div>
<div id="ref-kendall1973functional">
<p>Kendall, M. G., &amp; Stuart, A. (1973). Functional and structural relationship. <em>The Advanced Theory of Statistics</em>, <em>2</em>, 399–343.</p>
</div>
<div id="ref-keysers2014dissociating">
<p>Keysers, C., &amp; Gazzola, V. (2014). Dissociating the ability and propensity for empathy. <em>Trends in Cognitive Sciences</em>, <em>18</em>(4), 163–166.</p>
</div>
<div id="ref-khaligh2014deep">
<p>Khaligh-Razavi, S.-M., &amp; Kriegeskorte, N. (2014). Deep supervised, but not unsupervised, models may explain it cortical representation. <em>PLoS Computational Biology</em>, <em>10</em>(11), e1003915.</p>
</div>
<div id="ref-kidd2015psychology">
<p>Kidd, C., &amp; Hayden, B. Y. (2015). The psychology and neuroscience of curiosity. <em>Neuron</em>, <em>88</em>(3), 449–460.</p>
</div>
<div id="ref-Klein2017-su">
<p>Klein, A., Ghosh, S. S., Bao, F. S., Giard, J., Häme, Y., Stavsky, E., Lee, N., Rossa, B., Reuter, M., Chaibub Neto, E., &amp; Keshavan, A. (2017). Mindboggling morphometry of human brains. <em>PLoS Comput. Biol.</em>, <em>13</em>(2), e1005350.</p>
</div>
<div id="ref-Klein2018-un">
<p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., Aveyard, M., Axt, J. R., Babalola, M. T., Bahnı́k, Š., Batra, R., Berkics, M., Bernstein, M. J., Berry, D. R., Bialobrzeska, O., Binan, E. D., Bocian, K., Brandt, M. J., Busching, R., … Nosek, B. A. (2018). Many labs 2: Investigating variation in replicability across samples and settings. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(4), 443–490.</p>
</div>
<div id="ref-Ko2018-rv">
<p>Ko, B. C. (2018). A brief review of facial emotion recognition based on visual information. <em>Sensors</em>, <em>18</em>(2).</p>
</div>
<div id="ref-kobayashi2019diverse">
<p>Kobayashi, K., Ravaioli, S., Baranès, A., Woodford, M., &amp; Gottlieb, J. (2019). Diverse motives for human curiosity. <em>Nature Human Behaviour</em>, <em>3</em>(6), 587–595.</p>
</div>
<div id="ref-Koolschijn2015-hd">
<p>Koolschijn, P. C. M. P., Geurts, H. M., Leij, A. R. van der, &amp; Scholte, H. S. (2015). Are autistic traits in the general population related to global and regional brain differences? <em>J. Autism Dev. Disord.</em>, <em>45</em>(9), 2779–2791.</p>
</div>
<div id="ref-Kostro2014-cm">
<p>Kostro, D., Abdulkadir, A., Durr, A., Roos, R., Leavitt, B. R., Johnson, H., Cash, D., Tabrizi, S. J., Scahill, R. I., Ronneberger, O., Klöppel, S., &amp; Track-HD Investigators. (2014). Correction of inter-scanner and within-subject variance in structural MRI based automated diagnosing. <em>Neuroimage</em>, <em>98</em>, 405–415.</p>
</div>
<div id="ref-Kriegeskorte2015-qi">
<p>Kriegeskorte, N. (2015). Deep neural networks: A new framework for modeling biological vision and brain information processing. <em>Annu Rev Vis Sci</em>, <em>1</em>, 417–446.</p>
</div>
<div id="ref-kriegeskorte2008representational">
<p>Kriegeskorte, N., Mur, M., &amp; Bandettini, P. A. (2008). Representational similarity analysis-connecting the branches of systems neuroscience. <em>Frontiers in Systems Neuroscience</em>, <em>2</em>, 4.</p>
</div>
<div id="ref-kriegeskorte2009circular">
<p>Kriegeskorte, N., Simmons, W. K., Bellgowan, P. S., &amp; Baker, C. I. (2009). Circular analysis in systems neuroscience: The dangers of double dipping. <em>Nature Neuroscience</em>, <em>12</em>(5), 535.</p>
</div>
<div id="ref-krishnan2016somatic">
<p>Krishnan, A., Woo, C.-W., Chang, L. J., Ruzic, L., Gu, X., López-Solà, M., Jackson, P. L., Pujol, J., Fan, J., &amp; Wager, T. D. (2016). Somatic and vicarious pain are represented by dissociable multivariate brain patterns. <em>Elife</em>, <em>5</em>, e15166.</p>
</div>
<div id="ref-Krumhuber2013-qi">
<p>Krumhuber, E. G., Kappas, A., &amp; Manstead, A. S. R. (2013). Effects of dynamic aspects of facial expressions: A review. <em>Emot. Rev.</em>, <em>5</em>(1), 41–46.</p>
</div>
<div id="ref-Kumar2020-eo">
<p>Kumar, M., Ellis, C. T., Lu, Q., Zhang, H., Capotă, M., Willke, T. L., Ramadge, P. J., Turk-Browne, N. B., &amp; Norman, K. A. (2020). BrainIAK tutorials: User-friendly learning materials for advanced fMRI analysis. <em>PLoS Comput. Biol.</em>, <em>16</em>(1), e1007549.</p>
</div>
<div id="ref-Kunz2019-uh">
<p>Kunz, M., Meixner, D., &amp; Lautenbacher, S. (2019). Facial muscle movements encoding pain—a systematic review. <em>Pain</em>, <em>160</em>(3), 535.</p>
</div>
<div id="ref-kveraga2015if">
<p>Kveraga, K., Boshyan, J., Adams Jr, R. B., Mote, J., Betz, N., Ward, N., Hadjikhani, N., Bar, M., &amp; Barrett, L. F. (2015). If it bleeds, it leads: Separating threat from mere negativity. <em>Social Cognitive and Affective Neuroscience</em>, <em>10</em>(1), 28–35.</p>
</div>
<div id="ref-lage2019methods">
<p>Lage-Castellanos, A., Valente, G., Formisano, E., &amp; De Martino, F. (2019). Methods for computing the maximum performance of computational models of fMRI responses. <em>PLoS Computational Biology</em>, <em>15</em>(3), e1006397.</p>
</div>
<div id="ref-lakens2013calculating">
<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and anovas. <em>Frontiers in Psychology</em>, <em>4</em>, 863.</p>
</div>
<div id="ref-lamm2011meta">
<p>Lamm, C., Decety, J., &amp; Singer, T. (2011). Meta-analytic evidence for common and distinct neural networks associated with directly experienced pain and empathy for pain. <em>Neuroimage</em>, <em>54</em>(3), 2492–2502.</p>
</div>
<div id="ref-lamm2015role">
<p>Lamm, C., &amp; Majdandžić, J. (2015). The role of shared neural activations, mirror neurons, and morality in empathy–a critical comment. <em>Neuroscience Research</em>, <em>90</em>, 15–24.</p>
</div>
<div id="ref-lang2005international">
<p>Lang, P. J. (2005). International affective picture system (iaps): Affective ratings of pictures and instruction manual. <em>Technical Report</em>.</p>
</div>
<div id="ref-lang2010emotion">
<p>Lang, P. J., &amp; Bradley, M. M. (2010). Emotion and the motivational brain. <em>Biological Psychology</em>, <em>84</em>(3), 437–450.</p>
</div>
<div id="ref-lang1997international">
<p>Lang, P. J., Bradley, M. M., Cuthbert, B. N., &amp; others. (1997). International affective picture system (iaps): Technical manual and affective ratings. <em>NIMH Center for the Study of Emotion and Attention</em>, <em>1</em>, 39–58.</p>
</div>
<div id="ref-LaRocque2013-sh">
<p>LaRocque, J. J., Lewis-Peacock, J. A., Drysdale, A. T., Oberauer, K., &amp; Postle, B. R. (2013). Decoding attended information in short-term memory: An EEG study. <em>J. Cogn. Neurosci.</em>, <em>25</em>(1), 127–142.</p>
</div>
<div id="ref-LeCun2015-xa">
<p>LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. <em>Nature</em>, <em>521</em>(7553), 436–444.</p>
</div>
<div id="ref-Lefevre2014-vo">
<p>Lefevre, C. E., Etchells, P. J., Howell, E. C., Clark, A. P., &amp; Penton-Voak, I. S. (2014). Facial width-to-height ratio predicts self-reported dominance and aggression in males and females, but a measure of masculinity does not. <em>Biol. Lett.</em>, <em>10</em>(10), 20140729.</p>
</div>
<div id="ref-legrand2009self">
<p>Legrand, D., &amp; Ruby, P. (2009). What is self-specific? Theoretical investigation and critical review of neuroimaging results. <em>Psychological Review</em>, <em>116</em>(1), 252.</p>
</div>
<div id="ref-lench2011discrete">
<p>Lench, H. C., Flores, S. A., &amp; Bench, S. W. (2011). Discrete emotions predict changes in cognition, judgment, experience, behavior, and physiology: A meta-analysis of experimental emotion elicitations. <em>Psychological Bulletin</em>, <em>137</em>(5), 834.</p>
</div>
<div id="ref-levy2012root">
<p>Levy, D. J., &amp; Glimcher, P. W. (2012). The root of all value: A neural common currency for choice. <em>Current Opinion in Neurobiology</em>, <em>22</em>(6), 1027–1038.</p>
</div>
<div id="ref-Li2016-ss">
<p>Li, X., Morgan, P. S., Ashburner, J., Smith, J., &amp; Rorden, C. (2016). The first step for neuroimaging data analysis: DICOM to NIfTI conversion. <em>J. Neurosci. Methods</em>, <em>264</em>, 47–56.</p>
</div>
<div id="ref-Lien1998-bg">
<p>Lien, J. J., Kanade, T., Cohn, J. F., &amp; Ching-Chung Li. (1998). Automated facial expression recognition based on FACS action units. <em>Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition</em>, 390–395.</p>
</div>
<div id="ref-van2018induction">
<p>Lieshout, L. L. van, Vandenbroucke, A. R., Müller, N. C., Cools, R., &amp; Lange, F. P. de. (2018). Induction and relief of curiosity elicit parietal and frontal activity. <em>Journal of Neuroscience</em>, <em>38</em>(10), 2579–2588.</p>
</div>
<div id="ref-Lindelov2019-jk">
<p>Lindeløv, J. K. (2019). <em>Common statistical tests are linear models</em>. <a href="https://lindeloev.github.io/tests-as-linear/">https://lindeloev.github.io/tests-as-linear/</a>.</p>
</div>
<div id="ref-lindquist2016brain">
<p>Lindquist, K. A., Satpute, A. B., Wager, T. D., Weber, J., &amp; Barrett, L. F. (2016). The brain basis of positive and negative affect: Evidence from a meta-analysis of the human neuroimaging literature. <em>Cerebral Cortex</em>, <em>26</em>(5), 1910–1922.</p>
</div>
<div id="ref-lindquist2012brain">
<p>Lindquist, K. A., Wager, T. D., Kober, H., Bliss-Moreau, E., &amp; Barrett, L. F. (2012). The brain basis of emotion: A meta-analytic review. <em>The Behavioral and Brain Sciences</em>, <em>35</em>(3), 121.</p>
</div>
<div id="ref-litman2005curiosity">
<p>Litman, J. (2005). Curiosity and the pleasures of learning: Wanting and liking new information. <em>Cognition &amp; Emotion</em>, <em>19</em>(6), 793–814.</p>
</div>
<div id="ref-Liu2020-vo">
<p>Liu, M., Duan, Y., Ince, R. A. A., Chen, C., Garrod, O. G. B., Schyns, P., &amp; Jack, R. (2020). <em>Facial expressions of emotion categories are embedded within a dimensional space of valence-arousal</em>.</p>
</div>
<div id="ref-liu2011common">
<p>Liu, X., Hairston, J., Schrier, M., &amp; Fan, J. (2011). Common and distinct networks underlying reward valence and processing stages: A meta-analysis of functional neuroimaging studies. <em>Neuroscience &amp; Biobehavioral Reviews</em>, <em>35</em>(5), 1219–1236.</p>
</div>
<div id="ref-loewenstein1994psychology">
<p>Loewenstein, G. (1994). The psychology of curiosity: A review and reinterpretation. <em>Psychological Bulletin</em>, <em>116</em>(1), 75.</p>
</div>
<div id="ref-Long2017-fb">
<p>Long, B., Yu, C. P., &amp; Konkle, T. (2017). A mid-level organization of the ventral stream. <em>bioRxiv</em>.</p>
</div>
<div id="ref-Luders2002-ms">
<p>Lüders, E., Steinmetz, H., &amp; Jäncke, L. (2002). Brain size and grey matter volume in the healthy human brain. <em>Neuroreport</em>, <em>13</em>(17), 2371–2374.</p>
</div>
<div id="ref-Van_der_Maas2021-rx">
<p>Maas, H. L. J. van der, Snoek, L., &amp; Stevenson, C. E. (2021). How much intelligence is there in artificial intelligence? A 2020 update. <em>Intelligence</em>, <em>87</em>.</p>
</div>
<div id="ref-Magnotta2006-zs">
<p>Magnotta, V. A., Friedman, L., &amp; FIRST BIRN. (2006). Measurement of Signal-to-Noise and Contrast-to-Noise in the fBIRN multicenter imaging study. <em>J. Digit. Imaging</em>, <em>19</em>(2), 140–147.</p>
</div>
<div id="ref-marchewka2014nencki">
<p>Marchewka, A., Żurawski, Ł., Jednoróg, K., &amp; Grabowska, A. (2014). The nencki affective picture system (naps): Introduction to a novel, standardized, wide-range, high-quality, realistic picture database. <em>Behavior Research Methods</em>, <em>46</em>(2), 596–610.</p>
</div>
<div id="ref-marvin2016curiosity">
<p>Marvin, C. B., &amp; Shohamy, D. (2016). Curiosity and reward: Valence predicts choice and information prediction errors enhance learning. <em>Journal of Experimental Psychology: General</em>, <em>145</em>(3), 266.</p>
</div>
<div id="ref-Matsumoto2008-qk">
<p>Matsumoto, D., Keltner, D., Shiota, M. N., O’Sullivan, M., &amp; Frank, M. (2008). Facial expressions of emotion. <em>Handbook of Emotions., 3rd Ed.</em>, <em>3</em>, 211–234.</p>
</div>
<div id="ref-McCarthy2019-yt">
<p>McCarthy, P. (2021). <em>FSLeyes</em> (Version 1.0.1). Zenodo. <a href="https://doi.org/10.5281/zenodo.4704476">https://doi.org/10.5281/zenodo.4704476</a></p>
</div>
<div id="ref-McCrae1987-ww">
<p>McCrae, R. R., &amp; Costa, P. T., Jr. (1987). Validation of the five-factor model of personality across instruments and observers. <em>J. Pers. Soc. Psychol.</em>, <em>52</em>(1), 81–90.</p>
</div>
<div id="ref-McElreath2020-pz">
<p>McElreath, R. (2020). <em>Statistical rethinking: A bayesian course with examples in R and STAN</em>. CRC Press.</p>
</div>
<div id="ref-McGrath2008-oj">
<p>McGrath, J., Saha, S., Chant, D., &amp; Welham, J. (2008). Schizophrenia: A concise overview of incidence, prevalence, and mortality. <em>Epidemiol. Rev.</em>, <em>30</em>, 67–76.</p>
</div>
<div id="ref-McKinney2011-kl">
<p>McKinney, W., &amp; Others. (2011). Pandas: A foundational python library for data analysis and statistics. <em>Python for High Performance and Scientific Computing</em>, <em>14</em>(9).</p>
</div>
<div id="ref-medford2010conjoint">
<p>Medford, N., &amp; Critchley, H. D. (2010). Conjoint activity of anterior insular and anterior cingulate cortex: Awareness and response. <em>Brain Structure and Function</em>, <em>214</em>(5-6), 535–549.</p>
</div>
<div id="ref-Mendes2019-yh">
<p>Mendes, N., Oligschläger, S., Lauckner, M. E., Golchert, J., Huntenburg, J. M., Falkiewicz, M., Ellamil, M., Krause, S., Baczkowski, B. M., Cozatl, R., Osoianu, A., Kumral, D., Pool, J., Golz, L., Dreyer, M., Haueis, P., Jost, R., Kramarenko, Y., Engen, H., … Margulies, D. S. (2019). A functional connectome phenotyping dataset including cognitive state and personality measures. <em>Sci Data</em>, <em>6</em>, 180307.</p>
</div>
<div id="ref-menon2010saliency">
<p>Menon, V., &amp; Uddin, L. Q. (2010). Saliency, switching, attention and control: A network model of insula function. <em>Brain Structure and Function</em>, <em>214</em>(5-6), 655–667.</p>
</div>
<div id="ref-Mileva2014-ld">
<p>Mileva, V. R., Cowan, M. L., Cobey, K. D., Knowles, K. K., &amp; Little, A. C. (2014). In the face of dominance: Self-perceived and other-perceived dominance are positively associated with facial-width-to-height ratio in men. <em>Pers. Individ. Dif.</em>, <em>69</em>, 115–118.</p>
</div>
<div id="ref-Milham2003-zc">
<p>Milham, M. P., Banich, M. T., &amp; Barad, V. (2003). Competition for priority in processing increases prefrontal cortex’s involvement in top-down control: An event-related fMRI study of the stroop task. <em>Brain Res. Cogn. Brain Res.</em>, <em>17</em>(2), 212–222.</p>
</div>
<div id="ref-Miller2016-oi">
<p>Miller, K. L., Alfaro-Almagro, F., Bangerter, N. K., Thomas, D. L., Yacoub, E., Xu, J., Bartsch, A. J., Jbabdi, S., Sotiropoulos, S. N., Andersson, J. L. R., Griffanti, L., Douaud, G., Okell, T. W., Weale, P., Dragonu, I., Garratt, S., Hudson, S., Collins, R., Jenkinson, M., … Smith, S. M. (2016). Multimodal population brain imaging in the UK biobank prospective epidemiological study. <em>Nat. Neurosci.</em>, <em>19</em>(11), 1523–1536.</p>
</div>
<div id="ref-misaki2010comparison">
<p>Misaki, M., Kim, Y., Bandettini, P. A., &amp; Kriegeskorte, N. (2010). Comparison of multivariate classifiers and response normalizations for pattern-information fMRI. <em>Neuroimage</em>, <em>53</em>(1), 103–118.</p>
</div>
<div id="ref-mischkowski2016painkiller">
<p>Mischkowski, D., Crocker, J., &amp; Way, B. M. (2016). From painkiller to empathy killer: Acetaminophen (paracetamol) reduces empathy for pain. <em>Social Cognitive and Affective Neuroscience</em>, <em>11</em>(9), 1345–1353.</p>
</div>
<div id="ref-Montepare2003-hy">
<p>Montepare, J. M., &amp; Dobish, H. (2003). The contribution of emotion perceptions and their overgeneralizations to trait impressions. <em>J. Nonverbal Behav.</em>, <em>27</em>(4), 237–254.</p>
</div>
<div id="ref-Moshontz2018-rc">
<p>Moshontz, H., Campbell, L., Ebersole, C. R., IJzerman, H., Urry, H. L., Forscher, P. S., Grahe, J. E., McCarthy, R. J., Musser, E. D., Antfolk, J., Castille, C. M., Evans, T. R., Fiedler, S., Flake, J. K., Forero, D. A., Janssen, S. M. J., Keene, J. R., Protzko, J., Aczel, B., … Chartier, C. R. (2018). The psychological science accelerator: Advancing psychology through a distributed collaborative network. <em>Adv Methods Pract Psychol Sci</em>, <em>1</em>(4), 501–515.</p>
</div>
<div id="ref-mumford2014impact">
<p>Mumford, J. A., Davis, T., &amp; Poldrack, R. A. (2014). The impact of study design on pattern estimation for single-trial multivariate pattern analysis. <em>Neuroimage</em>, <em>103</em>, 130–138.</p>
</div>
<div id="ref-murayama2018psychological">
<p>Murayama, K. (2018). Psychological science agenda| june 2018. <em>Psychological Science</em>.</p>
</div>
<div id="ref-murayama2019process">
<p>Murayama, K., FitzGibbon, L., &amp; Sakaki, M. (2019). Process account of curiosity and interest: A reward-learning perspective. <em>Educational Psychology Review</em>, <em>31</em>(4), 875–895.</p>
</div>
<div id="ref-Murugappan2021-yj">
<p>Murugappan, M., &amp; Mutawa, A. (2021). Facial geometric feature extraction based emotional expression classification using machine learning algorithms. <em>PLoS One</em>, <em>16</em>(2), e0247131.</p>
</div>
<div id="ref-Naselaris2021-ba">
<p>Naselaris, T., Allen, E., &amp; Kay, K. (2021). Extensive sampling for complete models of individual brains. <em>Current Opinion in Behavioral Sciences</em>, <em>40</em>, 45–51.</p>
</div>
<div id="ref-Naselaris2015-jn">
<p>Naselaris, T., &amp; Kay, K. N. (2015). Resolving ambiguities of MVPA using explicit models of representation. <em>Trends Cogn. Sci.</em>, <em>19</em>(10), 551–554.</p>
</div>
<div id="ref-Naselaris2011-oh">
<p>Naselaris, T., Kay, K. N., Nishimoto, S., &amp; Gallant, J. L. (2011). Encoding and decoding in fMRI. <em>Neuroimage</em>, <em>56</em>(2), 400–410.</p>
</div>
<div id="ref-Nastase2020-he">
<p>Nastase, S. A., Goldstein, A., &amp; Hasson, U. (2020). Keep it real: Rethinking the primacy of experimental control in cognitive neuroscience. <em>Neuroimage</em>, <em>222</em>, 117254.</p>
</div>
<div id="ref-Neri1999-rj">
<p>Neri, P., Parker, A. J., &amp; Blakemore, C. (1999). Probing the human stereoscopic system with reverse correlation. <em>Nature</em>, <em>401</em>(6754), 695–698.</p>
</div>
<div id="ref-Neth2009-eh">
<p>Neth, D., &amp; Martinez, A. M. (2009). Emotion perception in emotionless face images suggests a norm-based representation. <em>J. Vis.</em>, <em>9</em>(1), 5.1–11.</p>
</div>
<div id="ref-Newell1973-no">
<p>Newell, A. (1973). You can’t play 20 questions with nature and win: Projective comments on the papers of this symposium. In W. G. Chase (Ed.), <em>Visual information processing</em>. New York: Academic Press.</p>
</div>
<div id="ref-Ngo2021-kf">
<p>Ngo, G., Khosla, M., Jamison, K., Kuceyeski, A., &amp; others. (2021). Predicting individual task contrasts from resting-state functional connectivity using a surface-based convolutional network. <em>bioRxiv</em>.</p>
</div>
<div id="ref-nichols2005valid">
<p>Nichols, T., Brett, M., Andersson, J., Wager, T., &amp; Poline, J.-B. (2005). Valid conjunction inference with the minimum statistic. <em>Neuroimage</em>, <em>25</em>(3), 653–660.</p>
</div>
<div id="ref-Nichols2017-ze">
<p>Nichols, T. E., Das, S., Eickhoff, S. B., Evans, A. C., Glatard, T., Hanke, M., Kriegeskorte, N., Milham, M. P., Poldrack, R. A., Poline, J.-B., Proal, E., Thirion, B., Van Essen, D. C., White, T., &amp; Yeo, B. T. T. (2017). Best practices in data analysis and sharing in neuroimaging using MRI. <em>Nat. Neurosci.</em>, <em>20</em>(3), 299–303.</p>
</div>
<div id="ref-nichols2002nonparametric">
<p>Nichols, T. E., &amp; Holmes, A. P. (2002). Nonparametric permutation tests for functional neuroimaging: A primer with examples. <em>Human Brain Mapping</em>, <em>15</em>(1), 1–25.</p>
</div>
<div id="ref-Nili2014-ar">
<p>Nili, H., Wingfield, C., Walther, A., Su, L., Marslen-Wilson, W., &amp; Kriegeskorte, N. (2014). A toolbox for representational similarity analysis. <em>PLoS Comput. Biol.</em>, <em>10</em>(4), e1003553.</p>
</div>
<div id="ref-norman2006beyond">
<p>Norman, K. A., Polyn, S. M., Detre, G. J., &amp; Haxby, J. V. (2006). Beyond mind-reading: Multi-voxel pattern analysis of fMRI data. <em>Trends in Cognitive Sciences</em>, <em>10</em>(9), 424–430.</p>
</div>
<div id="ref-Nunez2019-lh">
<p>Núñez, R., Allen, M., Gao, R., Miller Rigoli, C., Relaford-Doyle, J., &amp; Semenuks, A. (2019). What happened to cognitive science? <em>Nat Hum Behav</em>, <em>3</em>(8), 782–791.</p>
</div>
<div id="ref-OBrien2011-lj">
<p>O’Brien, L. M., Ziegler, D. A., Deutsch, C. K., Frazier, J. A., Herbert, M. R., &amp; Locascio, J. J. (2011). Statistical adjustments for brain size in volumetric neuroimaging studies: Some practical implications in methods. <em>Psychiatry Res.</em>, <em>193</em>(2), 113–122.</p>
</div>
<div id="ref-Ojala2010-rc">
<p>Ojala, M., &amp; Garriga, G. C. (2010). Permutation tests for studying classifier performance. <em>J. Mach. Learn. Res.</em>, <em>11</em>(Jun), 1833–1863.</p>
</div>
<div id="ref-Onderwijsindeling2016-tb">
<p>Onderwijsindeling, S. (2016). Standard educational classification. <em>Den Haag/Heerlen, Netherlands: Centraal Bureau Voor de Statistiek [Statistics Netherlands]</em>.</p>
</div>
<div id="ref-Oosterhof2009-mf">
<p>Oosterhof, N. N., &amp; Todorov, A. (2009). Shared perceptual basis of emotional expressions and trustworthiness impressions from faces. <em>Emotion</em>, <em>9</em>(1), 128–133.</p>
</div>
<div id="ref-oosterwijk2017choosing">
<p>Oosterwijk, S. (2017a). Choosing the negative: A behavioral demonstration of morbid curiosity. <em>PloS One</em>, <em>12</em>(7), e0178399.</p>
</div>
<div id="ref-oosterwijk2017prereg">
<p>Oosterwijk, S. (2017b). <em>CurioVal preregistered fMRI analyses</em>. OSF. <a href="osf.io/gdtk9">osf.io/gdtk9</a></p>
</div>
<div id="ref-oosterwijk2014embodiment">
<p>Oosterwijk, S., &amp; Barrett, L. F. (2014). Embodiment in the construction of emotion experience and emotion understanding. <em>Routledge Handbook of Embodied Cognition. New York: Routledge</em>, 250–260.</p>
</div>
<div id="ref-oosterwijk2016neural">
<p>Oosterwijk, S., Lindquist, K. A., Adebayo, M., &amp; Barrett, L. F. (2016). The neural representation of typical and atypical experiences of negative images: Comparing fear, disgust and morbid fascination. <em>Social Cognitive and Affective Neuroscience</em>, <em>11</em>(1), 11–22.</p>
</div>
<div id="ref-oosterwijk2012states">
<p>Oosterwijk, S., Lindquist, K. A., Anderson, E., Dautoff, R., Moriguchi, Y., &amp; Barrett, L. F. (2012). States of mind: Emotions, body feelings, and thoughts share distributed neural networks. <em>NeuroImage</em>, <em>62</em>(3), 2110–2128.</p>
</div>
<div id="ref-oosterwijk2015concepts">
<p>Oosterwijk, S., Mackey, S., Wilson-Mendenhall, C., Winkielman, P., &amp; Paulus, M. P. (2015). Concepts in context: Processing mental state concepts with internal or external focus involves different neural systems. <em>Social Neuroscience</em>, <em>10</em>(3), 294–307.</p>
</div>
<div id="ref-Oosterwijk2017-sc">
<p>Oosterwijk, S., Snoek, L., Rotteveel, M., Barrett, L. F., &amp; Scholte, H. S. (2017). Shared states: Using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding. <em>Soc. Cogn. Affect. Neurosci.</em>, <em>12</em>(7), 1025–1035.</p>
</div>
<div id="ref-Oosterwijk2020-uf">
<p>Oosterwijk, S., Snoek, L., Tekoppele, J., Engelbert, L. H., &amp; Scholte, H. S. (2020). Choosing to view morbid information involves reward circuitry. <em>Sci. Rep.</em>, <em>10</em>(1), 15291.</p>
</div>
<div id="ref-parkinson2014common">
<p>Parkinson, C., Liu, S., &amp; Wheatley, T. (2014). A common cortical metric for spatial, temporal, and social distance. <em>Journal of Neuroscience</em>, <em>34</em>(5), 1979–1987.</p>
</div>
<div id="ref-Parmley2014-nj">
<p>Parmley, M., &amp; Cunningham, J. G. (2014). She looks sad, but he looks mad: The effects of age, gender, and ambiguity on emotion perception. <em>J. Soc. Psychol.</em>, <em>154</em>(4), 323–338.</p>
</div>
<div id="ref-Parra2005-um">
<p>Parra, L. C., Spence, C. D., Gerson, A. D., &amp; Sajda, P. (2005). Recipes for the linear analysis of EEG. <em>Neuroimage</em>, <em>28</em>(2), 326–341.</p>
</div>
<div id="ref-pedregosa2011scikit">
<p>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., &amp; others. (2011). Scikit-learn: Machine learning in python. <em>The Journal of Machine Learning Research</em>, <em>12</em>, 2825–2830.</p>
</div>
<div id="ref-peelen2010supramodal">
<p>Peelen, M. V., Atkinson, A. P., &amp; Vuilleumier, P. (2010). Supramodal representations of perceived emotions in the human brain. <em>Journal of Neuroscience</em>, <em>30</em>(30), 10127–10134.</p>
</div>
<div id="ref-Peelen2007-ew">
<p>Peelen, M. V., &amp; Downing, P. E. (2007). Using multi-voxel pattern analysis of fMRI data to interpret overlapping functional activations. <em>Trends Cogn. Sci.</em>, <em>11</em>(1), 4–5.</p>
</div>
<div id="ref-Peirce2019-rj">
<p>Peirce, J., Gray, J. R., Simpson, S., MacAskill, M., Höchenberger, R., Sogo, H., Kastman, E., &amp; Lindeløv, J. K. (2019). PsychoPy2: Experiments in behavior made easy. <em>Behav. Res. Methods</em>, <em>51</em>(1), 195–203.</p>
</div>
<div id="ref-Pessoa2002-tb">
<p>Pessoa, L., Gutierrez, E., Bandettini, P., &amp; Ungerleider, L. (2002). Neural correlates of visual working memory: fMRI amplitude predicts task performance. <em>Neuron</em>, <em>35</em>(5), 975–987.</p>
</div>
<div id="ref-Pinto2013-kh">
<p>Pinto, Y., Leij, A. R. van der, Sligte, I. G., Lamme, V. A. F., &amp; Scholte, H. S. (2013). Bottom-up and top-down attention are independent. <em>J. Vis.</em>, <em>13</em>(3), 16.</p>
</div>
<div id="ref-poldrack2006can">
<p>Poldrack, R. A. (2006). Can cognitive processes be inferred from neuroimaging data? <em>Trends in Cognitive Sciences</em>, <em>10</em>(2), 59–63.</p>
</div>
<div id="ref-Poldrack2014-ov">
<p>Poldrack, R. A., &amp; Gorgolewski, K. J. (2014). Making big data open: Data sharing in neuroimaging. <em>Nat. Neurosci.</em>, <em>17</em>(11), 1510–1517.</p>
</div>
<div id="ref-popov2018practices">
<p>Popov, V., Ostarek, M., &amp; Tenison, C. (2018). Practices and pitfalls in inferring neural representations. <em>NeuroImage</em>, <em>174</em>, 340–351.</p>
</div>
<div id="ref-Power2012-kt">
<p>Power, J. D., Barnes, K. A., Snyder, A. Z., Schlaggar, B. L., &amp; Petersen, S. E. (2012). Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion. <em>Neuroimage</em>, <em>59</em>(3), 2142–2154.</p>
</div>
<div id="ref-Power2014-gh">
<p>Power, J. D., Mitra, A., Laumann, T. O., Snyder, A. Z., Schlaggar, B. L., &amp; Petersen, S. E. (2014). Methods to detect, characterize, and remove motion artifact in resting state fMRI. <em>Neuroimage</em>, <em>84</em>, 320–341.</p>
</div>
<div id="ref-powers2020evaluation">
<p>Powers, D. M. (2011). Evaluation: From precision, recall and f-measure to roc, informedness, markedness and correlation. <em>arXiv Preprint arXiv:2010.16061</em>.</p>
</div>
<div id="ref-pruim2015ica">
<p>Pruim, R. H., Mennes, M., Rooij, D. van, Llera, A., Buitelaar, J. K., &amp; Beckmann, C. F. (2015). ICA-aroma: A robust ica-based strategy for removing motion artifacts from fMRI data. <em>Neuroimage</em>, <em>112</em>, 267–277.</p>
</div>
<div id="ref-pulvermuller2010active">
<p>Pulvermüller, F., &amp; Fadiga, L. (2010). Active perception: Sensorimotor circuits as a cortical basis for language. <em>Nature Reviews Neuroscience</em>, <em>11</em>(5), 351–360.</p>
</div>
<div id="ref-Punitha2013-jy">
<p>Punitha, A., &amp; Geetha, M. K. (2013). Texture based emotion recognition from facial expressions using support vector machine. <em>Int. J. Comput. Appl.</em>, <em>80</em>(5), 1–5.</p>
</div>
<div id="ref-Quionero-Candela2009-ge">
<p>Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., &amp; Lawrence, N. D. (2009). <em>Dataset shift in machine learning</em>. The MIT Press.</p>
</div>
<div id="ref-Ramakrishnan2014-ki">
<p>Ramakrishnan, K., Scholte, H. S., Groen, I. I. A., Smeulders, A. W. M., &amp; Ghebreab, S. (2014). Visual dictionaries as intermediate features in the human brain. <em>Front. Comput. Neurosci.</em>, <em>8</em>, 168.</p>
</div>
<div id="ref-Rao2017-bw">
<p>Rao, A., Monteiro, J. M., Mourao-Miranda, J., &amp; Alzheimer’s Disease Initiative. (2017). Predictive modelling using neuroimaging data in the presence of confounds. <em>Neuroimage</em>, <em>150</em>, 23–49.</p>
</div>
<div id="ref-Raven2000-hs">
<p>Raven, J. (2000). The raven’s progressive matrices: Change and stability over culture and time. <em>Cogn. Psychol.</em>, <em>41</em>(1), 1–48.</p>
</div>
<div id="ref-Raven1998-om">
<p>Raven, J., Court, J. H., &amp; Raven, J. C. (1998). <em>Manual for raven’s progressive matrices and vocabulary scales</em>.</p>
</div>
<div id="ref-Reggio1982-ex">
<p>Reggio, G. (1982). <em>Koyaanisqatsi</em>. Institute for Regional Education/American Zoetrope.</p>
</div>
<div id="ref-rime2005brief">
<p>Rimé, B., Delfosse, C., &amp; Corsini, S. (2005). Emotion fascination: Responses to viewing pictures of september 11 attacks. <em>Cognition &amp; Emotion</em>, <em>19</em>(6), 923–932.</p>
</div>
<div id="ref-Ringach2004-nn">
<p>Ringach, D., &amp; Shapley, R. (2004). Reverse correlation in neurophysiology. <em>Cogn. Sci.</em>, <em>28</em>(2), 147–166.</p>
</div>
<div id="ref-Ritchie2017-gl">
<p>Ritchie, J. B., Kaplan, D. M., &amp; Klein, C. (2017). Decoding the brain: Neural representation and the limits of multivariate pattern analysis in cognitive neuroscience. <em>Br. J. Philos. Sci.</em></p>
</div>
<div id="ref-Van_Rooij2021-bk">
<p>Rooij, I. van, &amp; Baggio, G. (2021). Theory before the test: How to build High-Verisimilitude explanatory theories in psychological science. <em>Perspect. Psychol. Sci.</em>, 1745691620970604.</p>
</div>
<div id="ref-Rosenblatt2016-oy">
<p>Rosenblatt, J. D. (2016). Multivariate revisit to “sex beyond the genitalia”. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>113</em>(14), E1966–7.</p>
</div>
<div id="ref-Rosenblatt2014-az">
<p>Rosenblatt, J. D., Vink, M., &amp; Benjamini, Y. (2014). Revisiting multi-subject random effects in fMRI: Advocating prevalence estimation. <em>Neuroimage</em>, <em>84</em>, 113–121.</p>
</div>
<div id="ref-Russakovsky2015-oo">
<p>Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., &amp; Fei-Fei, L. (2015). ImageNet large scale visual recognition challenge. <em>Int. J. Comput. Vis.</em>, <em>115</em>(3), 211–252.</p>
</div>
<div id="ref-rutgen2015placebo">
<p>Rütgen, M., Seidel, E.-M., Silani, G., Riečansky, I., Hummer, A., Windischberger, C., Petrovic, P., &amp; Lamm, C. (2015). Placebo analgesia and its opioidergic regulation suggest that empathy for pain is grounded in self pain. <em>Proceedings of the National Academy of Sciences</em>, <em>112</em>(41), E5638–E5646.</p>
</div>
<div id="ref-Saad2013-zd">
<p>Saad, Z. S., Reynolds, R. C., Jo, H. J., Gotts, S. J., Chen, G., Martin, A., &amp; Cox, R. W. (2013). Correcting brain-wide correlation differences in resting-state FMRI. <em>Brain Connect.</em>, <em>3</em>(4), 339–352.</p>
</div>
<div id="ref-sabatinelli2011emotional">
<p>Sabatinelli, D., Fortune, E. E., Li, Q., Siddiqui, A., Krafft, C., Oliver, W. T., Beck, S., &amp; Jeffries, J. (2011). Emotional perception: Meta-analyses of face and natural scene processing. <em>Neuroimage</em>, <em>54</em>(3), 2524–2533.</p>
</div>
<div id="ref-Sahani2003-kk">
<p>Sahani, M., &amp; Linden, J. F. (2003). How linear are auditory cortical responses? <em>Adv. Neural Inf. Process. Syst.</em>, 125–132.</p>
</div>
<div id="ref-Said2009-tf">
<p>Said, C. P., Sebe, N., &amp; Todorov, A. (2009). Structural resemblance to emotional expressions predicts evaluation of emotionally neutral faces. <em>Emotion</em>, <em>9</em>(2), 260–264.</p>
</div>
<div id="ref-sakaki2018curiosity">
<p>Sakaki, M., Yagi, A., &amp; Murayama, K. (2018). Curiosity in old age: A possible key to achieving adaptive aging. <em>Neuroscience &amp; Biobehavioral Reviews</em>, <em>88</em>, 106–116.</p>
</div>
<div id="ref-Salvatier2016-ko">
<p>Salvatier, J., Wiecki, T. V., &amp; Fonnesbeck, C. (2016). Probabilistic programming in python using PyMC3. <em>PeerJ Comput. Sci.</em>, <em>2</em>, e55.</p>
</div>
<div id="ref-samanez2015decision">
<p>Samanez-Larkin, G. R., &amp; Knutson, B. (2015). Decision making in the ageing brain: Changes in affective and motivational circuits. <em>Nature Reviews Neuroscience</em>, <em>16</em>(5), 278–289.</p>
</div>
<div id="ref-Sato2007-ah">
<p>Sato, W., &amp; Yoshikawa, S. (2007). Enhanced experience of emotional arousal in response to dynamic facial expressions. <em>J. Nonverbal Behav.</em>, <em>31</em>(2), 119–135.</p>
</div>
<div id="ref-satpute2019deconstructing">
<p>Satpute, A. B., Kragel, P. A., Barrett, L. F., Wager, T. D., &amp; Bianciardi, M. (2019). Deconstructing arousal into wakeful, autonomic and affective varieties. <em>Neuroscience Letters</em>, <em>693</em>, 19–28.</p>
</div>
<div id="ref-Van_der_Schalk2011-bq">
<p>Schalk, J. van der, Hawk, S. T., Fischer, A. H., &amp; Doosje, B. (2011). Moving faces, looking places: Validation of the amsterdam dynamic facial expression set (ADFES). <em>Emotion</em>, <em>11</em>(4), 907–920.</p>
</div>
<div id="ref-Schafer2019-ue">
<p>Schäfer, T., &amp; Schwarz, M. A. (2019). The meaningfulness of effect sizes in psychological research: Differences between Sub-Disciplines and the impact of potential biases. <em>Front. Psychol.</em>, <em>10</em>, 813.</p>
</div>
<div id="ref-Scholte2018-he">
<p>Scholte, H. S. (2018). Fantastic DNimals and where to find them. <em>Neuroimage</em>, <em>180</em>(Pt A), 112–113.</p>
</div>
<div id="ref-Schoppe2016-bu">
<p>Schoppe, O., Harper, N. S., Willmore, B. D. B., King, A. J., &amp; Schnupp, J. W. H. (2016). Measuring the performance of neural models. <em>Front. Comput. Neurosci.</em>, <em>10</em>, 10.</p>
</div>
<div id="ref-schyns2009information">
<p>Schyns, P. G., Gosselin, F., &amp; Smith, M. L. (2009). Information processing algorithms in the brain. <em>Trends in Cognitive Sciences</em>, <em>13</em>(1), 20–26.</p>
</div>
<div id="ref-scott1979optimal">
<p>Scott, D. W. (1979). On optimal and data-based histograms. <em>Biometrika</em>, <em>66</em>(3), 605–610.</p>
</div>
<div id="ref-Sedgwick2013-op">
<p>Sedgwick, P. (2013). Analysing case-control studies: Adjusting for confounding. <em>BMJ: British Medical Journal</em>, <em>346</em>.</p>
</div>
<div id="ref-Seijdel2020-ff">
<p>Seijdel, N., Tsakmakidis, N., Haan, E. H. F. de, Bohte, S. M., &amp; Scholte, H. S. (2020). Depth in convolutional neural networks solves scene segmentation. <em>PLoS Comput. Biol.</em>, <em>16</em>(7), e1008022.</p>
</div>
<div id="ref-Sepehrband2018-dy">
<p>Sepehrband, F., Lynch, K. M., Cabeen, R. P., Gonzalez-Zacarias, C., Zhao, L., D’Arcy, M., Kesselman, C., Herting, M. M., Dinov, I. D., Toga, A. W., &amp; Clark, K. A. (2018). Neuroanatomical morphometric characterization of sex differences in youth using statistical learning. <em>Neuroimage</em>, <em>172</em>, 217–227.</p>
</div>
<div id="ref-shenhav2016dorsal">
<p>Shenhav, A., Cohen, J. D., &amp; Botvinick, M. M. (2016). Dorsal anterior cingulate cortex and the value of control. <em>Nature Neuroscience</em>, <em>19</em>(10), 1286–1291.</p>
</div>
<div id="ref-silvia2008interest">
<p>Silvia, P. J. (2008). Interest—the curious emotion. <em>Current Directions in Psychological Science</em>, <em>17</em>(1), 57–60.</p>
</div>
<div id="ref-singer2012past">
<p>Singer, T. (2012). The past, present and future of social neuroscience: A european perspective. <em>Neuroimage</em>, <em>61</em>(2), 437–449.</p>
</div>
<div id="ref-singer2009common">
<p>Singer, T., Critchley, H. D., &amp; Preuschoff, K. (2009). A common role of insula in feelings, empathy and uncertainty. <em>Trends in Cognitive Sciences</em>, <em>13</em>(8), 334–340.</p>
</div>
<div id="ref-Smith2009-kj">
<p>Smith, S. M., Fox, P. T., Miller, K. L., Glahn, D. C., Fox, P. M., Mackay, C. E., Filippini, N., Watkins, K. E., Toro, R., Laird, A. R., &amp; Beckmann, C. F. (2009). Correspondence of the brain’s functional architecture during activation and rest. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>106</em>(31), 13040–13045.</p>
</div>
<div id="ref-Smith2006-sf">
<p>Smith, S. M., Jenkinson, M., Johansen-Berg, H., Rueckert, D., Nichols, T. E., Mackay, C. E., Watkins, K. E., Ciccarelli, O., Cader, M. Z., Matthews, P. M., &amp; Behrens, T. E. J. (2006). Tract-based spatial statistics: Voxelwise analysis of multi-subject diffusion data. <em>Neuroimage</em>, <em>31</em>(4), 1487–1505.</p>
</div>
<div id="ref-Smith2004-sc">
<p>Smith, S. M., Jenkinson, M., Woolrich, M. W., Beckmann, C. F., Behrens, T. E. J., Johansen-Berg, H., Bannister, P. R., De Luca, M., Drobnjak, I., Flitney, D. E., Niazy, R. K., Saunders, J., Vickers, J., Zhang, Y., De Stefano, N., Brady, J. M., &amp; Matthews, P. M. (2004). Advances in functional and structural MR image analysis and implementation as FSL. <em>Neuroimage</em>, <em>23 Suppl 1</em>, S208–19.</p>
</div>
<div id="ref-smith2009threshold">
<p>Smith, S. M., &amp; Nichols, T. E. (2009). Threshold-free cluster enhancement: Addressing problems of smoothing, threshold dependence and localisation in cluster inference. <em>Neuroimage</em>, <em>44</em>(1), 83–98.</p>
</div>
<div id="ref-Smith2018-th">
<p>Smith, S. M., &amp; Nichols, T. E. (2018). Statistical challenges in “big data” human neuroimaging. <em>Neuron</em>, <em>97</em>(2), 263–268.</p>
</div>
<div id="ref-Snoek2020n-id1000">
<p>Snoek, L., Miesen, M. van der, Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., &amp; Scholte, H. S. &amp;. (2020a). <em>AOMIC-ID1000 NeuroVault</em>.</p>
</div>
<div id="ref-Snoek2020-id1000">
<p>Snoek, L., Miesen, M. van der, Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., &amp; Scholte, H. S. &amp;. (2020b). <em>AOMIC-ID1000 OpenNeuro</em>.</p>
</div>
<div id="ref-Snoek2020n-piop1">
<p>Snoek, L., Miesen, M. van der, Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., &amp; Scholte, H. S. &amp;. (2020c). <em>AOMIC-PIOP1 NeuroVault</em>.</p>
</div>
<div id="ref-Snoek2020-piop1">
<p>Snoek, L., Miesen, M. van der, Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., &amp; Scholte, H. S. &amp;. (2020d). <em>AOMIC-PIOP1 OpenNeuro</em>.</p>
</div>
<div id="ref-Snoek2020n-piop2">
<p>Snoek, L., Miesen, M. van der, Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., &amp; Scholte, H. S. &amp;. (2020e). <em>AOMIC-PIOP2 NeuroVault</em>.</p>
</div>
<div id="ref-Snoek2020-piop2">
<p>Snoek, L., Miesen, M. van der, Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., &amp; Scholte, H. S. &amp;. (2020f). <em>AOMIC-PIOP2 OpenNeuro</em>.</p>
</div>
<div id="ref-Snoek2021-jx">
<p>Snoek, L., Miesen, M. M. van der, Beemsterboer, T., Leij, A. van der, Eigenhuis, A., &amp; Steven Scholte, H. (2021). The amsterdam open MRI collection, a set of multimodal MRI datasets for individual difference analyses. <em>Sci Data</em>, <em>8</em>(1), 85.</p>
</div>
<div id="ref-Snoek2019-my">
<p>Snoek, L., Miletić, S., &amp; Scholte, H. S. (2019). How to control for confounds in decoding analyses of neuroimaging data. <em>Neuroimage</em>, <em>184</em>, 741–760.</p>
</div>
<div id="ref-snoek-submitted">
<p>Snoek, L., Mittenbühler, M., Jack, R., Schyns, P., Fischer, A., &amp; Scholte, H. S. (n.d.). <em>Explainable models of facial movements predict emotion perception behavior</em>.</p>
</div>
<div id="ref-Spielberger1970-td">
<p>Spielberger, C. D., Gorsuch, R. L., &amp; Lushene, R. E. (1970). <em>STAI manual for the State-Trait anxiety inventory</em>. Consulting Psychologists Press.</p>
</div>
<div id="ref-spreng2009common">
<p>Spreng, R. N., Mar, R. A., &amp; Kim, A. S. (2009). The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: A quantitative meta-analysis. <em>Journal of Cognitive Neuroscience</em>, <em>21</em>(3), 489–510.</p>
</div>
<div id="ref-spunt2012integrative">
<p>Spunt, R. P., &amp; Lieberman, M. D. (2012). An integrative model of the neural systems supporting the comprehension of observed emotional behavior. <em>Neuroimage</em>, <em>59</em>(3), 3050–3059.</p>
</div>
<div id="ref-stelzer2014prioritizing">
<p>Stelzer, J., Buschmann, T., Lohmann, G., Margulies, D. S., Trampel, R., &amp; Turner, R. (2014). Prioritizing spatial accuracy in high-resolution fMRI data using multivariate feature weight mapping. <em>Frontiers in Neuroscience</em>, <em>8</em>, 66.</p>
</div>
<div id="ref-Streiner2006-ze">
<p>Streiner, D. L. (2006). Building a better model: An introduction to structural equation modelling. <em>Can. J. Psychiatry</em>, <em>51</em>(5), 317–324.</p>
</div>
<div id="ref-tamir2016people">
<p>Tamir, M. (2016). Why do people regulate their emotions? A taxonomy of motives in emotion regulation. <em>Personality and Social Psychology Review</em>, <em>20</em>(3), 199–222.</p>
</div>
<div id="ref-Thorstenson2018-io">
<p>Thorstenson, C. A., Elliot, A. J., Pazda, A. D., Perrett, D. I., &amp; Xiao, D. (2018). Emotion-color associations in the context of the face. <em>Emotion</em>, <em>18</em>(7), 1032–1042.</p>
</div>
<div id="ref-Tjur2009-dp">
<p>Tjur, T. (2009). Coefficients of determination in logistic regression Models—A new proposal: The coefficient of discrimination. <em>Am. Stat.</em>, <em>63</em>(4), 366–372.</p>
</div>
<div id="ref-Todd2013-sd">
<p>Todd, M. T., Nystrom, L. E., &amp; Cohen, J. D. (2013). Confounds in multivariate pattern analysis: Theory and rule representation case study. <em>Neuroimage</em>, <em>77</em>, 157–165.</p>
</div>
<div id="ref-Todorov2008-eb">
<p>Todorov, A., Baron, S. G., &amp; Oosterhof, N. N. (2008). Evaluating face trustworthiness: A model based approach. <em>Soc. Cogn. Affect. Neurosci.</em>, <em>3</em>(2), 119–127.</p>
</div>
<div id="ref-Toisoul2021-yc">
<p>Toisoul, A., Kossaifi, J., Bulat, A., Tzimiropoulos, G., &amp; Pantic, M. (2021). Estimation of continuous valence and arousal levels from faces in naturalistic conditions. <em>Nature Machine Intelligence</em>, <em>3</em>(1), 42–50.</p>
</div>
<div id="ref-Tosh2020-sf">
<p>Tosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., &amp; Hsu, D. (2020). <em>The piranha problem: Large effects swimming in a small pond</em>. <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/piranhas.pdf">http://www.stat.columbia.edu/~gelman/research/unpublished/piranhas.pdf</a>; stat.columbia.edu.</p>
</div>
<div id="ref-Tottenham2009-vn">
<p>Tottenham, N., Tanaka, J. W., Leon, A. C., McCarry, T., Nurse, M., Hare, T. A., Marcus, D. J., Westerlund, A., Casey, B. J., &amp; Nelson, C. (2009). The NimStim set of facial expressions: Judgments from untrained research participants. <em>Psychiatry Res.</em>, <em>168</em>(3), 242–249.</p>
</div>
<div id="ref-Tournier2019-hh">
<p>Tournier, J.-D., Smith, R., Raffelt, D., Tabbara, R., Dhollander, T., Pietsch, M., Christiaens, D., Jeurissen, B., Yeh, C.-H., &amp; Connelly, A. (2019). MRtrix3: A fast, flexible and open software framework for medical image processing and visualisation. <em>Neuroimage</em>, <em>202</em>, 116137.</p>
</div>
<div id="ref-Treiber2016-mc">
<p>Treiber, J. M., White, N. S., Steed, T. C., Bartsch, H., Holland, D., Farid, N., McDonald, C. R., Carter, B. S., Dale, A. M., &amp; Chen, C. C. (2016). Characterization and correction of geometric distortions in 814 diffusion weighted images. <em>PLoS One</em>, <em>11</em>(3), e0152472.</p>
</div>
<div id="ref-Turner2017-fi">
<p>Turner, B. M., Forstmann, B. U., Love, B. C., Palmeri, T. J., &amp; Van Maanen, L. (2017). Approaches to analysis in model-based cognitive neuroscience. <em>J. Math. Psychol.</em>, <em>76</em>(B), 65–79.</p>
</div>
<div id="ref-Tustison2010-tk">
<p>Tustison, N. J., Avants, B. B., Cook, P. A., Zheng, Y., Egan, A., Yushkevich, P. A., &amp; Gee, J. C. (2010). N4ITK: Improved N3 bias correction. <em>IEEE Trans. Med. Imaging</em>, <em>29</em>(6), 1310–1320.</p>
</div>
<div id="ref-uddin2007self">
<p>Uddin, L. Q., Iacoboni, M., Lange, C., &amp; Keenan, J. P. (2007). The self and social cognition: The role of cortical midline structures and mirror neurons. <em>Trends in Cognitive Sciences</em>, <em>11</em>(4), 153–157.</p>
</div>
<div id="ref-unkelbach2008positive">
<p>Unkelbach, C., Fiedler, K., Bayer, M., Stegmüller, M., &amp; Danner, D. (2008). Why positive information is processed faster: The density hypothesis. <em>Journal of Personality and Social Psychology</em>, <em>95</em>(1), 36.</p>
</div>
<div id="ref-Van_der_Ploeg1980-tq">
<p>Van der Ploeg, H. M. (1980). Validity of the Zelf-Beoordelings-Vragenlijst (a dutch version of the spielberger State-Trait anxiety inventory). <em>Ned. Tijdschr. Psychol.</em>, <em>35</em>(4), 243–249.</p>
</div>
<div id="ref-Van_Essen2013-df">
<p>Van Essen, D. C., Smith, S. M., Barch, D. M., Behrens, T. E. J., Yacoub, E., Ugurbil, K., &amp; WU-Minn HCP Consortium. (2013). The WU-Minn human connectome project: An overview. <em>Neuroimage</em>, <em>80</em>, 62–79.</p>
</div>
<div id="ref-Van_Haren2013-iv">
<p>Van Haren, N. E., Cahn, W., Hulshoff Pol, H. E., &amp; Kahn, R. S. (2013). Confounders of excessive brain volume loss in schizophrenia. <em>Neurosci. Biobehav. Rev.</em>, <em>37</em>(10 Pt 1), 2418–2423.</p>
</div>
<div id="ref-van2009understanding">
<p>Van Overwalle, F., &amp; Baetens, K. (2009). Understanding others’ actions and goals by mirror and mentalizing systems: A meta-analysis. <em>Neuroimage</em>, <em>48</em>(3), 564–584.</p>
</div>
<div id="ref-Varoquaux2018-uo">
<p>Varoquaux, G. (2018). Cross-validation failure: Small sample sizes lead to large error bars. <em>Neuroimage</em>, <em>180</em>(Pt A), 68–77.</p>
</div>
<div id="ref-Varoquaux2017-fj">
<p>Varoquaux, G., Raamana, P. R., Engemann, D. A., Hoyos-Idrobo, A., Schwartz, Y., &amp; Thirion, B. (2017). Assessing and tuning brain decoders: Cross-validation, caveats, and guidelines. <em>Neuroimage</em>, <em>145</em>(Pt B), 166–179.</p>
</div>
<div id="ref-Varoquaux2014-su">
<p>Varoquaux, G., &amp; Thirion, B. (2014). How machine learning is shaping cognitive neuroimaging. <em>Gigascience</em>, <em>3</em>, 28.</p>
</div>
<div id="ref-Veraart2016-zi">
<p>Veraart, J., Fieremans, E., &amp; Novikov, D. S. (2016). Diffusion MRI noise mapping using random matrix theory. <em>Magn. Reson. Med.</em>, <em>76</em>(5), 1582–1593.</p>
</div>
<div id="ref-Veraart2016-rv">
<p>Veraart, J., Novikov, D. S., Christiaens, D., Ades-Aron, B., Sijbers, J., &amp; Fieremans, E. (2016). Denoising of diffusion MRI using random matrix theory. <em>Neuroimage</em>, <em>142</em>, 394–406.</p>
</div>
<div id="ref-Veraart2013-ya">
<p>Veraart, J., Sijbers, J., Sunaert, S., Leemans, A., &amp; Jeurissen, B. (2013). Weighted linear least squares estimation of diffusion MRI parameters: Strengths, limitations, and pitfalls. <em>Neuroimage</em>, <em>81</em>, 335–346.</p>
</div>
<div id="ref-Vorst2010-ex">
<p>Vorst, H. (2010). <em>Intelligentie structuur test (IST)</em>. Hogrefe.</p>
</div>
<div id="ref-Van_Waarde2014-sh">
<p>Waarde, J. A. van, Scholte, H. S., Oudheusden, L. J. B. van, Verwey, B., Denys, D., &amp; Wingen, G. A. van. (2014). A functional MRI marker may predict the outcome of electroconvulsive therapy in severe and treatment-resistant depression. <em>Mol. Psychiatry</em>, <em>20</em>, 609.</p>
</div>
<div id="ref-Wacholder1992-wb">
<p>Wacholder, S., Silverman, D. T., McLaughlin, J. K., &amp; Mandel, J. S. (1992). Selection of controls in case-control studies. III. Design options. <em>Am. J. Epidemiol.</em>, <em>135</em>(9), 1042–1050.</p>
</div>
<div id="ref-Wagenmakers2012-vd">
<p>Wagenmakers, E.-J., Wetzels, R., Borsboom, D., Maas, H. L. J. van der, &amp; Kievit, R. A. (2012). An agenda for purely confirmatory research. <em>Perspect. Psychol. Sci.</em>, <em>7</em>(6), 632–638.</p>
</div>
<div id="ref-wager2008prefrontal">
<p>Wager, T. D., Davidson, M. L., Hughes, B. L., Lindquist, M. A., &amp; Ochsner, K. N. (2008). Prefrontal-subcortical pathways mediating successful emotion regulation. <em>Neuron</em>, <em>59</em>(6), 1037–1050.</p>
</div>
<div id="ref-Walther2016-je">
<p>Walther, A., Nili, H., Ejaz, N., Alink, A., Kriegeskorte, N., &amp; Diedrichsen, J. (2016). Reliability of dissimilarity measures for multi-voxel pattern analysis. <em>Neuroimage</em>, <em>137</em>, 188–200.</p>
</div>
<div id="ref-Wang2017-nk">
<p>Wang, S., Peterson, D. J., Gatenby, J. C., Li, W., Grabowski, T. J., &amp; Madhyastha, T. M. (2017). Evaluation of field map and nonlinear registration methods for correction of susceptibility artifacts in diffusion MRI. <em>Front. Neuroinform.</em>, <em>11</em>, 17.</p>
</div>
<div id="ref-Waskom2020-qq">
<p>Waskom, M., Botvinnik, O., Ostblom, J., Lukauskas, S., Hobson, P., MaozGelbart, Gemperline, D. C., Augspurger, T., Halchenko, Y., Cole, J. B., Warmenhoven, J., Ruiter, J. de, Pye, C., Hoyer, S., Vanderplas, J., Villalba, S., Kunter, G., Quintero, E., Bachant, P., … Evans, C. (2020). <em>Mwaskom/seaborn: V0.10.0 (january 2020)</em>.</p>
</div>
<div id="ref-waskom2021seaborn">
<p>Waskom, M. L. (2021). Seaborn: Statistical data visualization. <em>Journal of Open Source Software</em>, <em>6</em>(60), 3021.</p>
</div>
<div id="ref-waytz2011two">
<p>Waytz, A., &amp; Mitchell, J. P. (2011). Two mechanisms for simulating other minds: Dissociations between mirroring and self-projection. <em>Current Directions in Psychological Science</em>, <em>20</em>(3), 197–200.</p>
</div>
<div id="ref-weber2018frontostriatal">
<p>Weber, S. C., Kahnt, T., Quednow, B. B., &amp; Tobler, P. N. (2018). Frontostriatal pathways gate processing of behaviorally relevant reward dimensions. <em>PLoS Biology</em>, <em>16</em>(10), e2005722.</p>
</div>
<div id="ref-Wegrzyn2017-ke">
<p>Wegrzyn, M., Vogt, M., Kireclioglu, B., Schneider, J., &amp; Kissler, J. (2017). Mapping the emotional face. How individual face parts contribute to successful emotion recognition. <em>PLoS One</em>, <em>12</em>(5), e0177239.</p>
</div>
<div id="ref-Weichwald2015-aj">
<p>Weichwald, S., Meyer, T., Özdenizci, O., Schölkopf, B., Ball, T., &amp; Grosse-Wentrup, M. (2015). Causal interpretation rules for encoding and decoding models in neuroimaging. <em>Neuroimage</em>, <em>110</em>, 48–59.</p>
</div>
<div id="ref-westfall2016fixing">
<p>Westfall, J., Nichols, T. E., &amp; Yarkoni, T. (2016). Fixing the stimulus-as-fixed-effect fallacy in task fMRI. <em>Wellcome Open Research</em>, <em>1</em>.</p>
</div>
<div id="ref-westfall2016statistically">
<p>Westfall, J., &amp; Yarkoni, T. (2016). Statistically controlling for confounding constructs is harder than you think. <em>PloS One</em>, <em>11</em>(3), e0152719.</p>
</div>
<div id="ref-wierzba2015erotic">
<p>Wierzba, M., Riegel, M., Pucz, A., Leśniewska, Z., Dragan, W. Ł., Gola, M., Jednoróg, K., &amp; Marchewka, A. (2015). Erotic subset for the nencki affective picture system (naps ero): Cross-sexual comparison study. <em>Frontiers in Psychology</em>, <em>6</em>, 1336.</p>
</div>
<div id="ref-Wiggers1982-na">
<p>Wiggers, M. (1982). Judgments of facial expressions of emotion predicted from facial behavior. <em>J. Nonverbal Behav.</em>, <em>7</em>(2), 101–116.</p>
</div>
<div id="ref-wilson2011grounding">
<p>Wilson-Mendenhall, C. D., Barrett, L. F., Simmons, W. K., &amp; Barsalou, L. W. (2011). Grounding emotion in situated conceptualization. <em>Neuropsychologia</em>, <em>49</em>(5), 1105–1127.</p>
</div>
<div id="ref-Windhager2011-ik">
<p>Windhager, S., Schaefer, K., &amp; Fink, B. (2011). Geometric morphometrics of male facial shape in relation to physical strength and perceived attractiveness, dominance, and masculinity. <em>Am. J. Hum. Biol.</em>, <em>23</em>(6), 805–814.</p>
</div>
<div id="ref-winkler2014permutation">
<p>Winkler, A. M., Ridgway, G. R., Webster, M. A., Smith, S. M., &amp; Nichols, T. E. (2014). Permutation inference for the general linear model. <em>Neuroimage</em>, <em>92</em>, 381–397.</p>
</div>
<div id="ref-wood2015controllability">
<p>Wood, K. H., Wheelock, M. D., Shumen, J. R., Bowen, K. H., Ver Hoef, L. W., &amp; Knight, D. C. (2015). Controllability modulates the neural response to predictable but not unpredictable threat in humans. <em>NeuroImage</em>, <em>119</em>, 371–381.</p>
</div>
<div id="ref-Woolgar2014-jb">
<p>Woolgar, A., Golland, P., &amp; Bode, S. (2014). Coping with confounds in multivoxel pattern analysis: What should we do about reaction time differences? A comment on todd, nystrom &amp; cohen 2013. <em>Neuroimage</em>, <em>98</em>, 506–512.</p>
</div>
<div id="ref-woolgar2011multi">
<p>Woolgar, A., Thompson, R., Bor, D., &amp; Duncan, J. (2011). Multi-voxel coding of stimuli, rules, and responses in human frontoparietal cortex. <em>Neuroimage</em>, <em>56</em>(2), 744–752.</p>
</div>
<div id="ref-woolrich2008robust">
<p>Woolrich, M. (2008). Robust group analysis using outlier inference. <em>Neuroimage</em>, <em>41</em>(2), 286–301.</p>
</div>
<div id="ref-woolrich2004multilevel">
<p>Woolrich, M. W., Behrens, T. E., Beckmann, C. F., Jenkinson, M., &amp; Smith, S. M. (2004). Multilevel linear modelling for fmri group analysis using bayesian inference. <em>Neuroimage</em>, <em>21</em>(4), 1732–1747.</p>
</div>
<div id="ref-woolrich2001temporal">
<p>Woolrich, M. W., Ripley, B. D., Brady, M., &amp; Smith, S. M. (2001). Temporal autocorrelation in univariate linear modeling of fmri data. <em>Neuroimage</em>, <em>14</em>(6), 1370–1386.</p>
</div>
<div id="ref-worsley2001statistical">
<p>Worsley, K. J. (2001). Statistical analysis of activation images. <em>Functional MRI: An Introduction to Methods</em>, <em>14</em>(1), 251–270.</p>
</div>
<div id="ref-Wu2006-qs">
<p>Wu, M. C.-K., David, S. V., &amp; Gallant, J. L. (2006). Complete functional characterization of sensory neurons by system identification. <em>Annu. Rev. Neurosci.</em>, <em>29</em>, 477–505.</p>
</div>
<div id="ref-wurm2015decoding">
<p>Wurm, M. F., &amp; Lingnau, A. (2015). Decoding actions at different levels of abstraction. <em>Journal of Neuroscience</em>, <em>35</em>(20), 7727–7735.</p>
</div>
<div id="ref-Xie2009-fp">
<p>Xie, X., &amp; Lam, K.-M. (2009). Facial expression recognition based on shape and texture. <em>Pattern Recognit.</em>, <em>42</em>(5), 1003–1011.</p>
</div>
<div id="ref-Xu2020-jd">
<p>Xu, T., White, J., Kalkan, S., &amp; Gunes, H. (2020). Investigating bias and fairness in facial expression recognition. <em>Computer Vision – ECCV 2020 Workshops</em>, 506–523.</p>
</div>
<div id="ref-xu2018deeper">
<p>Xu, T., Zhan, J., Garrod, O. G., Torr, P. H., Zhu, S.-C., Ince, R. A., &amp; Schyns, P. G. (2018). Deeper interpretability of deep networks. <em>arXiv Preprint arXiv:1811.07807</em>.</p>
</div>
<div id="ref-yamins2014performance">
<p>Yamins, D. L., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., &amp; DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. <em>Proceedings of the National Academy of Sciences</em>, <em>111</em>(23), 8619–8624.</p>
</div>
<div id="ref-Yarkoni2009-pz">
<p>Yarkoni, T. (2009). Big correlations in little studies: Inflated fMRI correlations reflect low statistical Power—Commentary on vul et al. (2009). <em>Perspect. Psychol. Sci.</em>, <em>4</em>(3), 294–298.</p>
</div>
<div id="ref-yarkoni2011large">
<p>Yarkoni, T., Poldrack, R. A., Nichols, T. E., Van Essen, D. C., &amp; Wager, T. D. (2011). Large-scale automated synthesis of human functional neuroimaging data. <em>Nature Methods</em>, <em>8</em>(8), 665–670.</p>
</div>
<div id="ref-Yarkoni2017-om">
<p>Yarkoni, T., &amp; Westfall, J. (2017). Choosing prediction over explanation in psychology: Lessons from machine learning. <em>Perspect. Psychol. Sci.</em>, 1745691617693393.</p>
</div>
<div id="ref-Yu2012-ag">
<p>Yu, H., Garrod, O. G. B., &amp; Schyns, P. G. (2012). Perception-driven facial expression synthesis. <em>Comput. Graph.</em>, <em>36</em>(3), 152–162.</p>
</div>
<div id="ref-Yu-Feng2007-sg">
<p>Yu-Feng, Z., Yong, H., Chao-Zhe, Z., Qing-Jiu, C., Man-Qiu, S., Meng, L., Li-Xia, T., Tian-Zi, J., &amp; Yu-Feng, W. (2007). Altered baseline brain activity in children with ADHD revealed by resting-state functional MRI. <em>Brain and Development</em>, <em>29</em>(2), 83–91.</p>
</div>
<div id="ref-zaki2012neuroscience">
<p>Zaki, J., &amp; Ochsner, K. N. (2012). The neuroscience of empathy: Progress, pitfalls and promise. <em>Nature Neuroscience</em>, <em>15</em>(5), 675–680.</p>
</div>
<div id="ref-zaki2016anatomy">
<p>Zaki, J., Wager, T. D., Singer, T., Keysers, C., &amp; Gazzola, V. (2016). The anatomy of suffering: Understanding the relationship between nociceptive and empathic pain. <em>Trends in Cognitive Sciences</em>, <em>20</em>(4), 249–259.</p>
</div>
<div id="ref-Zebrowitz2017-qe">
<p>Zebrowitz, L. A. (2017). First impressions from faces. <em>Curr. Dir. Psychol. Sci.</em>, <em>26</em>(3), 237–242.</p>
</div>
<div id="ref-Zech2018-bq">
<p>Zech, J. R., Badgeley, M. A., Liu, M., Costa, A. B., Titano, J. J., &amp; Oermann, E. K. (2018). Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study. <em>PLoS Med.</em>, <em>15</em>(11), e1002683.</p>
</div>
<div id="ref-Zhang2001-wa">
<p>Zhang, Y., Brady, M., &amp; Smith, S. (2001). Segmentation of brain MR images through a hidden markov random field model and the expectation-maximization algorithm. <em>IEEE Trans. Med. Imaging</em>, <em>20</em>(1), 45–57.</p>
</div>
<div id="ref-zuckerman1979">
<p>Zuckerman, M. (1979). <em>Sensation seeking. Beyond the optimal level of arousal</em>. L. Erlbaum Associates.</p>
</div>
<div id="ref-zuckerman1986personality">
<p>Zuckerman, M., &amp; Litle, P. (1986). Personality and curiosity about morbid and sexual events. <em>Personality and Individual Differences</em>, <em>7</em>(1), 49–56.</p>
</div>
</div>


</div>
            </section>

          </div>
        </div>
      </div>
<a href="resources-supplement.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="contributions-to-the-chapters.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"download": "docs/thesis.pdf"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
