<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Introduction | Towards prediction</title>
  <meta name="description" content="1 Introduction | Towards prediction" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Introduction | Towards prediction" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Introduction | Towards prediction" />
  
  
  

<meta name="author" content="Lukas Snoek" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="shared-states.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD thesis of Lukas Snoek</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="general-introduction.html"><a href="general-introduction.html#inference-done-differently"><i class="fa fa-check"></i><b>1.1</b> Inference done differently</a></li>
<li class="chapter" data-level="1.2" data-path="general-introduction.html"><a href="general-introduction.html#towards-prediction"><i class="fa fa-check"></i><b>1.2</b> Towards prediction</a></li>
<li class="chapter" data-level="1.3" data-path="general-introduction.html"><a href="general-introduction.html#outline-of-this-thesis"><i class="fa fa-check"></i><b>1.3</b> Outline of this thesis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="shared-states.html"><a href="shared-states.html"><i class="fa fa-check"></i><b>2</b> Shared states: using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding</a><ul>
<li class="chapter" data-level="2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods"><i class="fa fa-check"></i><b>2.2</b> Methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-subjects"><i class="fa fa-check"></i><b>2.2.1</b> Subjects</a></li>
<li class="chapter" data-level="2.2.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-experimental-design"><i class="fa fa-check"></i><b>2.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="2.2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-procedure"><i class="fa fa-check"></i><b>2.2.3</b> Procedure</a></li>
<li class="chapter" data-level="2.2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-image-acquisition"><i class="fa fa-check"></i><b>2.2.4</b> Image acquisition</a></li>
<li class="chapter" data-level="2.2.5" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-model-optimization-procedure"><i class="fa fa-check"></i><b>2.2.5</b> Model optimization procedure</a></li>
<li class="chapter" data-level="2.2.6" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-preprocessing"><i class="fa fa-check"></i><b>2.2.6</b> Preprocessing and single-trial modeling</a></li>
<li class="chapter" data-level="2.2.7" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-mvpa"><i class="fa fa-check"></i><b>2.2.7</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="2.2.8" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-additional-analyses"><i class="fa fa-check"></i><b>2.2.8</b> Additional analyses</a></li>
<li class="chapter" data-level="2.2.9" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-univariate-analysis"><i class="fa fa-check"></i><b>2.2.9</b> Univariate analysis</a></li>
<li class="chapter" data-level="2.2.10" data-path="shared-states.html"><a href="shared-states.html#shared-states-methods-code-availability"><i class="fa fa-check"></i><b>2.2.10</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="shared-states.html"><a href="shared-states.html#shared-states-results"><i class="fa fa-check"></i><b>2.3</b> Results</a><ul>
<li class="chapter" data-level="2.3.1" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-mvpa"><i class="fa fa-check"></i><b>2.3.1</b> Multi-voxel pattern analysis</a></li>
<li class="chapter" data-level="2.3.2" data-path="shared-states.html"><a href="shared-states.html#shared-states-results-univariate"><i class="fa fa-check"></i><b>2.3.2</b> Univariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="shared-states.html"><a href="shared-states.html#shared-states-discussion"><i class="fa fa-check"></i><b>2.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="confounds-decoding.html"><a href="confounds-decoding.html"><i class="fa fa-check"></i><b>3</b> How to control for confounds in decoding analyses of neuroimaging data</a><ul>
<li class="chapter" data-level="3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-true-vs-confounded"><i class="fa fa-check"></i><b>3.1.1</b> Partitioning effects into <em>true</em> signal and <em>confounded</em> signal</a></li>
<li class="chapter" data-level="3.1.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-methods"><i class="fa fa-check"></i><b>3.1.2</b> Methods for confound control</a></li>
<li class="chapter" data-level="3.1.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-introduction-current-study"><i class="fa fa-check"></i><b>3.1.3</b> Current study</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-data"><i class="fa fa-check"></i><b>3.2.1</b> Data</a></li>
<li class="chapter" data-level="3.2.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-pipeline"><i class="fa fa-check"></i><b>3.2.2</b> Decoding pipeline</a></li>
<li class="chapter" data-level="3.2.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-methods-evaluated-methods"><i class="fa fa-check"></i><b>3.2.3</b> Evaluated methods for confound control</a></li>
<li class="chapter" data-level="3.2.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#analyses-of-simulated-data"><i class="fa fa-check"></i><b>3.2.4</b> Analyses of simulated data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#results"><i class="fa fa-check"></i><b>3.3</b> Results</a><ul>
<li class="chapter" data-level="3.3.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#influence-of-brain-size"><i class="fa fa-check"></i><b>3.3.1</b> Influence of brain size</a></li>
<li class="chapter" data-level="3.3.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#baseline-model-no-confound-control"><i class="fa fa-check"></i><b>3.3.2</b> Baseline model: no confound control</a></li>
<li class="chapter" data-level="3.3.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#post-hoc-counterbalancing"><i class="fa fa-check"></i><b>3.3.3</b> Post hoc counterbalancing</a></li>
<li class="chapter" data-level="3.3.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#whole-dataset-confound-regression-wdcr"><i class="fa fa-check"></i><b>3.3.4</b> Whole-dataset confound regression (WDCR)</a></li>
<li class="chapter" data-level="3.3.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#cross-validated-confound-regression-cvcr"><i class="fa fa-check"></i><b>3.3.5</b> Cross-validated confound regression (CVCR)</a></li>
<li class="chapter" data-level="3.3.6" data-path="confounds-decoding.html"><a href="confounds-decoding.html#summary-methods-for-confound-control"><i class="fa fa-check"></i><b>3.3.6</b> Summary methods for confound control</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="confounds-decoding.html"><a href="confounds-decoding.html#confounds-decoding-discussion"><i class="fa fa-check"></i><b>3.4</b> Discussion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="confounds-decoding.html"><a href="confounds-decoding.html#relevance-and-consequences-for-previous-and-future-research"><i class="fa fa-check"></i><b>3.4.1</b> Relevance and consequences for previous and future research</a></li>
<li class="chapter" data-level="3.4.2" data-path="confounds-decoding.html"><a href="confounds-decoding.html#choosing-a-confound-model-linear-vs.-nonlinear-models"><i class="fa fa-check"></i><b>3.4.2</b> Choosing a confound model: linear vs. nonlinear models</a></li>
<li class="chapter" data-level="3.4.3" data-path="confounds-decoding.html"><a href="confounds-decoding.html#practical-recommendations"><i class="fa fa-check"></i><b>3.4.3</b> Practical recommendations</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="confounds-decoding.html"><a href="confounds-decoding.html#conclusion"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="aomic.html"><a href="aomic.html"><i class="fa fa-check"></i><b>4</b> The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses</a><ul>
<li class="chapter" data-level="4.1" data-path="aomic.html"><a href="aomic.html#background-summary"><i class="fa fa-check"></i><b>4.1</b> Background &amp; summary</a></li>
<li class="chapter" data-level="4.2" data-path="aomic.html"><a href="aomic.html#methods"><i class="fa fa-check"></i><b>4.2</b> Methods</a><ul>
<li class="chapter" data-level="4.2.1" data-path="aomic.html"><a href="aomic.html#scanner-details-and-general-scanning-protocol-all-datasets"><i class="fa fa-check"></i><b>4.2.1</b> Scanner details and general scanning protocol (all datasets)</a></li>
<li class="chapter" data-level="4.2.2" data-path="aomic.html"><a href="aomic.html#id1000-specifics"><i class="fa fa-check"></i><b>4.2.2</b> ID1000 specifics</a></li>
<li class="chapter" data-level="4.2.3" data-path="aomic.html"><a href="aomic.html#piop1-and-piop2-specifics"><i class="fa fa-check"></i><b>4.2.3</b> PIOP1 and PIOP2 specifics</a></li>
<li class="chapter" data-level="4.2.4" data-path="aomic.html"><a href="aomic.html#subject-variables-all-datasets"><i class="fa fa-check"></i><b>4.2.4</b> Subject variables (all datasets)</a></li>
<li class="chapter" data-level="4.2.5" data-path="aomic.html"><a href="aomic.html#psychometric-variables-all-datasets"><i class="fa fa-check"></i><b>4.2.5</b> Psychometric variables (all datasets)</a></li>
<li class="chapter" data-level="4.2.6" data-path="aomic.html"><a href="aomic.html#aomic-derivatives"><i class="fa fa-check"></i><b>4.2.6</b> Data standardization, preprocessing, and derivatives</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="aomic.html"><a href="aomic.html#data-records"><i class="fa fa-check"></i><b>4.3</b> Data records</a><ul>
<li class="chapter" data-level="4.3.1" data-path="aomic.html"><a href="aomic.html#data-formats-and-types"><i class="fa fa-check"></i><b>4.3.1</b> Data formats and types</a></li>
<li class="chapter" data-level="4.3.2" data-path="aomic.html"><a href="aomic.html#data-repositories-used"><i class="fa fa-check"></i><b>4.3.2</b> Data repositories used</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="aomic.html"><a href="aomic.html#technical-validation"><i class="fa fa-check"></i><b>4.4</b> Technical validation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="aomic.html"><a href="aomic.html#t1-weighted-scans"><i class="fa fa-check"></i><b>4.4.1</b> T1-weighted scans</a></li>
<li class="chapter" data-level="4.4.2" data-path="aomic.html"><a href="aomic.html#functional-bold-scans"><i class="fa fa-check"></i><b>4.4.2</b> Functional (BOLD) scans</a></li>
<li class="chapter" data-level="4.4.3" data-path="aomic.html"><a href="aomic.html#diffusion-weighted-scans"><i class="fa fa-check"></i><b>4.4.3</b> Diffusion-weighted scans</a></li>
<li class="chapter" data-level="4.4.4" data-path="aomic.html"><a href="aomic.html#physiological-data"><i class="fa fa-check"></i><b>4.4.4</b> Physiological data</a></li>
<li class="chapter" data-level="4.4.5" data-path="aomic.html"><a href="aomic.html#psychometric-data"><i class="fa fa-check"></i><b>4.4.5</b> Psychometric data</a></li>
<li class="chapter" data-level="4.4.6" data-path="aomic.html"><a href="aomic.html#aomic-code-availability"><i class="fa fa-check"></i><b>4.4.6</b> Code availability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html"><i class="fa fa-check"></i><b>5</b> Choosing to view morbid information involves reward circuitry</a><ul>
<li class="chapter" data-level="5.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods"><i class="fa fa-check"></i><b>5.2</b> Methods</a><ul>
<li class="chapter" data-level="5.2.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-participants"><i class="fa fa-check"></i><b>5.2.1</b> Participants</a></li>
<li class="chapter" data-level="5.2.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-design"><i class="fa fa-check"></i><b>5.2.2</b> Design</a></li>
<li class="chapter" data-level="5.2.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-materials"><i class="fa fa-check"></i><b>5.2.3</b> Materials</a></li>
<li class="chapter" data-level="5.2.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-procedure"><i class="fa fa-check"></i><b>5.2.4</b> Procedure</a></li>
<li class="chapter" data-level="5.2.5" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-behavioral-analysis"><i class="fa fa-check"></i><b>5.2.5</b> Behavioral analysis</a></li>
<li class="chapter" data-level="5.2.6" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-methods-imaging-details"><i class="fa fa-check"></i><b>5.2.6</b> Imaging details</a></li>
<li class="chapter" data-level="5.2.7" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-data-availability"><i class="fa fa-check"></i><b>5.2.7</b> Data availability</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results"><i class="fa fa-check"></i><b>5.3</b> Results</a><ul>
<li class="chapter" data-level="5.3.1" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-results-participants"><i class="fa fa-check"></i><b>5.3.1</b> Participants</a></li>
<li class="chapter" data-level="5.3.2" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#behavior-and-subjective-report"><i class="fa fa-check"></i><b>5.3.2</b> Behavior and subjective report</a></li>
<li class="chapter" data-level="5.3.3" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#roi-analyses"><i class="fa fa-check"></i><b>5.3.3</b> ROI analyses</a></li>
<li class="chapter" data-level="5.3.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#whole-brain-analyses"><i class="fa fa-check"></i><b>5.3.4</b> Whole-brain analyses</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="morbid-curiosity.html"><a href="morbid-curiosity.html#morbid-curiosity-discussion"><i class="fa fa-check"></i><b>5.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html"><i class="fa fa-check"></i><b>6</b> Explainable models of facial movements predict emotion perception behavior</a><ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#the-prediction-explanation-exploration-framework"><i class="fa fa-check"></i><b>6.1.1</b> The prediction-explanation-exploration framework</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-methods"><i class="fa fa-check"></i><b>6.2</b> Methods</a><ul>
<li class="chapter" data-level="6.2.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hypothesis-kernel-analysis-1"><i class="fa fa-check"></i><b>6.2.1</b> Hypothesis kernel analysis</a></li>
<li class="chapter" data-level="6.2.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#ablation-and-follow-up-exploration-analyses"><i class="fa fa-check"></i><b>6.2.2</b> Ablation and follow-up exploration analyses</a></li>
<li class="chapter" data-level="6.2.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-noise-ceiling"><i class="fa fa-check"></i><b>6.2.3</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="6.2.4" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#evaluated-mappings"><i class="fa fa-check"></i><b>6.2.4</b> Evaluated mappings</a></li>
<li class="chapter" data-level="6.2.5" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-dataset"><i class="fa fa-check"></i><b>6.2.5</b> Dataset used to evaluate mappings</a></li>
<li class="chapter" data-level="6.2.6" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-code"><i class="fa fa-check"></i><b>6.2.6</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-results"><i class="fa fa-check"></i><b>6.3</b> Results</a><ul>
<li class="chapter" data-level="6.3.1" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#prediction"><i class="fa fa-check"></i><b>6.3.1</b> Prediction</a></li>
<li class="chapter" data-level="6.3.2" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#explanation"><i class="fa fa-check"></i><b>6.3.2</b> Explanation</a></li>
<li class="chapter" data-level="6.3.3" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#exploration"><i class="fa fa-check"></i><b>6.3.3</b> Exploration</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-kernel-analysis.html"><a href="hypothesis-kernel-analysis.html#hka-discussion"><i class="fa fa-check"></i><b>6.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html"><i class="fa fa-check"></i><b>7</b> Affective face perception integrates both static and dynamic information</a><ul>
<li class="chapter" data-level="7.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-methods"><i class="fa fa-check"></i><b>7.2</b> Methods</a><ul>
<li class="chapter" data-level="7.2.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-participants"><i class="fa fa-check"></i><b>7.2.1</b> Participants</a></li>
<li class="chapter" data-level="7.2.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-experimental-design"><i class="fa fa-check"></i><b>7.2.2</b> Experimental design</a></li>
<li class="chapter" data-level="7.2.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-procedure"><i class="fa fa-check"></i><b>7.2.3</b> Procedure</a></li>
<li class="chapter" data-level="7.2.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-data-preproc"><i class="fa fa-check"></i><b>7.2.4</b> Data preprocessing</a></li>
<li class="chapter" data-level="7.2.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-pred-analysis"><i class="fa fa-check"></i><b>7.2.5</b> Predictive analysis</a></li>
<li class="chapter" data-level="7.2.6" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#noise-ceiling-estimation"><i class="fa fa-check"></i><b>7.2.6</b> Noise ceiling estimation</a></li>
<li class="chapter" data-level="7.2.7" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-bayes"><i class="fa fa-check"></i><b>7.2.7</b> Bayesian reconstructions</a></li>
<li class="chapter" data-level="7.2.8" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-code"><i class="fa fa-check"></i><b>7.2.8</b> Code availability</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-results"><i class="fa fa-check"></i><b>7.3</b> Results</a><ul>
<li class="chapter" data-level="7.3.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#encoding-model-performance"><i class="fa fa-check"></i><b>7.3.1</b> Encoding model performance</a></li>
<li class="chapter" data-level="7.3.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#reconstruction-model-visualizations"><i class="fa fa-check"></i><b>7.3.2</b> Reconstruction model visualizations</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-discussion"><i class="fa fa-check"></i><b>7.4</b> Discussion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#facial-morphology-independently-contributes-to-affective-face-perception"><i class="fa fa-check"></i><b>7.4.1</b> Facial morphology independently contributes to affective face perception</a></li>
<li class="chapter" data-level="7.4.2" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#the-influence-of-facial-morphology-does-not-result-from-visual-similarity-to-facial-movements"><i class="fa fa-check"></i><b>7.4.2</b> The influence of facial morphology does not result from visual similarity to facial movements</a></li>
<li class="chapter" data-level="7.4.3" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#categorical-representations-of-experienced-valence-and-arousal-correlate-with-representations-of-perceived-emotions"><i class="fa fa-check"></i><b>7.4.3</b> Categorical representations of experienced valence and arousal correlate with representations of perceived emotions</a></li>
<li class="chapter" data-level="7.4.4" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#predictive-models-quantify-what-is-not-yet-known"><i class="fa fa-check"></i><b>7.4.4</b> Predictive models quantify what is (not yet) known</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="static-vs-dynamic.html"><a href="static-vs-dynamic.html#svsd-conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i><b>8</b> Discussion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="shared-states-supplement.html"><a href="shared-states-supplement.html"><i class="fa fa-check"></i><b>A</b> Supplement to Chapter 2</a></li>
<li class="chapter" data-level="B" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html"><i class="fa fa-check"></i><b>B</b> Supplement to Chapter 3</a><ul>
<li class="chapter" data-level="B.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-methods"><i class="fa fa-check"></i><b>B.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="B.1.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#functional-mri-simulation"><i class="fa fa-check"></i><b>B.1.1</b> Functional MRI simulation</a></li>
<li class="chapter" data-level="B.1.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data"><i class="fa fa-check"></i><b>B.1.2</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.1.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation"><i class="fa fa-check"></i><b>B.1.3</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.1.4" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs-nonlinear-confound-models-predicting-vbm-and-tbss-data-based-on-brain-size"><i class="fa fa-check"></i><b>B.1.4</b> Linear vs nonlinear confound models: predicting VBM and TBSS data based on brain size</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#supplementary-results"><i class="fa fa-check"></i><b>B.2</b> Supplementary results</a><ul>
<li class="chapter" data-level="B.2.1" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#testing-confound-regression-on-simulated-fmri-data-1"><i class="fa fa-check"></i><b>B.2.1</b> Testing confound regression on simulated fMRI data</a></li>
<li class="chapter" data-level="B.2.2" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#controlling-for-confounds-during-pattern-estimation-1"><i class="fa fa-check"></i><b>B.2.2</b> Controlling for confounds during pattern estimation</a></li>
<li class="chapter" data-level="B.2.3" data-path="confounds-decoding-supplement.html"><a href="confounds-decoding-supplement.html#linear-vs.-nonlinear-confound-models-predicting-vbm-and-tbss-intensity-using-brain-size"><i class="fa fa-check"></i><b>B.2.3</b> Linear vs. nonlinear confound models: predicting VBM and TBSS intensity using brain size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="aomic-supplement.html"><a href="aomic-supplement.html"><i class="fa fa-check"></i><b>C</b> Supplement to Chapter 4</a></li>
<li class="chapter" data-level="D" data-path="morbid-curiosity-supplement.html"><a href="morbid-curiosity-supplement.html"><i class="fa fa-check"></i><b>D</b> Supplement to Chapter 5</a></li>
<li class="chapter" data-level="E" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html"><i class="fa fa-check"></i><b>E</b> Supplement to Chapter 6</a><ul>
<li class="chapter" data-level="E.1" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-supplementary-methods"><i class="fa fa-check"></i><b>E.1</b> Supplementary methods</a><ul>
<li class="chapter" data-level="E.1.1" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hypothesis-kernel-analysis-in-detail"><i class="fa fa-check"></i><b>E.1.1</b> Hypothesis kernel analysis (in detail)</a></li>
<li class="chapter" data-level="E.1.2" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-noise-ceiling-detail"><i class="fa fa-check"></i><b>E.1.2</b> Noise ceiling estimation (in detail)</a></li>
</ul></li>
<li class="chapter" data-level="E.2" data-path="hypothesis-kernel-analysis-supplement.html"><a href="hypothesis-kernel-analysis-supplement.html#hka-supp-fig"><i class="fa fa-check"></i><b>E.2</b> Supplementary figures</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="static-vs-dynamic-supplement.html"><a href="static-vs-dynamic-supplement.html"><i class="fa fa-check"></i><b>F</b> Supplement to Chapter 6</a></li>
<li class="chapter" data-level="G" data-path="resources-supplement.html"><a href="resources-supplement.html"><i class="fa fa-check"></i><b>G</b> Data, code, and educational materials</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="chapter" data-level="" data-path="contributions-to-the-chapters.html"><a href="contributions-to-the-chapters.html"><i class="fa fa-check"></i>Contributions to the chapters</a></li>
<li class="chapter" data-level="" data-path="list-of-other-publications.html"><a href="list-of-other-publications.html"><i class="fa fa-check"></i>List of other publications</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Towards prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="general-introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<blockquote>
<p>“Science advances by playing twenty questions with nature.
The proper tactic is to frame a general question, hopefully binary,
that can be attacked experimentally. Having settled that bits-worth,
one can proceed to the next. The policy appears optimal — one never risks much,
there is feedback from nature at every step, and progress is inevitable.
Unfortunately, the questions never seem to be really answered,
the strategy does not seem to work.”</p>
<footer>
— Allen Newell (1973)
</footer>
</blockquote>
<p>Almost fifty years ago, the artificial intelligence pioneer and cognitive psychologist Allen Newell summarized his discontent with the field of psychology with the sentence “you cannot play twenty questions with nature and win”. In a game of “twenty questions”, one player thinks of a person or object and the other player attempts to guess it by asking up to twenty questions, such as “is it a person?”, “is he a man?”. Only questions that require a binary (yes/no) answer are allowed. Newell argued that most (cognitive) psychology research attempts to understand human behavior and cognition in a manner analogous to a game of twenty questions; that is, by repeatedly asking and trying to answer “binary” research questions — such as “Does cognition impact perception?” and “Are emotional facial expressions innate?” — researchers attempt to gradually explore and reduce the space of possible scientific explanations in the hope to, ultimately, converge on the “the right answer”. Almost fifty years after Newell’s twenty questions article, most of the research in both psychology and cognitive neuroscience still revolves around asking binary research questions about the mind and brain, framed as hypotheses that are evaluated using an ever increasingly sophisticated toolbox of statistical significance tests. Newell, however, believed that in order to gain a fundamental understanding of how the mind and brain work, we need to go beyond asking binary questions and try to investigate human behavior and cognition in all its complexity using quantitative, predictive models that implement human cognitive capacities and behaviors. I believe that this argument is still as relevant today as it was almost fifty years ago.</p>
<p>In this thesis, I explore a different, complementary approach to the traditional methodology of hypothesis testing used in psychology and cognitive neuroscience research. Although this alternative approach has deep roots in psychology and is thus by no means new, the version I advocate and have used in this thesis extends it with ideas and techniques from the rapidly growing field of artificial intelligence and specifically machine learning. As I will describe in more detail in the next section, the crucial difference between the “hypothesis testing approach” and the “predictive approach”, as advocated by Newell, is the way they go about trying to explain and understand a particular cognitive capacity or behavior <span class="citation">(Breiman, <a href="bibliography.html#ref-Breiman2001-lf" role="doc-biblioref">2001</a>)</span>. Although I believe that both approaches have their merits, I think that the predictive approach may be particularly promising given the increasing availability of large datasets and rapid advances in artificial intelligence and machine learning <span class="citation">(Halevy et al., <a href="bibliography.html#ref-Halevy2009-cv" role="doc-biblioref">2009</a>; Yarkoni &amp; Westfall, <a href="bibliography.html#ref-Yarkoni2017-om" role="doc-biblioref">2017</a>)</span>.</p>
<p>This thesis features research that applies, adapts, and contributes to machine learning techniques and methods in the context of predictive models of behavior and neuroimaging data. Specifically, chapters in this thesis describe both examples of predictive models applied to neuroimaging data (chapter <a href="shared-states.html#shared-states">2</a>) and behavior (chapter <a href="hypothesis-kernel-analysis.html#hypothesis-kernel-analysis">6</a> and <a href="static-vs-dynamic.html#static-vs-dynamic">7</a> as well as elements that facilitate and enrich the predictive modelling framework, such as the value of making datasets publicly accessible <span class="citation">(chapter <a href="aomic.html#aomic">4</a>; Adjerid &amp; Kelley, <a href="bibliography.html#ref-Adjerid2018-vs" role="doc-biblioref">2018</a>; Poldrack &amp; Gorgolewski, <a href="bibliography.html#ref-Poldrack2014-ov" role="doc-biblioref">2014</a>)</span>, and a method to aid interpretation of predictive models (chapter <a href="confounds-decoding.html#confounds-decoding">3</a>). Note that the studies contained in this thesis do not all fall squarely in the predictive approach. For example, chapter <a href="morbid-curiosity.html#morbid-curiosity">5</a> features a study that revolved around a confirmatory (and preregistered) hypothesis and chapter <a href="shared-states.html#shared-states">2</a> describes a study that in fact tests a very specific hypothesis using a predictive model. In what follows, I will argue that the predictive approach represents a useful and promising way of doing research that complements the traditional hypothesis testing approach with respect to their common goal of explanation and gaining understanding of the brain and mind. But first, I will illustrate that these two approaches can be thought of as different inferences from the same model which helps to identify their relative (dis)advantages later.</p>
<div id="inference-done-differently" class="section level2">
<h2><span class="header-section-number">1.1</span> Inference done differently</h2>
<p>Both hypothesis testing and predictive modelling are scientific methods used in psychology and neuroscience to gain understanding of human cognition and behavior. Both approaches share an important common component: a statistical model <span class="citation">(Breiman, <a href="bibliography.html#ref-Breiman2001-lf" role="doc-biblioref">2001</a>)</span>. Although there are many different definitions and interpretations of the term “model” <span class="citation">(Kellen, <a href="bibliography.html#ref-Kellen2019-af" role="doc-biblioref">2019</a>)</span>, in this chapter, I define a statistical model as a quantitative representation of (a part of) a target system <span class="citation">(Frigg &amp; Hartmann, <a href="bibliography.html#ref-Frigg2020-hp" role="doc-biblioref">2020</a>)</span>. In psychology and cognitive neuroscience, a target system may refer to a specific cognitive capacity (e.g., emotion recognition) or behavior <span class="citation">(e.g., instrumental learning; Cummins, <a href="bibliography.html#ref-Cummins2000-pk" role="doc-biblioref">2000</a>; Rooij &amp; Baggio, <a href="bibliography.html#ref-Van_Rooij2021-bk" role="doc-biblioref">2021</a>)</span>. Models are used to create a quantitative description, or hypothesis, of how data within a target system may have been generated. Specifically, statistical models describe how one quantity of interest within the target system, <span class="math inline">\(y\)</span> (the “target variable”), may arise as a function (<span class="math inline">\(f\)</span>) of one or more other quantities in the target system, <span class="math inline">\(X\)</span> (the predictor variables or features), often in the presence of noise (<span class="math inline">\(\epsilon\)</span>):</p>
<p><span class="math display">\[\begin{equation}
y = f(X) + \epsilon
\end{equation}\]</span></p>
<p>Put differently, models represent explanations of how variability in a particular aspect of the target system (<span class="math inline">\(y\)</span>) arises as the result of a set of (causally related) features <span class="citation">(Cummins, <a href="bibliography.html#ref-Cummins2000-pk" role="doc-biblioref">2000</a>; Kay, <a href="bibliography.html#ref-Kay2017-vr" role="doc-biblioref">2017</a>)</span>. For example, chapter <a href="hypothesis-kernel-analysis.html#hypothesis-kernel-analysis">6</a> and <a href="static-vs-dynamic.html#static-vs-dynamic">7</a> describe models that attempt to explain the emotion people see in others’ facial expressions (<span class="math inline">\(y\)</span>) as a function of a combination of facial movements (<span class="math inline">\(X_{\mathrm{mov}}\)</span>):</p>
<p><span class="math display">\[\begin{align}
\mathrm{emotion} = f(X_{\mathrm{mov}}) + \epsilon
\end{align}\]</span></p>
<p>In principle, the function linking the predictors to the target can be any function that maps a vector of numbers (the predictors, <span class="math inline">\(X_{i}\)</span>) to a single number (the target value, <span class="math inline">\(y_{i}\)</span>), but almost all statistical tests as well as most predictive models in psychology and cognitive neuroscience use a variant of the general(ized) linear model <span class="citation">(GLM; Ivanova et al., <a href="bibliography.html#ref-Ivanova2021-wk" role="doc-biblioref">2021</a>; Lindeløv, <a href="bibliography.html#ref-Lindelov2019-jk" role="doc-biblioref">2019</a>)</span>. A linear model assumes that the target variable (which we assume to be continuous for now) can be expressed as the sum of a set of features (<span class="math inline">\(X_{1}, X_{2}, \dots , X_{P}\)</span>) weighted by a corresponding set of parameters (<span class="math inline">\(\beta_{1}, \beta_{2}, \dots , \beta_{P}\)</span>). When the target variable is continuous, the corresponding linear model is more commonly known as a <em>linear regression</em> model<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>:</p>
<p><span class="math display">\[\begin{equation}
f(X) = \sum_{j=1}^{P}X_{j} \beta_{j}
\end{equation}\]</span></p>
<p>In linear models, like the linear regression model above, the parameters quantify the strength of the association between each predictor and the target variable. Model parameters are considered unknown and need to be estimated from data. Here, “data” refers to a specific number of observations of the target variable (<span class="math inline">\(y\)</span>) and the predictor variables (<span class="math inline">\(X\)</span>). There are various mathematical techniques to estimate the model parameters, including the well-known (ordinary) least squares analytical solution, iterative gradient-based methods, regularized least squares, and Bayesian parameter inference. These methods differ in how they estimate the data (or, in more technical terms, which particular function they optimize or minimize during estimation), but they all return an <em>estimate</em> of the parameters of the model. These estimated parameters are often denoted with a “hat” (＾; i.e., <span class="math inline">\(\hat{\beta}\)</span>) to distinguish them from the true, but unknown, parameters (i.e., <span class="math inline">\(\beta\)</span>).</p>
<p>After obtaining estimates of the model parameters, the model can be used to make predictions about the value of the target variable (<span class="math inline">\(y\)</span>) given observations of the predictor variables (<span class="math inline">\(X\)</span>):</p>
<p><span class="math display">\[\begin{equation}
\hat{y} = \sum_{j=1}^{P}X_{j} \hat{\beta}_{j}
\end{equation}\]</span></p>
<p>Like the “hat” is used to distinguish estimated from true parameters, the “hat” used in the equation above is used to distinguish a prediction (i.e., an estimate of the target variable, <span class="math inline">\(\hat{y}\)</span>) from the true target value (<span class="math inline">\(y\)</span>). The model predictions can be compared to the actual target values to evaluate the model’s predictive accuracy (which is alternatively called “model fit” or simply “accuracy”), which is usually summarized in a single number using metrics such as <span class="math inline">\(R^{2}\)</span> (also more colloquially known as “explained variance”).</p>
<p>Thus far, the specification of a (linear) model and the estimation of its parameters is common to both the traditional and the predictive approach. The crucial difference between the two approaches, at this point, is what element they treat as unknown and perform inference on. In the hypothesis testing approach, inference is performed on the estimated model parameters while in the predictive approach, inference is performed on the model’s predictive accuracy <span class="citation">(Bzdok, <a href="bibliography.html#ref-Bzdok2017-li" role="doc-biblioref">2017</a>)</span>.</p>
<p>This difference in their focus of inference is associated with different cultures of research which use statistical models to explain a target system in different ways <span class="citation">(Breiman, <a href="bibliography.html#ref-Breiman2001-lf" role="doc-biblioref">2001</a>)</span>. In the traditional hypothesis testing approach, the inferences about model parameters are not meant to <em>directly</em> explain (parts of) a target system. Instead, the target system is verbally described and explained by a <em>theory</em> <span class="citation">(Kellen, <a href="bibliography.html#ref-Kellen2019-af" role="doc-biblioref">2019</a>)</span>. Explanation of the system occurs via testing hypotheses about very specific aspects of the system that are implied by a theory, often in strictly confirmatory experiments <span class="citation">(Wagenmakers et al., <a href="bibliography.html#ref-Wagenmakers2012-vd" role="doc-biblioref">2012</a>)</span>. Because such hypothesis-driven studies often use strictly controlled experiments in which the factor(s) of interest are explicitly manipulated, these studies afford <em>causal</em> interpretation of the observed statistical effects <span class="citation">(Groot, <a href="bibliography.html#ref-degroot" role="doc-biblioref">1961</a>)</span>. For example, if a particular theory about emotion (e.g., basic emotion theory) implies that certain categorical emotions should be universally recognized <span class="citation">(Keltner et al., <a href="bibliography.html#ref-Keltner2019-tm" role="doc-biblioref">2019</a>)</span>, then statistical tests that show that people across the globe are able to distinguish these emotions above chance level <span class="citation">(e.g., Ekman et al., <a href="bibliography.html#ref-Ekman1969-pu" role="doc-biblioref">1969</a>)</span> corroborate this theory. The logic behind this approach is that we get an increasingly better understanding of the target system if we keep testing hypotheses implied by the corresponding theory. Or in Newell’s terminology, if we just keep asking nature questions, we will at some point understand it.</p>
<p>Theories play a less significant role in the predictive modelling culture. Although theories may inspire particular classes of models and constrain the space of possible models <span class="citation">(Rooij &amp; Baggio, <a href="bibliography.html#ref-Van_Rooij2021-bk" role="doc-biblioref">2021</a>)</span>, they do not necessarily represent (a description of) the target system itself. Instead of theories, the predictive approach uses models themselves to both describe and explain a target system <span class="citation">(Guest &amp; Martin<a href="bibliography.html#ref-Guest2020-ef" role="doc-biblioref"></a>)</span>. These models can be thought of as algorithmic or mechanistic hypotheses of how a particular cognitive capacity or behavior may emerge <span class="citation">(Schyns et al., <a href="bibliography.html#ref-schyns2009information" role="doc-biblioref">2009</a>)</span>. For example, the categorical emotion model in chapter <a href="static-vs-dynamic.html#static-vs-dynamic">7</a> represents the mechanistic hypothesis that the capacity of people to infer and recognize emotions from others’ faces occurs through an integration of weighted linear combinations of both facial movements and facial morphological features. Another example is illustrated in Chapter <a href="shared-states.html#shared-states">2</a>, which describes a study in which we hypothesized that the same brain networks associated with emotion experience underlie the capacity for emotion understanding <span class="citation">(Oosterwijk et al., <a href="bibliography.html#ref-Oosterwijk2017-sc" role="doc-biblioref">2017</a>)</span>. Using a predictive model trained on neural patterns associated with components of emotion experience, we could accurately predict emotion components associated with emotion understanding in others, which suggests that these two processes share a common neural implementation <span class="citation">(Peelen &amp; Downing, <a href="bibliography.html#ref-Peelen2007-ew" role="doc-biblioref">2007</a>)</span>. Importantly, in the predictive approach, progress in terms of explanation and understanding is not achieved by binary tests of these theory-driven hypotheses, but by the exploration and development of increasingly accurate models of the target system itself <span class="citation">(Naselaris et al., <a href="bibliography.html#ref-Naselaris2011-oh" role="doc-biblioref">2011</a>)</span>.</p>
<p>To be clear, although the research in this thesis often uses techniques and models from machine learning, the predictive approach should not be equated with machine learning. The origins of this approach, at least in the domain of psychology, can be traced back to the psychophysics studies in the late nineteenth century. Psychophysics studies aim to develop lawlike models of how stimulus attributes give rise to sensory experiences and rarely feature explicit hypothesis tests of model parameters <span class="citation">(Gescheider, <a href="bibliography.html#ref-Gescheider2013-zm" role="doc-biblioref">2013</a>)</span>. Predictive, computational models also play a central role in the field of cognitive science, in which they are used as formal representations and implementations of cognitive processes <span class="citation">(Núñez et al., <a href="bibliography.html#ref-Nunez2019-lh" role="doc-biblioref">2019</a>)</span>. While hypothesis testing has dominated much of psychology and cognitive neuroscience apart from psychophysics and cognitive science, the predictive approach has become more prominent in both psychology <span class="citation">(Yarkoni &amp; Westfall, <a href="bibliography.html#ref-Yarkoni2017-om" role="doc-biblioref">2017</a>)</span> and cognitive neuroscience <span class="citation">(Varoquaux &amp; Thirion, <a href="bibliography.html#ref-Varoquaux2014-su" role="doc-biblioref">2014</a>)</span> in recent years. Machine learning has been particularly influential in cognitive neuroscience, where it was introduced as “pattern analysis” <span class="citation">(Norman et al., <a href="bibliography.html#ref-norman2006beyond" role="doc-biblioref">2006</a>)</span>, but there are many other examples of predictive approaches in psychology and cognitive neuroscience. These approaches include network analysis <span class="citation">(Borsboom &amp; Cramer, <a href="bibliography.html#ref-Borsboom2013-wb" role="doc-biblioref">2013</a>)</span> and structural equation modelling <span class="citation">(Streiner, <a href="bibliography.html#ref-Streiner2006-ze" role="doc-biblioref">2006</a>)</span> in psychology and system identification <span class="citation">(Wu et al., <a href="bibliography.html#ref-Wu2006-qs" role="doc-biblioref">2006</a>)</span>, model-based cognitive neuroscience <span class="citation">(Forstmann &amp; Wagenmakers, <a href="bibliography.html#ref-Forstmann2015-rz" role="doc-biblioref">2015</a>; Turner et al., <a href="bibliography.html#ref-Turner2017-fi" role="doc-biblioref">2017</a>)</span>, and encoding models in cognitive neuroscience <span class="citation">(Holdgraf et al., <a href="bibliography.html#ref-Holdgraf2017-eu" role="doc-biblioref">2017</a>; Naselaris et al., <a href="bibliography.html#ref-Naselaris2011-oh" role="doc-biblioref">2011</a>)</span>. Although these approaches differ in the way they construct and apply models, they all emphasize predictive accuracy rather than hypothesis testing.</p>
<p>In sum, although the traditional and predictive approach share a core component — a quantitative model — they differ in what aspect of the model they use for inference. The associated research cultures implement different approaches to explain and gain understanding of a target system. As I will discuss in the next section, the predictive and hypothesis testing approach each have specific advantages and, when used in combination, can compensate for the weaknesses of the other.</p>
</div>
<div id="towards-prediction" class="section level2">
<h2><span class="header-section-number">1.2</span> Towards prediction</h2>
<p>Scientific models come in many forms and can have many different purposes. In psychology and cognitive neuroscience, researchers use scientific models primarily to explain cognitive capacities and behaviors <span class="citation">(Yarkoni &amp; Westfall, <a href="bibliography.html#ref-Yarkoni2017-om" role="doc-biblioref">2017</a>)</span>. Here I use the term “explanation” to be the identification of the causal components of a particular target system (ibid.). Specifically, scientific models used for hypothesis tests serve as tests of the existence of causal components implied by a particular theory. Explanation is, arguably, not the only function of scientific models. Two other functions often attributed to scientific models are prediction and exploration <span class="citation">(Cichy &amp; Kaiser, <a href="bibliography.html#ref-Cichy2019-zf" role="doc-biblioref">2019</a>; Gelfert, <a href="bibliography.html#ref-Gelfert2016-hd" role="doc-biblioref">2016</a>)</span>. In what follows, I will evaluate the models from the hypothesis testing and the predictive approach on these criteria and argue that they emphasize these criteria differently.</p>
<p>In terms of their ability to <em>explain</em>, models from the hypothesis testing approach are hard to beat. By employing carefully controlled experiments in which usually only a single factor is manipulated, hypothesis tests of models are able to clearly establish the presence of specific causal components of the target system. Moreover, these models usually contain few variables and parameters and are almost always linear, which makes for easy interpretation of the estimated causal effects. The strict experimental setup and simplicity of the models, however, leave little room for <em>exploration</em> of alternative, possibly better models of the target system of phenomenon. In fact, exploration is often explicitly discouraged in the context of hypothesis testing <span class="citation">(Wagenmakers et al., <a href="bibliography.html#ref-Wagenmakers2012-vd" role="doc-biblioref">2012</a>)</span>, which forces researchers to set up a completely new study in order to test an alternative model. Not only exploration suffers from the emphasis on explanation, but prediction as well. The very fact that most models for hypothesis testing only intend to investigate and test a very specific part of the target system results in very simple models that, arguably, cannot capture the complexity of the cognitive capacities and behaviors studied by psychologists and cognitive neuroscientists <span class="citation">(Jolly &amp; Chang, <a href="bibliography.html#ref-Jolly2019-lx" role="doc-biblioref">2019</a>; Tosh et al., <a href="bibliography.html#ref-Tosh2020-sf" role="doc-biblioref">2020</a>)</span>. The result is that each individual model is usually only able to correctly <em>predict</em> a fraction of the variance of the target variable. In a large sample of psychology studies, <span class="citation">Schäfer &amp; Schwarz (<a href="bibliography.html#ref-Schafer2019-ue" role="doc-biblioref">2019</a>)</span> found that the median model performance, expressed as the proportion of explained variance of the target variable, was only 12.6% and was found to be as low as 2.5% for purely confirmatory and preregistered studies.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>A prerequisite for comparing different predictive models is that, ideally, they use the same dataset. Using the same dataset to evaluate different models not only facilitates model comparison but also facilitates incremental progress over time. The famous ImageNet dataset used in computer vision provides a striking example of the impact common datasets can have on the field <span class="citation">(Deng et al., <a href="bibliography.html#ref-Deng2009-bp" role="doc-biblioref">2009</a>)</span>. Since 2011, the ImageNet dataset has been used in the yearly ImageNet Large Scale Visual Recognition Challenge <span class="citation">(Russakovsky et al., <a href="bibliography.html#ref-Russakovsky2015-oo" role="doc-biblioref">2015</a>)</span>, a competition in which researchers can submit object recognition models trained and evaluated on the ImageNet dataset. In 2011, the best performing model achieved 51% accuracy, which has improved yearly, with the best performing model in the 2021 edition achieving 91%.6.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> In the past decade, public datasets have emerged in psychology and cognitive neuroscience as well, often motivated by the desire to improve research transparency and reproducibility <span class="citation">(Gewin, <a href="bibliography.html#ref-Gewin2016-ff" role="doc-biblioref">2016</a>)</span>. However, few have emerged as de facto benchmarks for a given subdomain like ImageNet is for object recognition, which may be due to the fact that most of these datasets are acquired in strictly controlled experiments that strongly limit the variety of models that can be explored and thus limit their reuse <span class="citation">(Naselaris et al., <a href="bibliography.html#ref-Naselaris2021-ba" role="doc-biblioref">2021</a>)</span>. In cognitive neuroscience, there have been some notable exceptions, which include the Natural Scenes Database <span class="citation">(Allen et al., <a href="bibliography.html#ref-Allen2021-zd" role="doc-biblioref">2021</a>)</span> and the Naturalistic Neuroimaging Database <span class="citation">(Aliko et al., <a href="bibliography.html#ref-Aliko2020-ry" role="doc-biblioref">2020</a>)</span>, both with the goal to facilitate the development of models for real-world vision. In Chapter <a href="aomic.html#aomic">4</a>, I describe our effort to release a large, richly annotated dataset to the public domain <span class="citation">(Snoek et al., <a href="bibliography.html#ref-Snoek2021-jx" role="doc-biblioref">2021</a>)</span>. This dataset, the Amsterdam Open MRI Collection, contains a set of multimodal MRI datasets for individual difference analyses, which colleagues and I made publicly available. Not only does the variety in data sources (MRI, physiological, demographic, and psychometric data) allow for the development of a wide variety of novel models, it can also be used to evaluate the generalizability of existing models <span class="citation">(see e.g. Ngo et al., <a href="bibliography.html#ref-Ngo2021-kf" role="doc-biblioref">2021</a>)</span>.</p>
<p>The predictive accuracy of predictive models trained on large, observational datasets, however, does not come for free. One major disadvantage of the predictive approach is that the mechanisms their models represent may not represent the actual mechanisms underlying human cognition and behavior. In other words, complex models may represent what the philosopher Daniel Dennett called “cognitive wheels”: useful inventions that may solve practical problems, but just like wheels do not occur in nature, do not reflect the true mechanisms underlying human cognitive capacities and behaviors <span class="citation">(Dennett, <a href="bibliography.html#ref-Dennett2006-el" role="doc-biblioref">2006</a>; see also Maas et al., <a href="bibliography.html#ref-Van_der_Maas2021-rx" role="doc-biblioref">2021</a>)</span>. A famous example of a cognitive wheel is the finding that state-of-the-art object recognition models seem to rely more on the texture than the shape of the object <span class="citation">(Geirhos et al., <a href="bibliography.html#ref-Geirhos2020-af" role="doc-biblioref">2020</a>; Xu et al., <a href="bibliography.html#ref-xu2018deeper" role="doc-biblioref">2018</a>)</span>, which seems to be the other way around in humans <span class="citation">(Baker et al., <a href="bibliography.html#ref-baker2018deep" role="doc-biblioref">2018</a>)</span>. Relatedly, models used in artificial intelligence seem to be extremely sensitive to spurious, non-causal relationships <span class="citation">(Geirhos et al., <a href="bibliography.html#ref-Geirhos2020-af" role="doc-biblioref">2020</a>)</span>. A famous example of this issue is the observation that a model trained on X-ray data to predict pneumonia diagnosis in fact used text annotations included in the X-ray images rather than the images themselves <span class="citation">(Zech et al., <a href="bibliography.html#ref-Zech2018-bq" role="doc-biblioref">2018</a>)</span>. These limitations have led to the critique that using complex predictive models to explain and understand a target system, especially when using highly non-linear models as is common in many artificial intelligence applications, is like trading in one black box for another <span class="citation">(Kay, <a href="bibliography.html#ref-Kay2017-vr" role="doc-biblioref">2017</a>)</span>. Indeed, given the definition of “explanation” as identification of causal components of a target system, it is hard to argue that predictive models by themselves explain anything.</p>
<p>It is fair to say predictive models, by themselves, are not sufficient as a satisfactory explanation of a target system, but this is not an insurmountable issue. I would argue that the construction and evaluation of a predictive model is only the first step; the second step would be to gain insight into the mechanism that is learned by the model <span class="citation">(Cichy &amp; Kaiser, <a href="bibliography.html#ref-Cichy2019-zf" role="doc-biblioref">2019</a>)</span>. In this second step, the models are treated as concrete representations of the target system that can be manipulated, experimented with, and picked apart in order to gain insights into its mechanism — not unlike model organisms in animal research <span class="citation">(Scholte, <a href="bibliography.html#ref-Scholte2018-he" role="doc-biblioref">2018</a>)</span>. In both the machine learning community and the psychology and cognitive neuroscience community, techniques have been developed to gain insight into the mechanisms of predictive models. One common technique is to selectively manipulate specific model components, such as parameters or intermediate stimulus representations, to test whether these manipulations lead to similar changes in behavior in models and humans <span class="citation">(e.g., Seijdel et al., <a href="bibliography.html#ref-Seijdel2020-ff" role="doc-biblioref">2020</a>)</span>. A related technique is to selectively manipulate the input to the model instead of manipulating the model itself. Chapter <a href="confounds-decoding.html#confounds-decoding">3</a> outlines such a method that can be used to control for specific stimulus features (“confounds”) in predictive models applied to neuroimaging data <span class="citation">(see also Dinga et al., <a href="bibliography.html#ref-Dinga2020-si" role="doc-biblioref">2020</a>)</span>, which can prevent models from learning spurious relationships. Another technique to increase the evidence for a “valid” model (rather than a cognitive wheel) is to show that key components of the model have plausible neural correlates <span class="citation">(Güçlü &amp; Gerven, <a href="bibliography.html#ref-Guclu2015-qj" role="doc-biblioref">2015</a>; Kriegeskorte et al., <a href="bibliography.html#ref-kriegeskorte2008representational" role="doc-biblioref">2008</a>; Yamins et al., <a href="bibliography.html#ref-yamins2014performance" role="doc-biblioref">2014</a>)</span> or to directly constrain models with neural data <span class="citation">(Turner et al., <a href="bibliography.html#ref-Turner2017-fi" role="doc-biblioref">2017</a>)</span>. The underlying idea of applying these different techniques is that explanation and understanding of a target system is not something that is achieved by experiments on the target system directly, but with experiments on the models that represent them <span class="citation">(Cichy &amp; Kaiser, <a href="bibliography.html#ref-Cichy2019-zf" role="doc-biblioref">2019</a>)</span>.</p>
<p>Even though some of the weaknesses of the predictive approach can be mitigated, this does not mean that hypothesis testing should be abandoned. I believe that hypothesis testing remains and will remain an important tool in psychology and cognitive neuroscience and that there are plenty of scenarios in which hypothesis testing should in fact be preferred. First, if the goal is not to provide explanations and gain understanding of some target system, but to test an intervention, then hypothesis testing is an appropriate method. For example, if one wants to know whether some educational intervention improves reading skills in children, then running a randomized controlled experiment and associated hypothesis test is an excellent way to answer this question. Second, hypothesis tests may be useful in providing answers to important (binary) questions that may challenge important assumptions in a particular research domain or theory. For example, Chapter <a href="morbid-curiosity.html#morbid-curiosity">5</a> describes a neuroimaging study that investigated the neural correlates of curiosity for negative information <span class="citation">(“morbid curiosity”; Oosterwijk et al., <a href="bibliography.html#ref-Oosterwijk2020-uf" role="doc-biblioref">2020</a>)</span>, with the preregistered hypothesis that choosing negative content activates reward-related brain regions. The confirmation of this hypothesis challenges current theories of curiosity, because the most obvious indicator of reward — a pleasurable experience — is missing in curiosity for negative content. Therefore, this finding may indicate that information is rewarding “in and of itself”. Finally, phenomena established by the hypothesis testing approach may inform and constrain the development of predictive models <span class="citation">(Borsboom et al., <a href="bibliography.html#ref-Borsboom2020-xg" role="doc-biblioref">2020</a>; Kellen, <a href="bibliography.html#ref-Kellen2019-af" role="doc-biblioref">2019</a>)</span>. An example of this feature is illustrated in Chapter <a href="static-vs-dynamic.html#static-vs-dynamic">7</a>, which describes a model that uses variance in facial morphology to predict the emotions people see in “neutral” faces. The development of this model was inspired by the extensive literature on the associations between factors related to variance in facial morphology (e.g., age, gender, and ethnicity) and the emotional interpretations of static, “neutral” faces <span class="citation">(Hess, Adams, &amp; Kleck, <a href="bibliography.html#ref-Hess2009-xo" role="doc-biblioref">2009</a>)</span>. Although the predictive models were not developed to test specific effects, we actually observed (or “replicated” if you will) several well-known effects from the emotional expression literature, such as the visual similarity and conceptual confusion between anger and disgust expressions <span class="citation">(Jack et al., <a href="bibliography.html#ref-Jack2014-ku" role="doc-biblioref">2014</a>)</span>.</p>
<p>To summarize, I believe that the predictive approach represents a useful addition to the methodological toolbelt of psychologists and cognitive neuroscientists. Given the striking progress in machine learning and artificial intelligence, I think that shifting the focus from explanation to prediction may be a promising avenue for psychology and cognitive neuroscience, but theory and hypothesis testing will remain important to constrain, inform, and test models — an idea that will be revisited in the <a href="general-discussion.html#general-discussion">general discussion</a>.</p>
</div>
<div id="outline-of-this-thesis" class="section level2">
<h2><span class="header-section-number">1.3</span> Outline of this thesis</h2>
<p>Although the chapters of this thesis have been shortly introduced in the previous sections, I will shortly summarize them here for convenience.</p>
<p>In <strong>chapter <a href="shared-states.html#shared-states">2</a></strong>, I describe a study in which we used predictive models applied to functional MRI data, known as “decoding models” in the neuroimaging literature, to test an hypothesis about the shared neural basis of emotion experience and emotion understanding. To remedy the interpretational difficulties inherent to decoding analyses (and predictive models in general), <strong>chapter <a href="confounds-decoding.html#confounds-decoding">3</a></strong> outlines a method we developed to adjust for confounds in decoding analyses which helps to rule out alternative explanations of the results. Moving away from the focus on predictive models, <strong>chapter <a href="aomic.html#aomic">4</a></strong> is the result from our effort to publish the “Amsterdam Open MRI Collection” (AOMIC), a set of three large, multimodal, MRI datasets, and <strong>chapter <a href="morbid-curiosity.html#morbid-curiosity">5</a></strong> describes a confirmatory, fully pre-registered neuroimaging study on a psychological phenomenon called “morbid curiosity”. Finally, the last two chapters return to the use of predictive models, this time in the context of facial expression perception. <strong>Chapter <a href="hypothesis-kernel-analysis.html#hypothesis-kernel-analysis">6</a></strong> outlines a method we developed (“hypothesis kernel analysis”) to formalize verbal hypotheses as quantitative predictive models, which we apply to a specific set of hypotheses about how facial movements relate to categorical emotions. At last, <strong>chapter <a href="static-vs-dynamic.html#static-vs-dynamic">7</a></strong> concludes this thesis with a study that compares predictive models of affective face perception based on static features (i.e., facial morphology) and dynamic features (i.e., facial movements), which shows that people integrate both sources of information in their affective inferences and experiences.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>In this chapter, we assume for simplicity that the target variable, <span class="math inline">\(y\)</span>, is continuous. The target variable, however, does not need to be continuous; in that case, linear models from the GLM additionally include an “inverse link function”, <span class="math inline">\(g^{-1}\)</span>, that maps the linear combination of features to the right domain: <span class="math inline">\(y = g^{-1}(X\beta)\)</span>.<a href="general-introduction.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Note that the original article by <span class="citation">Schäfer &amp; Schwarz (<a href="bibliography.html#ref-Schafer2019-ue" role="doc-biblioref">2019</a>)</span> reported effect size, <span class="math inline">\(r\)</span>, instead of “variance explained”, <span class="math inline">\(R^{2}\)</span>. In analyses that are not cross-validated, the latter can be obtained by squaring the former <span class="citation">(but see Funder &amp; Ozer, <a href="bibliography.html#ref-Funder2019-ow" role="doc-biblioref">2019</a>)</span>.<a href="general-introduction.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Retrieved from <a href="https://paperswithcode.com/sota/image-classification-on-imagenet" class="uri">https://paperswithcode.com/sota/image-classification-on-imagenet</a>.<a href="general-introduction.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="shared-states.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"download": "docs/thesis.pdf"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
